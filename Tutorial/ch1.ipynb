{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: GemPy Basic\n",
    "\n",
    "In this first example, we will show how to construct a first basic model and the main objects and functions. First we import gempy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "# These two lines are necessary only if gempy is not installed\n",
    "import sys, os\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# Importing gempy\n",
    "import gempy as gp\n",
    "\n",
    "# Embedding matplotlib figures into the notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Aux imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9.0.dev-c697eeab84e5b8a74908da654b66ec9eca4f1291'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import theano\n",
    "theano.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data get stored in a python object InputData. Therefore we can use python serialization to save the input of the models. In the next chapter we will see different ways to create data but for this example we will use a stored one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# geo_data = gp.read_pickle('../input_data/NoFault.pickle')\n",
    "# geo_data.n_faults = 0\n",
    "# print(geo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing the data from csv files and settign extent and resolution\n",
    "geo_data = gp.create_data([0,2000,0,2000,-2000,0],[ 50,50,50],\n",
    "                         path_f = os.pardir+\"/input_data/FabLessPoints_Foliations.csv\",\n",
    "                         path_i = os.pardir+\"/input_data/FabLessPoints_Points.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assigning series to formations as well as their order (timewise)\n",
    "gp.set_series(geo_data, {\"fault\":'MainFault', \n",
    "                      \"Rest\":('SecondaryReservoir','Seal','Reservoir', 'NonReservoirDeep')},\n",
    "                       order_series = [\"fault\",\n",
    "                                       \"Rest\",\n",
    "                                       ], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_data = gp.select_series(geo_data, ['Rest'])\n",
    "geo_data.set_formation_number(['SecondaryReservoir', 'Seal','Reservoir','NonReservoirDeep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interp_data = gp.InterpolatorInput(geo_data, u_grade = [3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This geo_data object contains essential information that we can access through the correspondent getters. Such a the coordinates of the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.             0.         -2000.        ]\n",
      " [    0.             0.         -1959.18371582]\n",
      " [    0.             0.         -1918.36730957]\n",
      " ..., \n",
      " [ 2000.          2000.           -81.63265228]\n",
      " [ 2000.          2000.           -40.81632614]\n",
      " [ 2000.          2000.             0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(gp.get_grid(geo_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MainFault', 'NonReservoirDeep', 'Reservoir', 'Seal',\n",
       "       'SecondaryReservoir'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(geo_data.series.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main input the potential field method is the coordinates of interfaces points as well as the orientations. These pandas dataframes can we access by the following methods:\n",
    "\n",
    "#### Interfaces Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>formation</th>\n",
       "      <th>series</th>\n",
       "      <th>annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>800.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>-1400.0</td>\n",
       "      <td>Reservoir</td>\n",
       "      <td>Rest</td>\n",
       "      <td>${\\bf{x}}_{\\alpha \\,{\\bf{1}},0}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>800.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>-1400.0</td>\n",
       "      <td>Reservoir</td>\n",
       "      <td>Rest</td>\n",
       "      <td>${\\bf{x}}_{\\alpha \\,{\\bf{1}},1}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>600.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>-1050.0</td>\n",
       "      <td>Reservoir</td>\n",
       "      <td>Rest</td>\n",
       "      <td>${\\bf{x}}_{\\alpha \\,{\\bf{1}},2}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>-950.0</td>\n",
       "      <td>Reservoir</td>\n",
       "      <td>Rest</td>\n",
       "      <td>${\\bf{x}}_{\\alpha \\,{\\bf{1}},3}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>-1275.0</td>\n",
       "      <td>Reservoir</td>\n",
       "      <td>Rest</td>\n",
       "      <td>${\\bf{x}}_{\\alpha \\,{\\bf{1}},4}$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X       Y       Z  formation series                       annotations\n",
       "5   800.0   200.0 -1400.0  Reservoir   Rest  ${\\bf{x}}_{\\alpha \\,{\\bf{1}},0}$\n",
       "6   800.0  1800.0 -1400.0  Reservoir   Rest  ${\\bf{x}}_{\\alpha \\,{\\bf{1}},1}$\n",
       "7   600.0  1000.0 -1050.0  Reservoir   Rest  ${\\bf{x}}_{\\alpha \\,{\\bf{1}},2}$\n",
       "8   300.0  1000.0  -950.0  Reservoir   Rest  ${\\bf{x}}_{\\alpha \\,{\\bf{1}},3}$\n",
       "9  2000.0  1000.0 -1275.0  Reservoir   Rest  ${\\bf{x}}_{\\alpha \\,{\\bf{1}},4}$"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.get_data(geo_data, 'interfaces').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Foliations Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>dip</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>polarity</th>\n",
       "      <th>formation</th>\n",
       "      <th>series</th>\n",
       "      <th>annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1450.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>-1150.0</td>\n",
       "      <td>18.435</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Reservoir</td>\n",
       "      <td>Rest</td>\n",
       "      <td>${\\bf{x}}_{\\beta \\,{\\bf{3}},0}$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X       Y       Z     dip  azimuth  polarity  formation series  \\\n",
       "1  1450.0  1000.0 -1150.0  18.435     90.0         1  Reservoir   Rest   \n",
       "\n",
       "                       annotations  \n",
       "1  ${\\bf{x}}_{\\beta \\,{\\bf{3}},0}$  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.get_data(geo_data, 'foliations').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to notice the columns of each data frame. These not only contains the geometrical properties of the data but also the **formation** and **series** at which they belong. This division is fundamental in order to preserve the depositional ages of the setting to model.\n",
    "\n",
    "A projection of the aforementioned data can be visualized in to 2D by the following function. It is possible to choose the direction of visualization as well as the series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVwAAAFgCAYAAAD3rsH6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJHCFEEIl/wf4rta0j4kEmAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3925d08e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "geo_data.geo_data_type= 3\n",
    "gp.plot_data(geo_data, series='Rest', direction='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "GemPy supports visualization in 3D as well trough vtk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ta_3D(geo_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ins and outs of Input data objects\n",
    "\n",
    "As we have seen objects DataManagement.InputData (usually called geo_data in the tutorials) aim to have all the original geological properties, measurements and geological relations stored. \n",
    "\n",
    "Once we have the data ready to generate a model, we will need to create the next object type towards the final geological model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theano.config.warn_float64 = 'warn'\n",
    "\n",
    "theano.config.floatX\n",
    "\n",
    "import theano.tensor as T\n",
    "\n",
    "a = T.scalar(dtype='int32')\n",
    "b = T.scalar(dtype='float32')\n",
    "c = a/b\n",
    "c.eval({a:2, b:3}).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ebbf057612bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minterp_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInterpolatorInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeo_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu_grade\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterp_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/PycharmProjects/gempy/gempy/DataManagement.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, geo_data, compile_theano, compute_all, u_grade, rescaling_factor, **kwargs)\u001b[0m\n\u001b[0;32m    854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInterpolatorClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeo_data_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeo_data_res\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcompile_theano\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mth_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_th_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompute_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompile_th_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/PycharmProjects/gempy/gempy/DataManagement.py\u001b[0m in \u001b[0;36mcompile_th_fn\u001b[1;34m(self, compute_all)\u001b[0m\n\u001b[0;32m    874\u001b[0m         \u001b[1;31m# then we compile we have to pass the number of formations that are faults!!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m         th_fn = theano.function(input_data_T, self.interpolator.tg.whole_block_model(self.geo_data_res.n_faults,\n\u001b[1;32m--> 876\u001b[1;33m                                                                                      compute_all=compute_all),\n\u001b[0m\u001b[0;32m    877\u001b[0m                                 \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m                                 \u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/PycharmProjects/gempy/gempy/theanograf.py\u001b[0m in \u001b[0;36mwhole_block_model\u001b[1;34m(self, n_faults, compute_all)\u001b[0m\n\u001b[0;32m   1276\u001b[0m                                \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlen_series_f\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_faults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtaps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m                                \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_formations_per_serie\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_faults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtaps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m                                dict(input=self.u_grade_T[n_faults:], taps=[0])]\n\u001b[0m\u001b[0;32m   1279\u001b[0m                 )\n\u001b[0;32m   1280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/theano/scan_module/scan.py\u001b[0m in \u001b[0;36mscan\u001b[1;34m(fn, sequences, outputs_info, non_sequences, n_steps, truncate_gradient, go_backwards, mode, name, profile, allow_gc, strict, return_list)\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[1;31m# and outputs that needs to be separated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 773\u001b[1;33m     \u001b[0mcondition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscan_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_updates_and_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcondition\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[0mas_while\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/PycharmProjects/gempy/gempy/theanograf.py\u001b[0m in \u001b[0;36mcompute_a_series\u001b[1;34m(self, len_i_0, len_i_1, len_f_0, len_f_1, n_form_per_serie_0, n_form_per_serie_1, u_grade_iter, final_block)\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;31m# Computing the series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \u001b[1;31m# ====================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m         \u001b[0mpotential_field_contribution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlen_points\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         final_block = T.set_subtensor(\n",
      "\u001b[1;32m/home/miguel/PycharmProjects/gempy/gempy/theanograf.py\u001b[0m in \u001b[0;36mblock_series\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m         \u001b[1;31m# Value of the potential field at the interfaces of the computed series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 979\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpotential_field_at_interfaces_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpotential_field_at_interfaces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_formation_op\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m         \u001b[1;31m# self.pot_field_for_faults = potential_field_at_interfaces_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/PycharmProjects/gempy/gempy/theanograf.py\u001b[0m in \u001b[0;36mpotential_field_at_interfaces\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    948\u001b[0m             sequences=dict(input=npf,\n\u001b[0;32m    949\u001b[0m                            taps=[0, 1]),\n\u001b[1;32m--> 950\u001b[1;33m             non_sequences=potential_field_interfaces)\n\u001b[0m\u001b[0;32m    951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[1;31m#  self.potential_field_at_interfaces_value = theano.shared(self.updates1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/theano/scan_module/scan.py\u001b[0m in \u001b[0;36mscan\u001b[1;34m(fn, sequences, outputs_info, non_sequences, n_steps, truncate_gradient, go_backwards, mode, name, profile, allow_gc, strict, return_list)\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[1;31m# and outputs that needs to be separated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 773\u001b[1;33m     \u001b[0mcondition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscan_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_updates_and_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcondition\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[0mas_while\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/PycharmProjects/gempy/gempy/theanograf.py\u001b[0m in \u001b[0;36maverage_potential\u001b[1;34m(dim_a, dim_b, pfi)\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0maverage\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mper\u001b[0m \u001b[0mformation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m             \"\"\"\n\u001b[1;32m--> 941\u001b[1;33m             \u001b[0maverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpfi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdim_b\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdim_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    942\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0maverage\u001b[0m  \u001b[1;31m# , {self.pot_value: T.stack([average])}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/theano/tensor/var.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m                     \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSubtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdvancedIndexingError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0madvanced\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/theano/tensor/subtensor.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(entry, slice_ok)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m                 \u001b[0mslice_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSubtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m                 \u001b[0mslice_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/theano/tensor/subtensor.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(entry, slice_ok)\u001b[0m\n\u001b[0;32m    347\u001b[0m             (entry.type in invalid_scal_types or\n\u001b[0;32m    348\u001b[0m              entry.type in invalid_tensor_types)):\n\u001b[1;32m--> 349\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expected an integer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscal_types\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected an integer"
     ]
    }
   ],
   "source": [
    "interp_data = gp.InterpolatorInput(geo_data, u_grade = [3])\n",
    "print(interp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interp_data.get_formation_number()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "By default (there is a flag in case you do not need) when we create a interp_data object we also compile the theano function that compute the model. That is the reason why takes long.\n",
    "\n",
    "gempy.DataManagement.InterpolatorInput (usually called interp_data in the tutorials) prepares the original data to the interpolation algorithm by scaling the coordinates for better and adding all the mathematical parametrization needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range 0.8882311582565308 3464.1015172\n",
      "Number of drift equations [2 2]\n",
      "Covariance at 0 0.01878463476896286\n",
      "Foliations nugget effect 0.009999999776482582\n"
     ]
    }
   ],
   "source": [
    "gp.get_kriging_parameters(interp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These later parameters have a default value computed from the original data or can be changed by the user (be careful of changing any of these if you do not fully understand their meaning).\n",
    " \n",
    "At this point, we have all what we need to compute our model. By default everytime we compute a model we obtain 3 results:\n",
    "\n",
    "- Lithology block model\n",
    "- The potential field\n",
    "- Faults network block model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "One of the index value is out of bound. Error code: 65535.\\n\nApply node that caused the error: GpuAdvancedSubtensor1(for{gpu,scan_fn}.0, Elemwise{add,no_inplace}.0)\nToposort index: 409\nInputs types: [CudaNdarrayType(float32, vector), TensorType(int64, vector)]\nInputs shapes: [(4,), (4,)]\nInputs strides: [(1,), (8,)]\nInputs values: [b'CudaNdarray([ 0.03435151  0.11909181 -0.02655532  0.13297006])', array([0, 1, 2, 4])]\nInputs type_num: ['', 7]\nOutputs clients: [[HostFromGpu(GpuAdvancedSubtensor1.0), GpuAdvancedIncSubtensor1{no_inplace,set}(<CudaNdarrayType(float32, vector)>, GpuAdvancedSubtensor1.0, Elemwise{add,no_inplace}.0)]]\n\nDebugprint of the apply node: \nGpuAdvancedSubtensor1 [id A] <CudaNdarrayType(float32, vector)> ''   \n |for{gpu,scan_fn} [id B] <CudaNdarrayType(float32, vector)> ''   \n | |<TensorType(int64, scalar)> [id C] <TensorType(int64, scalar)>\n | |Elemwise{Cast{int32}} [id D] <TensorType(int32, vector)> ''   \n | | |<TensorType(int64, vector)> [id E] <TensorType(int64, vector)>\n | |Elemwise{Cast{int32}} [id F] <TensorType(int32, vector)> ''   \n | | |<TensorType(int64, vector)> [id G] <TensorType(int64, vector)>\n | |GpuFromHost [id H] <CudaNdarrayType(float32, vector)> ''   \n | | |Elemwise{Composite{Cast{float32}((i0 - i1))}} [id I] <TensorType(float32, vector)> ''   \n | |   |<TensorType(int64, vector)> [id G] <TensorType(int64, vector)>\n | |   |<TensorType(int64, vector)> [id E] <TensorType(int64, vector)>\n | |<TensorType(int64, scalar)> [id C] <TensorType(int64, scalar)>\n | |GpuSubtensor{int64:int64:} [id J] <CudaNdarrayType(float32, vector)> ''   \n |   |GpuElemwise{Composite{((((i0 * i1 * i2 * i3) + (-i4)) + i5) + i6)}}[(0, 3)] [id K] <CudaNdarrayType(float32, vector)> ''   \n |   | |CudaNdarrayConstant{[-1.]} [id L] <CudaNdarrayType(float32, (True,))>\n |   | |GpuDimShuffle{x} [id M] <CudaNdarrayType(float32, (True,))> ''   \n |   | | |<CudaNdarrayType(float32, (True, True))> [id N] <CudaNdarrayType(float32, (True, True))>\n |   | |GpuDimShuffle{x} [id O] <CudaNdarrayType(float32, (True,))> ''   \n |   | | |<CudaNdarrayType(float32, (True, True))> [id P] <CudaNdarrayType(float32, (True, True))>\n |   | |GpuCAReduce{add}{1,0} [id Q] <CudaNdarrayType(float32, vector)> ''   \n |   | | |GpuElemwise{Composite{(i0 * i1 * i2 * (((i3 + (i4 / i5)) - ((i6 * i7) / i8)) + ((i9 * i10) / i11)))}}[(0, 0)] [id R] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |GpuFromHost [id S] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |Subtensor{:int64:} [id T] <TensorType(float32, matrix)> ''   \n |   | |   |   |InplaceDimShuffle{1,0} [id U] <TensorType(float32, matrix)> ''   \n |   | |   |   | |Reshape{2} [id V] <TensorType(float32, matrix)> ''   \n |   | |   |   |   |Alloc [id W] <TensorType(float32, (False, True, True, False))> ''   \n |   | |   |   |   | |Reshape{1} [id X] <TensorType(float32, vector)> 'Dual Kriging parameters'   \n |   | |   |   |   | |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id Y] <TensorType(int64, scalar)> ''   \n |   | |   |   |   | | |Shape_i{1} [id Z] <TensorType(int64, scalar)> ''   \n |   | |   |   |   | | | |Nonzero [id BA] <TensorType(int64, matrix)> ''   \n |   | |   |   |   | | |   |HostFromGpu [id BB] <TensorType(float32, vector)> ''   \n |   | |   |   |   | | |     |GpuReshape{1} [id BC] <CudaNdarrayType(float32, vector)> ''   \n |   | |   |   |   | | |       |GpuElemwise{mul,no_inplace} [id BD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |   |   | | |       | |Coordinates of the grid points to interpolate_copy[cuda] [id BE] <CudaNdarrayType(float32, matrix)>\n |   | |   |   |   | | |       | |GpuFromHost [id BF] <CudaNdarrayType(float32, col)> ''   \n |   | |   |   |   | | |       |   |Elemwise{Cast{float32}} [id BG] <TensorType(float32, col)> ''   \n |   | |   |   |   | | |       |     |InplaceDimShuffle{0,x} [id BH] <TensorType(bool, col)> ''   \n |   | |   |   |   | | |       |       |Elemwise{eq,no_inplace} [id BI] <TensorType(bool, vector)> 'Yet simulated LITHOLOGY node'   \n |   | |   |   |   | | |       |TensorConstant{(1,) of -1} [id BJ] <TensorType(int64, (True,))>\n |   | |   |   |   | | |TensorConstant{3} [id BK] <TensorType(int64, scalar)>\n |   | |   |   |   | | |Shape_i{0} [id BL] <TensorType(int64, scalar)> ''   \n |   | |   |   |   | | | |Rest of the points of the layers_copy[cuda] [id BM] <CudaNdarrayType(float32, matrix)>\n |   | |   |   |   | | |Shape_i{0} [id BN] <TensorType(int64, scalar)> ''   \n |   | |   |   |   | |   |Reference points for every layer_copy[cuda] [id BO] <CudaNdarrayType(float32, matrix)>\n |   | |   |   |   | |TensorConstant{1} [id BP] <TensorType(int8, scalar)>\n |   | |   |   |   | |TensorConstant{1} [id BP] <TensorType(int8, scalar)>\n |   | |   |   |   | |Elemwise{add,no_inplace} [id BQ] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   |Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i3 * i4) // (i5 * i3 * i4)), i0)}}[(0, 0)] [id BR] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |Elemwise{mul,no_inplace} [id BS] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | | |TensorConstant{3} [id BK] <TensorType(int64, scalar)>\n |   | |   |   |   |   | | |Elemwise{sub,no_inplace} [id BT] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id BU] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |   | |Elemwise{lt,no_inplace} [id BV] <TensorType(bool, scalar)> ''   \n |   | |   |   |   |   | |   | | |<TensorType(int64, scalar)> [id BW] <TensorType(int64, scalar)>\n |   | |   |   |   |   | |   | | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |   | |<TensorType(int64, scalar)> [id BW] <TensorType(int64, scalar)>\n |   | |   |   |   |   | |   | |Shape_i{0} [id BY] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |   | | |Position of the dips_copy[cuda] [id BZ] <CudaNdarrayType(float32, matrix)>\n |   | |   |   |   |   | |   | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |   | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4)}}[(0, 2)] [id CB] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |     |Elemwise{lt,no_inplace} [id CC] <TensorType(bool, scalar)> ''   \n |   | |   |   |   |   | |     | |<TensorType(int64, scalar)> [id CD] <TensorType(int64, scalar)>\n |   | |   |   |   |   | |     | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |     |<TensorType(int64, scalar)> [id CD] <TensorType(int64, scalar)>\n |   | |   |   |   |   | |     |Shape_i{0} [id BY] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |     |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |     |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id BU] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |TensorConstant{3} [id BK] <TensorType(int64, scalar)>\n |   | |   |   |   |   | |Elemwise{sub,no_inplace} [id BT] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |Shape_i{1} [id CE] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | | |Position of the dips_copy[cuda] [id BZ] <CudaNdarrayType(float32, matrix)>\n |   | |   |   |   |   | |TensorConstant{-3} [id CF] <TensorType(int64, scalar)>\n |   | |   |   |   |   |Elemwise{sub,no_inplace} [id CG] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id CH] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | | |Elemwise{lt,no_inplace} [id CI] <TensorType(bool, scalar)> ''   \n |   | |   |   |   |   | | | |<TensorType(int64, scalar)> [id CJ] <TensorType(int64, scalar)>\n |   | |   |   |   |   | | | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   | | |<TensorType(int64, scalar)> [id CJ] <TensorType(int64, scalar)>\n |   | |   |   |   |   | | |Shape_i{0} [id BL] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4)}}[(0, 2)] [id CK] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   |   |Elemwise{lt,no_inplace} [id CL] <TensorType(bool, scalar)> ''   \n |   | |   |   |   |   |   | |<TensorType(int64, scalar)> [id CM] <TensorType(int64, scalar)>\n |   | |   |   |   |   |   | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   |   |<TensorType(int64, scalar)> [id CM] <TensorType(int64, scalar)>\n |   | |   |   |   |   |   |Shape_i{0} [id BL] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   |   |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id CH] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   |<TensorType(int64, scalar)> [id CN] <TensorType(int64, scalar)>\n |   | |   |   |   |MakeVector{dtype='int64'} [id CO] <TensorType(int64, vector)> ''   \n |   | |   |   |     |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id Y] <TensorType(int64, scalar)> ''   \n |   | |   |   |     |Elemwise{add,no_inplace} [id BQ] <TensorType(int64, scalar)> ''   \n |   | |   |   |ScalarFromTensor [id CP] <int64> ''   \n |   | |   |     |Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i3 * i4) // (i5 * i3 * i4)), i0)}}[(0, 0)] [id BR] <TensorType(int64, scalar)> ''   \n |   | |   |GpuJoin [id CQ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   | |GpuElemwise{sub,no_inplace} [id CR] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuDimShuffle{0,x} [id CS] <CudaNdarrayType(float32, col)> ''   \n |   | |   | | | |GpuSubtensor{int64:int64:int8, int64} [id CT] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | | |   |Position of the dips_copy[cuda] [id BZ] <CudaNdarrayType(float32, matrix)>\n |   | |   | | |   |ScalarFromTensor [id CU] <int64> ''   \n |   | |   | | |   | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id CV] <TensorType(int64, scalar)> ''   \n |   | |   | | |   |   |Elemwise{le,no_inplace} [id CW] <TensorType(bool, scalar)> ''   \n |   | |   | | |   |   | |Elemwise{sub,no_inplace} [id BT] <TensorType(int64, scalar)> ''   \n |   | |   | | |   |   | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   | | |   |   |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   | | |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4)}}[(0, 2)] [id CB] <TensorType(int64, scalar)> ''   \n |   | |   | | |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id BU] <TensorType(int64, scalar)> ''   \n |   | |   | | |   |ScalarFromTensor [id CX] <int64> ''   \n |   | |   | | |   | |Elemwise{Switch}[(0, 2)] [id CY] <TensorType(int64, scalar)> ''   \n |   | |   | | |   |   |Elemwise{le,no_inplace} [id CW] <TensorType(bool, scalar)> ''   \n |   | |   | | |   |   |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   | | |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id BU] <TensorType(int64, scalar)> ''   \n |   | |   | | |   |Constant{1} [id CZ] <int8>\n |   | |   | | |   |Constant{0} [id DA] <int64>\n |   | |   | | |GpuDimShuffle{x,0} [id DB] <CudaNdarrayType(float32, row)> ''   \n |   | |   | |   |GpuSubtensor{::, int64} [id DC] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | |     |GpuJoin [id DD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |     | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   | |     | |GpuJoin [id DE] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |     | | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   | |     | | |GpuReshape{2} [id DF] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |     | | | |GpuAdvancedSubtensor1 [id DG] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | |     | | | | |GpuReshape{1} [id BC] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | |     | | | | |Subtensor{int64} [id DH] <TensorType(int64, vector)> ''   \n |   | |   | |     | | | |   |Nonzero [id BA] <TensorType(int64, matrix)> ''   \n |   | |   | |     | | | |   |Constant{0} [id DA] <int64>\n |   | |   | |     | | | |TensorConstant{[-1  3]} [id DI] <TensorType(int64, vector)>\n |   | |   | |     | | |Rest of the points of the layers_copy[cuda] [id BM] <CudaNdarrayType(float32, matrix)>\n |   | |   | |     | |Reference points for every layer_copy[cuda] [id BO] <CudaNdarrayType(float32, matrix)>\n |   | |   | |     |Constant{0} [id DA] <int64>\n |   | |   | |GpuElemwise{sub,no_inplace} [id DJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuDimShuffle{0,x} [id DK] <CudaNdarrayType(float32, col)> ''   \n |   | |   | | | |GpuSubtensor{int64:int64:int8, int64} [id DL] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | | |   |Position of the dips_copy[cuda] [id BZ] <CudaNdarrayType(float32, matrix)>\n |   | |   | | |   |ScalarFromTensor [id CU] <int64> ''   \n |   | |   | | |   |ScalarFromTensor [id CX] <int64> ''   \n |   | |   | | |   |Constant{1} [id CZ] <int8>\n |   | |   | | |   |Constant{1} [id DM] <int64>\n |   | |   | | |GpuDimShuffle{x,0} [id DN] <CudaNdarrayType(float32, row)> ''   \n |   | |   | |   |GpuSubtensor{::, int64} [id DO] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | |     |GpuJoin [id DD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |     |Constant{1} [id DM] <int64>\n |   | |   | |GpuElemwise{sub,no_inplace} [id DP] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |   |GpuDimShuffle{0,x} [id DQ] <CudaNdarrayType(float32, col)> ''   \n |   | |   |   | |GpuSubtensor{int64:int64:int8, int64} [id DR] <CudaNdarrayType(float32, vector)> ''   \n |   | |   |   |   |Position of the dips_copy[cuda] [id BZ] <CudaNdarrayType(float32, matrix)>\n |   | |   |   |   |ScalarFromTensor [id CU] <int64> ''   \n |   | |   |   |   |ScalarFromTensor [id CX] <int64> ''   \n |   | |   |   |   |Constant{1} [id CZ] <int8>\n |   | |   |   |   |Constant{2} [id DS] <int64>\n |   | |   |   |GpuDimShuffle{x,0} [id DT] <CudaNdarrayType(float32, row)> ''   \n |   | |   |     |GpuSubtensor{::, int64} [id DU] <CudaNdarrayType(float32, vector)> ''   \n |   | |   |       |GpuJoin [id DD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |       |Constant{2} [id DS] <int64>\n |   | |   |GpuElemwise{Composite{Cast{float32}(LT(i0, i1))},no_inplace} [id DV] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id DW] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuDimShuffle{0,x} [id DX] <CudaNdarrayType(float32, col)> ''   \n |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id DY] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | | |   |GpuReshape{2} [id DZ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |     |GpuAlloc [id EA] <CudaNdarrayType(float32, (False, True, False, False))> ''   \n |   | |   | | |     | |GpuSubtensor{int64:int64:} [id EB] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |     | | |Position of the dips_copy[cuda] [id BZ] <CudaNdarrayType(float32, matrix)>\n |   | |   | | |     | | |ScalarFromTensor [id EC] <int64> ''   \n |   | |   | | |     | | | |<TensorType(int64, scalar)> [id CD] <TensorType(int64, scalar)>\n |   | |   | | |     | | |ScalarFromTensor [id ED] <int64> ''   \n |   | |   | | |     | |   |<TensorType(int64, scalar)> [id BW] <TensorType(int64, scalar)>\n |   | |   | | |     | |TensorConstant{3} [id EE] <TensorType(int8, scalar)>\n |   | |   | | |     | |TensorConstant{1} [id BP] <TensorType(int8, scalar)>\n |   | |   | | |     | |Elemwise{sub,no_inplace} [id BT] <TensorType(int64, scalar)> ''   \n |   | |   | | |     | |Shape_i{1} [id CE] <TensorType(int64, scalar)> ''   \n |   | |   | | |     |MakeVector{dtype='int64'} [id EF] <TensorType(int64, vector)> ''   \n |   | |   | | |       |Elemwise{mul,no_inplace} [id BS] <TensorType(int64, scalar)> ''   \n |   | |   | | |       |Shape_i{1} [id CE] <TensorType(int64, scalar)> ''   \n |   | |   | | |GpuDimShuffle{x,0} [id EG] <CudaNdarrayType(float32, row)> ''   \n |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id EH] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | | |   |GpuJoin [id DD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuDot22Scalar [id EI] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |GpuReshape{2} [id DZ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |GpuDimShuffle{1,0} [id EJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | | |GpuJoin [id DD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |TensorConstant{2.0} [id EK] <TensorType(float32, scalar)>\n |   | |   | | |CudaNdarrayConstant{[[ 0.]]} [id EL] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |<CudaNdarrayType(float32, (True, True))> [id EM] <CudaNdarrayType(float32, (True, True))>\n |   | |   |<CudaNdarrayType(float32, (True, True))> [id EN] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{mul,no_inplace} [id EO] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 26.25]]} [id EP] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id DW] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |<CudaNdarrayType(float32, (True, True))> [id EQ] <CudaNdarrayType(float32, (True, True))>\n |   | |   |CudaNdarrayConstant{[[ 17.5]]} [id ER] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{pow,no_inplace} [id ES] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id DW] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 3.]]} [id ET] <CudaNdarrayType(float32, (True, True))>\n |   | |   |<CudaNdarrayType(float32, (True, True))> [id EU] <CudaNdarrayType(float32, (True, True))>\n |   | |   |CudaNdarrayConstant{[[ 5.25]]} [id EV] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Pow}[(0, 0)] [id EW] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id DW] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 5.]]} [id EX] <CudaNdarrayType(float32, (True, True))>\n |   | |   |<CudaNdarrayType(float32, (True, True))> [id EY] <CudaNdarrayType(float32, (True, True))>\n |   | |GpuCAReduce{add}{1,0} [id EZ] <CudaNdarrayType(float32, vector)> ''   \n |   | | |GpuElemwise{Composite{(i0 * (i1 * ((i2 * ((i3 + i4 + i5) - (i6 + i7))) - (i8 * ((i3 + i9 + i10) - i11)))))}}[(0, 2)] [id FA] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |GpuSubtensor{int64:int64:} [id FB] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuDimShuffle{1,0} [id FC] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuReshape{2} [id FD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |   |GpuFromHost [id FE] <CudaNdarrayType(float32, (False, True, True, False))> ''   \n |   | |   | |   | |Alloc [id W] <TensorType(float32, (False, True, True, False))> ''   \n |   | |   | |   |MakeVector{dtype='int64'} [id CO] <TensorType(int64, vector)> ''   \n |   | |   | |ScalarFromTensor [id CP] <int64> ''   \n |   | |   | |ScalarFromTensor [id FF] <int64> ''   \n |   | |   |   |Elemwise{add,no_inplace} [id FG] <TensorType(int64, scalar)> ''   \n |   | |   |     |Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i3 * i4) // (i5 * i3 * i4)), i0)}}[(0, 0)] [id BR] <TensorType(int64, scalar)> ''   \n |   | |   |     |Elemwise{sub,no_inplace} [id CG] <TensorType(int64, scalar)> ''   \n |   | |   |<CudaNdarrayType(float32, (True, True))> [id FH] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{Cast{float32}(LT(i0, i1))},no_inplace} [id FI] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id FJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuDimShuffle{0,x} [id FK] <CudaNdarrayType(float32, col)> ''   \n |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id FL] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | | |   |GpuSubtensor{int64:int64:} [id FM] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |     |Rest of the points of the layers_copy[cuda] [id BM] <CudaNdarrayType(float32, matrix)>\n |   | |   | | |     |ScalarFromTensor [id FN] <int64> ''   \n |   | |   | | |     | |<TensorType(int64, scalar)> [id CM] <TensorType(int64, scalar)>\n |   | |   | | |     |ScalarFromTensor [id FO] <int64> ''   \n |   | |   | | |       |<TensorType(int64, scalar)> [id CJ] <TensorType(int64, scalar)>\n |   | |   | | |GpuDimShuffle{x,0} [id EG] <CudaNdarrayType(float32, row)> ''   \n |   | |   | | |GpuDot22Scalar [id FP] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |GpuSubtensor{int64:int64:} [id FM] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |GpuDimShuffle{1,0} [id EJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |TensorConstant{2.0} [id EK] <TensorType(float32, scalar)>\n |   | |   | | |CudaNdarrayConstant{[[ 0.]]} [id EL] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |<CudaNdarrayType(float32, (True, True))> [id EM] <CudaNdarrayType(float32, (True, True))>\n |   | |   |CudaNdarrayConstant{[[ 1.]]} [id FQ] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id FR] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 8.75]]} [id FS] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id FT] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id FJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |<CudaNdarrayType(float32, (True, True))> [id EM] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |CudaNdarrayConstant{[[ 3.]]} [id ET] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id FU] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 0.75]]} [id FV] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id FT] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 7.]]} [id FW] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace} [id FX] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 7.]]} [id FW] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id FT] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))}}[(0, 1)] [id FY] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 3.5]]} [id FZ] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id FT] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 5.]]} [id EX] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{Cast{float32}(LT(i0, i1))},no_inplace} [id GA] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id GB] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuDimShuffle{0,x} [id GC] <CudaNdarrayType(float32, col)> ''   \n |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id GD] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | | |   |GpuSubtensor{int64:int64:} [id GE] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |     |Reference points for every layer_copy[cuda] [id BO] <CudaNdarrayType(float32, matrix)>\n |   | |   | | |     |ScalarFromTensor [id FN] <int64> ''   \n |   | |   | | |     |ScalarFromTensor [id FO] <int64> ''   \n |   | |   | | |GpuDimShuffle{x,0} [id EG] <CudaNdarrayType(float32, row)> ''   \n |   | |   | | |GpuDot22Scalar [id GF] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |GpuSubtensor{int64:int64:} [id GE] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |GpuDimShuffle{1,0} [id EJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |TensorConstant{2.0} [id EK] <TensorType(float32, scalar)>\n |   | |   | | |CudaNdarrayConstant{[[ 0.]]} [id EL] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |<CudaNdarrayType(float32, (True, True))> [id EM] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id GG] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 8.75]]} [id FS] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id GH] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id GB] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |<CudaNdarrayType(float32, (True, True))> [id EM] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |CudaNdarrayConstant{[[ 3.]]} [id ET] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id GI] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 0.75]]} [id FV] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id GH] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 7.]]} [id FW] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{((i0 * sqr(i1)) + (i2 * (i1 ** i3)))}}[(0, 1)] [id GJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |     |CudaNdarrayConstant{[[ 7.]]} [id FW] <CudaNdarrayType(float32, (True, True))>\n |   | |     |GpuElemwise{TrueDiv}[(0, 0)] [id GH] <CudaNdarrayType(float32, matrix)> ''   \n |   | |     |CudaNdarrayConstant{[[ 3.5]]} [id FZ] <CudaNdarrayType(float32, (True, True))>\n |   | |     |CudaNdarrayConstant{[[ 5.]]} [id EX] <CudaNdarrayType(float32, (True, True))>\n |   | |GpuCAReduce{add}{1,0} [id GK] <CudaNdarrayType(float32, vector)> ''   \n |   | | |GpuElemwise{Composite{(((i0 * i1) * i2) * i3)}}[(0, 2)] [id GL] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |GpuSubtensor{int64:int64:} [id GM] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuDimShuffle{1,0} [id FC] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |ScalarFromTensor [id FF] <int64> ''   \n |   | |   | |ScalarFromTensor [id GN] <int64> ''   \n |   | |   |   |Elemwise{Add}[(0, 0)] [id GO] <TensorType(int64, scalar)> ''   \n |   | |   |     |Elemwise{add,no_inplace} [id FG] <TensorType(int64, scalar)> ''   \n |   | |   |     |<TensorType(int64, scalar)> [id CN] <TensorType(int64, scalar)>\n |   | |   |<CudaNdarrayType(float32, (True, True))> [id N] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuDimShuffle{1,0} [id GP] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuReshape{2} [id GQ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |   |GpuAlloc [id GR] <CudaNdarrayType(float32, (False, True, True, False))> ''   \n |   | |   |   | |GpuSubtensor{:int64:} [id GS] <CudaNdarrayType(float32, vector)> ''   \n |   | |   |   | | |<CudaNdarrayType(float32, vector)> [id GT] <CudaNdarrayType(float32, vector)>\n |   | |   |   | | |ScalarFromTensor [id GU] <int64> ''   \n |   | |   |   | |   |<TensorType(int64, scalar)> [id CN] <TensorType(int64, scalar)>\n |   | |   |   | |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id Y] <TensorType(int64, scalar)> ''   \n |   | |   |   | |TensorConstant{1} [id BP] <TensorType(int8, scalar)>\n |   | |   |   | |TensorConstant{1} [id BP] <TensorType(int8, scalar)>\n |   | |   |   | |Elemwise{Composite{Switch(LT(i0, i1), Switch(LT((i0 + i2), i1), i1, (i0 + i2)), Switch(LT(i0, i2), i0, i2))}}[(0, 2)] [id GV] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |<TensorType(int64, scalar)> [id CN] <TensorType(int64, scalar)>\n |   | |   |   |   |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |Shape_i{0} [id GW] <TensorType(int64, scalar)> ''   \n |   | |   |   |     |<CudaNdarrayType(float32, vector)> [id GT] <CudaNdarrayType(float32, vector)>\n |   | |   |   |MakeVector{dtype='int64'} [id GX] <TensorType(int64, vector)> ''   \n |   | |   |     |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id Y] <TensorType(int64, scalar)> ''   \n |   | |   |     |Elemwise{Composite{Switch(LT(i0, i1), Switch(LT((i0 + i2), i1), i1, (i0 + i2)), Switch(LT(i0, i2), i0, i2))}}[(0, 2)] [id GV] <TensorType(int64, scalar)> ''   \n |   | |   |GpuSubtensor{:int64:} [id GY] <CudaNdarrayType(float32, matrix)> ''   \n |   | |     |GpuJoin [id GZ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |     | |TensorConstant{1} [id BP] <TensorType(int8, scalar)>\n |   | |     | |GpuReshape{2} [id HA] <CudaNdarrayType(float32, matrix)> ''   \n |   | |     | | |GpuAdvancedSubtensor1 [id HB] <CudaNdarrayType(float32, vector)> ''   \n |   | |     | | | |GpuReshape{1} [id HC] <CudaNdarrayType(float32, vector)> ''   \n |   | |     | | | | |GpuElemwise{mul,no_inplace} [id HD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |     | | | | | |<CudaNdarrayType(float32, matrix)> [id HE] <CudaNdarrayType(float32, matrix)>\n |   | |     | | | | | |GpuFromHost [id HF] <CudaNdarrayType(float32, row)> ''   \n |   | |     | | | | |   |Elemwise{Cast{float32}} [id HG] <TensorType(float32, row)> ''   \n |   | |     | | | | |     |InplaceDimShuffle{x,0} [id HH] <TensorType(bool, row)> ''   \n |   | |     | | | | |       |Elemwise{eq,no_inplace} [id BI] <TensorType(bool, vector)> 'Yet simulated LITHOLOGY node'   \n |   | |     | | | | |TensorConstant{(1,) of -1} [id BJ] <TensorType(int64, (True,))>\n |   | |     | | | |Subtensor{int64} [id HI] <TensorType(int64, vector)> ''   \n |   | |     | | |   |Nonzero [id HJ] <TensorType(int64, matrix)> ''   \n |   | |     | | |   | |HostFromGpu [id HK] <TensorType(float32, vector)> ''   \n |   | |     | | |   |   |GpuReshape{1} [id HC] <CudaNdarrayType(float32, vector)> ''   \n |   | |     | | |   |Constant{0} [id DA] <int64>\n |   | |     | | |TensorConstant{[ 9 -1]} [id HL] <TensorType(int64, vector)>\n |   | |     | |<CudaNdarrayType(float32, matrix)> [id HM] <CudaNdarrayType(float32, matrix)>\n |   | |     |ScalarFromTensor [id GU] <int64> ''   \n |   | |GpuCAReduce{add}{1,0} [id HN] <CudaNdarrayType(float32, vector)> ''   \n |   |   |GpuElemwise{Mul}[(0, 0)] [id HO] <CudaNdarrayType(float32, matrix)> ''   \n |   |     |GpuSubtensor{int64::} [id HP] <CudaNdarrayType(float32, matrix)> ''   \n |   |     | |GpuDimShuffle{1,0} [id FC] <CudaNdarrayType(float32, matrix)> ''   \n |   |     | |ScalarFromTensor [id GN] <int64> ''   \n |   |     |GpuSubtensor{::, :int64:} [id HQ] <CudaNdarrayType(float32, matrix)> ''   \n |   |       |<CudaNdarrayType(float32, matrix)> [id HR] <CudaNdarrayType(float32, matrix)>\n |   |       |ScalarFromTensor [id HS] <int64> ''   \n |   |         |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id Y] <TensorType(int64, scalar)> ''   \n |   |<int64> [id HT] <int64>\n |   |<int64> [id HU] <int64>\n |Elemwise{add,no_inplace} [id HV] <TensorType(int64, vector)> ''   \n   |TensorConstant{(1,) of -1} [id BJ] <TensorType(int64, (True,))>\n   |Subtensor{int64:int64:} [id HW] <TensorType(int64, vector)> ''   \n     |Value of the formation_copy [id HX] <TensorType(int64, vector)>\n     |ScalarFromTensor [id HY] <int64> ''   \n     | |<TensorType(int64, scalar)> [id HZ] <TensorType(int64, scalar)>\n     |ScalarFromTensor [id IA] <int64> ''   \n       |<TensorType(int64, scalar)> [id IB] <TensorType(int64, scalar)>\n\nInner graphs of the scan ops:\n\nfor{gpu,scan_fn} [id B] <CudaNdarrayType(float32, vector)> ''   \n >GpuElemwise{true_div,no_inplace} [id IC] <CudaNdarrayType(float32, scalar)> ''   \n > |GpuCAReduce{add}{1} [id ID] <CudaNdarrayType(float32, scalar)> ''   \n > | |GpuSubtensor{int32:int32:} [id IE] <CudaNdarrayType(float32, vector)> ''   \n > |   |<CudaNdarrayType(float32, vector)> [id IF] <CudaNdarrayType(float32, vector)> -> [id J]\n > |   |ScalarFromTensor [id IG] <int32> ''   \n > |   | |<TensorType(int32, scalar)> [id IH] <TensorType(int32, scalar)> -> [id D]\n > |   |ScalarFromTensor [id II] <int32> ''   \n > |     |<TensorType(int32, scalar)> [id IJ] <TensorType(int32, scalar)> -> [id F]\n > |<CudaNdarrayType(float32, scalar)> [id IK] <CudaNdarrayType(float32, scalar)> -> [id H]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.\nApply node that caused the error: forall_inplace,gpu,scan_fn}(Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0, Subtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, GpuIncSubtensor{InplaceSet;:int64:}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}}.0, Coordinates of the grid points to interpolate, <CudaNdarrayType(float32, matrix)>, Value of the formation, <CudaNdarrayType(float32, vector)>, GpuFromHost.0, GpuFromHost.0, GpuFromHost.0, GpuFromHost.0, GpuFromHost.0, GpuFromHost.0, GpuDimShuffle{x}.0, GpuDimShuffle{x,x}.0, GpuDimShuffle{x,x}.0, GpuDimShuffle{x,x}.0, GpuElemwise{sqr,no_inplace}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{pow,no_inplace}.0, GpuElemwise{pow,no_inplace}.0, GpuElemwise{pow,no_inplace}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{neg,no_inplace}.0, GpuElemwise{true_div,no_inplace}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{Mul}[(0, 1)].0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace}.0, ScalarFromTensor.0, ScalarFromTensor.0, GpuElemwise{Composite{(((i0 * i1) / sqr(i2)) + i3)},no_inplace}.0, GpuAlloc{memset_0=True}.0, Elemwise{minimum,no_inplace}.0, GpuDimShuffle{1,0}.0, GpuIncSubtensor{InplaceSet;:int64:}.0, Subtensor{int64:int64:int8}.0, Subtensor{int64:int64:int8}.0)\nToposort index: 200\nInputs types: [TensorType(int64, scalar), TensorType(int64, vector), TensorType(int64, vector), TensorType(int64, vector), TensorType(int64, vector), TensorType(int64, vector), TensorType(int64, vector), TensorType(int64, vector), TensorType(int64, vector), TensorType(int64, vector), TensorType(int64, vector), TensorType(int64, vector), CudaNdarrayType(float32, 3D), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(int64, vector), CudaNdarrayType(float32, vector), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, vector), CudaNdarrayType(float32, vector), CudaNdarrayType(float32, vector), CudaNdarrayType(float32, (True,)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True,)), CudaNdarrayType(float32, (True,)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), Scalar(int64), Scalar(int64), CudaNdarrayType(float32, scalar), CudaNdarrayType(float32, matrix), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, vector), TensorType(int64, vector), TensorType(int64, vector)]\nInputs shapes: [(), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (2, 3, 125000), (), (125000, 3), (9, 125000), (4,), (4,), (1, 3), (30, 3), (30, 3), (1,), (1,), (1,), (1,), (1, 1), (1, 1), (1, 1), (1,), (1,), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (), (), (), (0, 125060), (), (9, 60), (9,), (4,), (4,)]\nInputs strides: [(), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (375000, 125000, 1), (), (3, 1), (125000, 1), (8,), (1,), (0, 1), (3, 1), (3, 1), (0,), (0,), (0,), (0,), (0, 0), (0, 0), (0, 0), (0,), (0,), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (), (), (), (125060, 1), (), (1, 9), (1,), (8,), (8,)]\nInputs values: [array(1), array([125030]), array([125000]), array([125060]), array([125030]), array([0]), array([30]), array([0]), array([1]), array([0]), array([4]), array([3]), 'not shown', array(1), 'not shown', 'not shown', array([1, 2, 3, 5]), b'CudaNdarray([ 0.  0.  0.  0.])', b'CudaNdarray([[ 0.57702309  0.50010002  0.48086923]])', 'not shown', 'not shown', b'CudaNdarray([ 18.43499947])', b'CudaNdarray([ 90.])', b'CudaNdarray([ 1.])', b'CudaNdarray([ 2.])', b'CudaNdarray([[ 2.]])', b'CudaNdarray([[ 0.88823116]])', b'CudaNdarray([[ 0.01878463]])', b'CudaNdarray([ 4.])', b'CudaNdarray([ 4.])', b'CudaNdarray([[ 0.43619636]])', b'CudaNdarray([[ 0.70077407]])', b'CudaNdarray([[ 0.55287892]])', b'CudaNdarray([[ 0.07513854]])', b'CudaNdarray([[-0.01878463]])', b'CudaNdarray([[-17.74500084]])', b'CudaNdarray([[ 0.87239271]])', b'CudaNdarray([[ 15.77909279]])', b'CudaNdarray([[ 2.21151567]])', b'CudaNdarray([[ 9.33673954]])', -30, -60, b'CudaNdarray(0.34333333373069763)', b'CudaNdarray([])', array(4), 'not shown', 'not shown', array([13, 18, 25, 30]), array([ 0, 13, 18, 25])]\nInputs type_num: [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, '', 7, '', '', 7, '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 7, 7, '', '', 7, '', '', 7, 7]\nOutputs clients: [[GpuSubtensor{int64:int64:int8}(forall_inplace,gpu,scan_fn}.0, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})], [HostFromGpu(forall_inplace,gpu,scan_fn}.1)]]\n\nDebugprint of the apply node: \nforall_inplace,gpu,scan_fn}.0 [id A] <CudaNdarrayType(float32, 3D)> ''   \n |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id C] <TensorType(int64, scalar)> ''   \n | | |TensorConstant{-1} [id D] <TensorType(int64, scalar)>\n | | |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n | | | |Length of interfaces in every series [id F] <TensorType(int64, vector)>\n | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |Elemwise{sub,no_inplace} [id H] <TensorType(int64, scalar)> ''   \n | | |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id I] <TensorType(int64, scalar)> ''   \n | |   |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n | |   |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id K] <TensorType(int64, scalar)> ''   \n | | |TensorConstant{-1} [id D] <TensorType(int64, scalar)>\n | | |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | | | |Length of foliations in every series [id M] <TensorType(int64, vector)>\n | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |Elemwise{sub,no_inplace} [id N] <TensorType(int64, scalar)> ''   \n | | |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id O] <TensorType(int64, scalar)> ''   \n | |   |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n | |   |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id P] <TensorType(int64, scalar)> ''   \n | | |TensorConstant{-1} [id D] <TensorType(int64, scalar)>\n | | |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | | | |List with the number of formations [id R] <TensorType(int64, vector)>\n | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |Elemwise{sub,no_inplace} [id S] <TensorType(int64, scalar)> ''   \n | | |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id T] <TensorType(int64, scalar)> ''   \n | |   |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n | |   |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |Shape_i{0} [id U] <TensorType(int64, scalar)> ''   \n |   |Grade of the universal drift [id V] <TensorType(int64, vector)>\n |Elemwise{add,no_inplace} [id W] <TensorType(int64, vector)> ''   \n | |Elemwise{Composite{(i0 - (i1 * i2))}}[(0, 0)] [id X] <TensorType(int64, (True,))> ''   \n | | |InplaceDimShuffle{x} [id Y] <TensorType(int64, (True,))> ''   \n | | | |Elemwise{Composite{(i0 + (i1 * i2))}}[(0, 0)] [id Z] <TensorType(int64, scalar)> ''   \n | | |   |Shape_i{0} [id BA] <TensorType(int64, scalar)> ''   \n | | |   | |Coordinates of the grid points to interpolate [id BB] <CudaNdarrayType(float32, matrix)>\n | | |   |TensorConstant{2} [id BC] <TensorType(int64, scalar)>\n | | |   |Shape_i{0} [id BD] <TensorType(int64, scalar)> ''   \n | | |     |Rest of the points of the layers [id BE] <TensorType(float32, matrix)>\n | | |TensorConstant{(1,) of 2} [id BF] <TensorType(int64, (True,))>\n | | |InplaceDimShuffle{x} [id BG] <TensorType(int64, (True,))> ''   \n | |   |Shape_i{0} [id BD] <TensorType(int64, scalar)> ''   \n | |Subtensor{int64:int64:int64} [id BH] <TensorType(int64, vector)> ''   \n |   |Length of interfaces in every series [id F] <TensorType(int64, vector)>\n |   |ScalarFromTensor [id BI] <int64> ''   \n |   | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id BJ] <TensorType(int64, scalar)> ''   \n |   |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id BK] <TensorType(bool, scalar)> ''   \n |   |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4))}}[(0, 3)] [id BL] <TensorType(int64, scalar)> ''   \n |   |   | | |Elemwise{le,no_inplace} [id BM] <TensorType(bool, scalar)> ''   \n |   |   | | | |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i1, i5), i1, i5))}}[(0, 5)] [id BN] <TensorType(int64, scalar)> ''   \n |   |   | | | | |Elemwise{lt,no_inplace} [id BO] <TensorType(bool, scalar)> ''   \n |   |   | | | | | |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n |   |   | | | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   | | | | |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n |   |   | | | | |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n |   |   | | | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id I] <TensorType(int64, scalar)> ''   \n |   |   | | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   | | | | |Elemwise{sub,no_inplace} [id H] <TensorType(int64, scalar)> ''   \n |   |   | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id I] <TensorType(int64, scalar)> ''   \n |   |   | | |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i1, i5), i1, i5))}}[(0, 5)] [id BN] <TensorType(int64, scalar)> ''   \n |   |   | | |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n |   |   | | |TensorConstant{-1} [id BP] <TensorType(int8, scalar)>\n |   |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4)}}[(0, 2)] [id BQ] <TensorType(int64, scalar)> ''   \n |   |   | | |Elemwise{le,no_inplace} [id BM] <TensorType(bool, scalar)> ''   \n |   |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id I] <TensorType(int64, scalar)> ''   \n |   |   | | |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n |   |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4))}}[(0, 3)] [id BL] <TensorType(int64, scalar)> ''   \n |   |   | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4)}}[(0, 2)] [id BQ] <TensorType(int64, scalar)> ''   \n |   |   |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n |   |ScalarFromTensor [id BR] <int64> ''   \n |   | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id BS] <TensorType(int64, scalar)> ''   \n |   |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id BK] <TensorType(bool, scalar)> ''   \n |   |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4))}}[(0, 3)] [id BL] <TensorType(int64, scalar)> ''   \n |   |   |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n |   |Constant{1} [id BT] <int64>\n |Elemwise{add,no_inplace} [id BU] <TensorType(int64, vector)> ''   \n | |Elemwise{Composite{(i0 - (i1 * i2))}}[(0, 0)] [id X] <TensorType(int64, (True,))> ''   \n | |Subtensor{int64:int64:int64} [id BV] <TensorType(int64, vector)> ''   \n |   |Length of interfaces in every series [id F] <TensorType(int64, vector)>\n |   |ScalarFromTensor [id BW] <int64> ''   \n |   | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id BX] <TensorType(int64, scalar)> ''   \n |   |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id BY] <TensorType(bool, scalar)> ''   \n |   |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}}[(0, 2)] [id BZ] <TensorType(int64, scalar)> ''   \n |   |   | | |Elemwise{le,no_inplace} [id CA] <TensorType(bool, scalar)> ''   \n |   |   | | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id CB] <TensorType(int64, scalar)> ''   \n |   |   | | | | |Elemwise{lt,no_inplace} [id BO] <TensorType(bool, scalar)> ''   \n |   |   | | | | |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n |   |   | | | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id C] <TensorType(int64, scalar)> ''   \n |   |   | | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id CB] <TensorType(int64, scalar)> ''   \n |   |   | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id C] <TensorType(int64, scalar)> ''   \n |   |   | | |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n |   |   | | |TensorConstant{-1} [id BP] <TensorType(int8, scalar)>\n |   |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5)}}[(0, 3)] [id CC] <TensorType(int64, scalar)> ''   \n |   |   | | |Elemwise{le,no_inplace} [id CA] <TensorType(bool, scalar)> ''   \n |   |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   | | |TensorConstant{0} [id CD] <TensorType(int64, scalar)>\n |   |   | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id C] <TensorType(int64, scalar)> ''   \n |   |   | | |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n |   |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}}[(0, 2)] [id BZ] <TensorType(int64, scalar)> ''   \n |   |   | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5)}}[(0, 3)] [id CC] <TensorType(int64, scalar)> ''   \n |   |   |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n |   |ScalarFromTensor [id CE] <int64> ''   \n |   | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id CF] <TensorType(int64, scalar)> ''   \n |   |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id BY] <TensorType(bool, scalar)> ''   \n |   |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}}[(0, 2)] [id BZ] <TensorType(int64, scalar)> ''   \n |   |   |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n |   |Constant{1} [id BT] <int64>\n |Elemwise{add,no_inplace} [id CG] <TensorType(int64, vector)> ''   \n | |Elemwise{Add}[(0, 0)] [id CH] <TensorType(int64, (True,))> ''   \n | | |Elemwise{Composite{(i0 - (i1 * i2))}}[(0, 0)] [id X] <TensorType(int64, (True,))> ''   \n | | |InplaceDimShuffle{x} [id BG] <TensorType(int64, (True,))> ''   \n | |Subtensor{int64:int64:int64} [id BH] <TensorType(int64, vector)> ''   \n |Elemwise{add,no_inplace} [id CI] <TensorType(int64, vector)> ''   \n | |Elemwise{Add}[(0, 0)] [id CH] <TensorType(int64, (True,))> ''   \n | |Subtensor{int64:int64:int64} [id BV] <TensorType(int64, vector)> ''   \n |Subtensor{int64:int64:int64} [id BV] <TensorType(int64, vector)> ''   \n |Subtensor{int64:int64:int64} [id BH] <TensorType(int64, vector)> ''   \n |Subtensor{int64:int64:int64} [id CJ] <TensorType(int64, vector)> ''   \n | |Length of foliations in every series [id M] <TensorType(int64, vector)>\n | |ScalarFromTensor [id CK] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id CL] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id CM] <TensorType(bool, scalar)> ''   \n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}}[(0, 2)] [id CN] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id CO] <TensorType(bool, scalar)> ''   \n | |   | | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id CP] <TensorType(int64, scalar)> ''   \n | |   | | | | |Elemwise{lt,no_inplace} [id BO] <TensorType(bool, scalar)> ''   \n | |   | | | | |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n | |   | | | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id K] <TensorType(int64, scalar)> ''   \n | |   | | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id CP] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id K] <TensorType(int64, scalar)> ''   \n | |   | | |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |   | | |TensorConstant{-1} [id BP] <TensorType(int8, scalar)>\n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5)}}[(0, 3)] [id CQ] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id CO] <TensorType(bool, scalar)> ''   \n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |TensorConstant{0} [id CD] <TensorType(int64, scalar)>\n | |   | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id K] <TensorType(int64, scalar)> ''   \n | |   | | |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}}[(0, 2)] [id CN] <TensorType(int64, scalar)> ''   \n | |   | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5)}}[(0, 3)] [id CQ] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |ScalarFromTensor [id CR] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id CS] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id CM] <TensorType(bool, scalar)> ''   \n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}}[(0, 2)] [id CN] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |Constant{1} [id BT] <int64>\n |Subtensor{int64:int64:int64} [id CT] <TensorType(int64, vector)> ''   \n | |Length of foliations in every series [id M] <TensorType(int64, vector)>\n | |ScalarFromTensor [id CU] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id CV] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id CW] <TensorType(bool, scalar)> ''   \n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4))}}[(0, 3)] [id CX] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id CY] <TensorType(bool, scalar)> ''   \n | |   | | | |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i1, i5), i1, i5))}}[(0, 5)] [id CZ] <TensorType(int64, scalar)> ''   \n | |   | | | | |Elemwise{lt,no_inplace} [id BO] <TensorType(bool, scalar)> ''   \n | |   | | | | |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n | |   | | | | |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |   | | | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id O] <TensorType(int64, scalar)> ''   \n | |   | | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | | | |Elemwise{sub,no_inplace} [id N] <TensorType(int64, scalar)> ''   \n | |   | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id O] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i1, i5), i1, i5))}}[(0, 5)] [id CZ] <TensorType(int64, scalar)> ''   \n | |   | | |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |   | | |TensorConstant{-1} [id BP] <TensorType(int8, scalar)>\n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4)}}[(0, 2)] [id DA] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id CY] <TensorType(bool, scalar)> ''   \n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id O] <TensorType(int64, scalar)> ''   \n | |   | | |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4))}}[(0, 3)] [id CX] <TensorType(int64, scalar)> ''   \n | |   | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4)}}[(0, 2)] [id DA] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |ScalarFromTensor [id DB] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id DC] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id CW] <TensorType(bool, scalar)> ''   \n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4))}}[(0, 3)] [id CX] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |Constant{1} [id BT] <int64>\n |Subtensor{int64:int64:int64} [id DD] <TensorType(int64, vector)> ''   \n | |List with the number of formations [id R] <TensorType(int64, vector)>\n | |ScalarFromTensor [id DE] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id DF] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id DG] <TensorType(bool, scalar)> ''   \n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}}[(0, 2)] [id DH] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id DI] <TensorType(bool, scalar)> ''   \n | |   | | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id DJ] <TensorType(int64, scalar)> ''   \n | |   | | | | |Elemwise{lt,no_inplace} [id BO] <TensorType(bool, scalar)> ''   \n | |   | | | | |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n | |   | | | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id P] <TensorType(int64, scalar)> ''   \n | |   | | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id DJ] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id P] <TensorType(int64, scalar)> ''   \n | |   | | |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |   | | |TensorConstant{-1} [id BP] <TensorType(int8, scalar)>\n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5)}}[(0, 3)] [id DK] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id DI] <TensorType(bool, scalar)> ''   \n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |TensorConstant{0} [id CD] <TensorType(int64, scalar)>\n | |   | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id P] <TensorType(int64, scalar)> ''   \n | |   | | |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}}[(0, 2)] [id DH] <TensorType(int64, scalar)> ''   \n | |   | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5)}}[(0, 3)] [id DK] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |ScalarFromTensor [id DL] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id DM] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id DG] <TensorType(bool, scalar)> ''   \n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}}[(0, 2)] [id DH] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |Constant{1} [id BT] <int64>\n |Subtensor{int64:int64:int64} [id DN] <TensorType(int64, vector)> ''   \n | |List with the number of formations [id R] <TensorType(int64, vector)>\n | |ScalarFromTensor [id DO] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id DP] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id DQ] <TensorType(bool, scalar)> ''   \n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4))}}[(0, 3)] [id DR] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id DS] <TensorType(bool, scalar)> ''   \n | |   | | | |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i1, i5), i1, i5))}}[(0, 5)] [id DT] <TensorType(int64, scalar)> ''   \n | |   | | | | |Elemwise{lt,no_inplace} [id BO] <TensorType(bool, scalar)> ''   \n | |   | | | | |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n | |   | | | | |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |   | | | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id T] <TensorType(int64, scalar)> ''   \n | |   | | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | | | |Elemwise{sub,no_inplace} [id S] <TensorType(int64, scalar)> ''   \n | |   | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id T] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i1, i5), i1, i5))}}[(0, 5)] [id DT] <TensorType(int64, scalar)> ''   \n | |   | | |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |   | | |TensorConstant{-1} [id BP] <TensorType(int8, scalar)>\n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4)}}[(0, 2)] [id DU] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id DS] <TensorType(bool, scalar)> ''   \n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id T] <TensorType(int64, scalar)> ''   \n | |   | | |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4))}}[(0, 3)] [id DR] <TensorType(int64, scalar)> ''   \n | |   | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4)}}[(0, 2)] [id DU] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |ScalarFromTensor [id DV] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id DW] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id DQ] <TensorType(bool, scalar)> ''   \n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4))}}[(0, 3)] [id DR] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |Constant{1} [id BT] <int64>\n |Subtensor{int64:int64:int64} [id DX] <TensorType(int64, vector)> ''   \n | |Grade of the universal drift [id V] <TensorType(int64, vector)>\n | |ScalarFromTensor [id DY] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id DZ] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id EA] <TensorType(bool, scalar)> ''   \n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1, i4), i3), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1, i4), i3))}}[(0, 2)] [id EB] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id EC] <TensorType(bool, scalar)> ''   \n | |   | | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id ED] <TensorType(int64, scalar)> ''   \n | |   | | | | |Elemwise{lt,no_inplace} [id BO] <TensorType(bool, scalar)> ''   \n | |   | | | | |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n | |   | | | | |Shape_i{0} [id U] <TensorType(int64, scalar)> ''   \n | |   | | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id ED] <TensorType(int64, scalar)> ''   \n | |   | | |Shape_i{0} [id U] <TensorType(int64, scalar)> ''   \n | |   | | |TensorConstant{-1} [id BP] <TensorType(int8, scalar)>\n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1), i3), i1), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1), i3), i1), i4)}} [id EE] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id EC] <TensorType(bool, scalar)> ''   \n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |TensorConstant{0} [id CD] <TensorType(int64, scalar)>\n | |   | | |Shape_i{0} [id U] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1, i4), i3), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1, i4), i3))}}[(0, 2)] [id EB] <TensorType(int64, scalar)> ''   \n | |   | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1), i3), i1), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1), i3), i1), i4)}} [id EE] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id U] <TensorType(int64, scalar)> ''   \n | |ScalarFromTensor [id EF] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id EG] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id EA] <TensorType(bool, scalar)> ''   \n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1, i4), i3), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1, i4), i3))}}[(0, 2)] [id EB] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id U] <TensorType(int64, scalar)> ''   \n | |Constant{1} [id BT] <int64>\n |GpuIncSubtensor{InplaceSet;:int64:} [id EH] <CudaNdarrayType(float32, 3D)> ''   \n | |GpuAllocEmpty [id EI] <CudaNdarrayType(float32, 3D)> ''   \n | | |Elemwise{Composite{(Switch(LT(maximum(i0, i1), i2), (maximum(i0, i1) + i3), (maximum(i0, i1) - i2)) + i3)}}[(0, 0)] [id EJ] <TensorType(int64, scalar)> ''   \n | | | |Elemwise{Composite{((i0 - i1) + i2)}} [id EK] <TensorType(int64, scalar)> ''   \n | | | | |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n | | | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id EL] <TensorType(int64, scalar)> ''   \n | | | | | |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n | | | | | |Elemwise{add,no_inplace} [id EM] <TensorType(int64, scalar)> ''   \n | | | | |   |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n | | | | |   |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n | | | | |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n | | | |TensorConstant{2} [id BC] <TensorType(int64, scalar)>\n | | | |TensorConstant{1} [id EN] <TensorType(int8, scalar)>\n | | | |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n | | |Elemwise{add,no_inplace} [id EO] <TensorType(int64, scalar)> ''   \n | | | |Shape_i{0} [id EP] <TensorType(int64, scalar)> ''   \n | | | | |final block of lithologies init [id EQ] <CudaNdarrayType(float32, matrix)>\n | | | |Shape_i{0} [id EP] <TensorType(int64, scalar)> ''   \n | | | |Shape_i{0} [id EP] <TensorType(int64, scalar)> ''   \n | | |Shape_i{1} [id ER] <TensorType(int64, scalar)> ''   \n | |   |final block of lithologies init [id EQ] <CudaNdarrayType(float32, matrix)>\n | |Rebroadcast{0} [id ES] <CudaNdarrayType(float32, 3D)> ''   \n | | |GpuDimShuffle{x,0,1} [id ET] <CudaNdarrayType(float32, (True, False, False))> ''   \n | |   |GpuJoin [id EU] <CudaNdarrayType(float32, matrix)> ''   \n | |     |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |     |final block of lithologies init [id EQ] <CudaNdarrayType(float32, matrix)>\n | |     |final block of lithologies init [id EQ] <CudaNdarrayType(float32, matrix)>\n | |     |final block of lithologies init [id EQ] <CudaNdarrayType(float32, matrix)>\n | |Constant{1} [id BT] <int64>\n |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n |Coordinates of the grid points to interpolate [id BB] <CudaNdarrayType(float32, matrix)>\n |<CudaNdarrayType(float32, matrix)> [id EV] <CudaNdarrayType(float32, matrix)>\n |Value of the formation [id EW] <TensorType(int64, vector)>\n |<CudaNdarrayType(float32, vector)> [id EX] <CudaNdarrayType(float32, vector)>\n |GpuFromHost [id EY] <CudaNdarrayType(float32, matrix)> ''   \n | |Position of the dips [id EZ] <TensorType(float32, matrix)>\n |GpuFromHost [id FA] <CudaNdarrayType(float32, matrix)> ''   \n | |Rest of the points of the layers [id BE] <TensorType(float32, matrix)>\n |GpuFromHost [id FB] <CudaNdarrayType(float32, matrix)> ''   \n | |Reference points for every layer [id FC] <TensorType(float32, matrix)>\n |GpuFromHost [id FD] <CudaNdarrayType(float32, vector)> ''   \n | |Angle of every dip [id FE] <TensorType(float32, vector)>\n |GpuFromHost [id FF] <CudaNdarrayType(float32, vector)> ''   \n | |Azimuth [id FG] <TensorType(float32, vector)>\n |GpuFromHost [id FH] <CudaNdarrayType(float32, vector)> ''   \n | |Polarity [id FI] <TensorType(float32, vector)>\n |GpuDimShuffle{x} [id FJ] <CudaNdarrayType(float32, (True,))> ''   \n | |<CudaNdarrayType(float32, scalar)> [id FK] <CudaNdarrayType(float32, scalar)>\n |GpuDimShuffle{x,x} [id FL] <CudaNdarrayType(float32, (True, True))> ''   \n | |<CudaNdarrayType(float32, scalar)> [id FK] <CudaNdarrayType(float32, scalar)>\n |GpuDimShuffle{x,x} [id FM] <CudaNdarrayType(float32, (True, True))> ''   \n | |Range [id FN] <CudaNdarrayType(float32, scalar)>\n |GpuDimShuffle{x,x} [id FO] <CudaNdarrayType(float32, (True, True))> ''   \n | |Covariance at 0 [id FP] <CudaNdarrayType(float32, scalar)>\n |GpuElemwise{sqr,no_inplace} [id FQ] <CudaNdarrayType(float32, (True,))> ''   \n | |GpuDimShuffle{x} [id FJ] <CudaNdarrayType(float32, (True,))> ''   \n |GpuElemwise{mul,no_inplace} [id FR] <CudaNdarrayType(float32, (True,))> ''   \n | |CudaNdarrayConstant{[ 2.]} [id FS] <CudaNdarrayType(float32, (True,))>\n | |GpuDimShuffle{x} [id FJ] <CudaNdarrayType(float32, (True,))> ''   \n |GpuElemwise{pow,no_inplace} [id FT] <CudaNdarrayType(float32, (True, True))> ''   \n | |GpuDimShuffle{x,x} [id FM] <CudaNdarrayType(float32, (True, True))> ''   \n | |CudaNdarrayConstant{[[ 7.]]} [id FU] <CudaNdarrayType(float32, (True, True))>\n |GpuElemwise{pow,no_inplace} [id FV] <CudaNdarrayType(float32, (True, True))> ''   \n | |GpuDimShuffle{x,x} [id FM] <CudaNdarrayType(float32, (True, True))> ''   \n | |CudaNdarrayConstant{[[ 3.]]} [id FW] <CudaNdarrayType(float32, (True, True))>\n |GpuElemwise{pow,no_inplace} [id FX] <CudaNdarrayType(float32, (True, True))> ''   \n | |GpuDimShuffle{x,x} [id FM] <CudaNdarrayType(float32, (True, True))> ''   \n | |CudaNdarrayConstant{[[ 5.]]} [id FY] <CudaNdarrayType(float32, (True, True))>\n |GpuElemwise{mul,no_inplace} [id FZ] <CudaNdarrayType(float32, (True, True))> ''   \n | |GpuDimShuffle{x,x} [id FO] <CudaNdarrayType(float32, (True, True))> ''   \n | |GpuDimShuffle{x,x} [id GA] <CudaNdarrayType(float32, (True, True))> ''   \n |   |<CudaNdarrayType(float32, scalar)> [id GB] <CudaNdarrayType(float32, scalar)>\n |GpuElemwise{neg,no_inplace} [id GC] <CudaNdarrayType(float32, (True, True))> ''   \n | |GpuDimShuffle{x,x} [id FO] <CudaNdarrayType(float32, (True, True))> ''   \n |GpuElemwise{true_div,no_inplace} [id GD] <CudaNdarrayType(float32, (True, True))> ''   \n | |CudaNdarrayConstant{[[-14.]]} [id GE] <CudaNdarrayType(float32, (True, True))>\n | |GpuElemwise{sqr,no_inplace} [id GF] <CudaNdarrayType(float32, (True, True))> ''   \n |   |GpuDimShuffle{x,x} [id FM] <CudaNdarrayType(float32, (True, True))> ''   \n |GpuElemwise{mul,no_inplace} [id GG] <CudaNdarrayType(float32, (True, True))> ''   \n | |CudaNdarrayConstant{[[ 2.]]} [id GH] <CudaNdarrayType(float32, (True, True))>\n | |GpuElemwise{pow,no_inplace} [id FT] <CudaNdarrayType(float32, (True, True))> ''   \n |GpuElemwise{Mul}[(0, 1)] [id GI] <CudaNdarrayType(float32, (True, True))> ''   \n | |CudaNdarrayConstant{[[ 20.]]} [id GJ] <CudaNdarrayType(float32, (True, True))>\n | |GpuElemwise{sqr,no_inplace} [id GF] <CudaNdarrayType(float32, (True, True))> ''   \n |GpuElemwise{mul,no_inplace} [id GK] <CudaNdarrayType(float32, (True, True))> ''   \n | |CudaNdarrayConstant{[[ 4.]]} [id GL] <CudaNdarrayType(float32, (True, True))>\n | |GpuElemwise{pow,no_inplace} [id FX] <CudaNdarrayType(float32, (True, True))> ''   \n |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id GM] <CudaNdarrayType(float32, (True, True))> ''   \n | |CudaNdarrayConstant{[[ 15.]]} [id GN] <CudaNdarrayType(float32, (True, True))>\n | |GpuDimShuffle{x,x} [id FM] <CudaNdarrayType(float32, (True, True))> ''   \n | |CudaNdarrayConstant{[[ 4.]]} [id GL] <CudaNdarrayType(float32, (True, True))>\n |ScalarFromTensor [id GO] <int64> ''   \n | |Elemwise{neg,no_inplace} [id GP] <TensorType(int64, scalar)> ''   \n |   |Shape_i{0} [id BD] <TensorType(int64, scalar)> ''   \n |ScalarFromTensor [id GQ] <int64> ''   \n | |Elemwise{Mul}[(0, 1)] [id GR] <TensorType(int64, scalar)> ''   \n |   |TensorConstant{-2} [id GS] <TensorType(int64, scalar)>\n |   |Shape_i{0} [id BD] <TensorType(int64, scalar)> ''   \n |GpuElemwise{Composite{(((i0 * i1) / sqr(i2)) + i3)},no_inplace} [id GT] <CudaNdarrayType(float32, scalar)> ''   \n | |CudaNdarrayConstant{14.0} [id GU] <CudaNdarrayType(float32, scalar)>\n | |Covariance at 0 [id FP] <CudaNdarrayType(float32, scalar)>\n | |Range [id FN] <CudaNdarrayType(float32, scalar)>\n | |<CudaNdarrayType(float32, scalar)> [id GV] <CudaNdarrayType(float32, scalar)>\n |GpuAlloc{memset_0=True} [id GW] <CudaNdarrayType(float32, matrix)> ''   \n | |CudaNdarrayConstant{0.0} [id GX] <CudaNdarrayType(float32, scalar)>\n | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |Elemwise{Composite{(i0 + (i1 * i2))}}[(0, 0)] [id Z] <TensorType(int64, scalar)> ''   \n |Elemwise{minimum,no_inplace} [id GY] <TensorType(int64, scalar)> ''   \n | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id GZ] <TensorType(int64, scalar)> ''   \n | | |TensorConstant{-1} [id D] <TensorType(int64, scalar)>\n | | |Prod{axis=None, dtype='int64', acc_dtype='int64'} [id HA] <TensorType(int64, scalar)> ''   \n | | | |MakeVector{dtype='int64'} [id HB] <TensorType(int64, vector)> ''   \n | | |   |Elemwise{Add}[(0, 1)] [id HC] <TensorType(int64, scalar)> ''   \n | | |     |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n | | |     |Shape_i{0} [id HD] <TensorType(int64, scalar)> ''   \n | | |       |<TensorType(int64, vector)> [id HE] <TensorType(int64, vector)>\n | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |Elemwise{sub,no_inplace} [id HF] <TensorType(int64, scalar)> ''   \n |   |Prod{axis=None, dtype='int64', acc_dtype='int64'} [id HA] <TensorType(int64, scalar)> ''   \n |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id HG] <TensorType(int64, scalar)> ''   \n |     |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n |     |Prod{axis=None, dtype='int64', acc_dtype='int64'} [id HA] <TensorType(int64, scalar)> ''   \n |GpuDimShuffle{1,0} [id HH] <CudaNdarrayType(float32, matrix)> ''   \n | |GpuJoin [id HI] <CudaNdarrayType(float32, matrix)> ''   \n |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |GpuJoin [id HJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |TensorConstant{1} [id EN] <TensorType(int8, scalar)>\n |   | |GpuFromHost [id FA] <CudaNdarrayType(float32, matrix)> ''   \n |   | |GpuElemwise{sqr,no_inplace} [id HK] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |GpuFromHost [id FA] <CudaNdarrayType(float32, matrix)> ''   \n |   | |GpuJoin [id HL] <CudaNdarrayType(float32, matrix)> ''   \n |   |   |TensorConstant{1} [id EN] <TensorType(int8, scalar)>\n |   |   |GpuElemwise{mul,no_inplace} [id HM] <CudaNdarrayType(float32, col)> ''   \n |   |   | |GpuDimShuffle{0,x} [id HN] <CudaNdarrayType(float32, col)> ''   \n |   |   | | |GpuSubtensor{::, int64} [id HO] <CudaNdarrayType(float32, vector)> ''   \n |   |   | |   |GpuFromHost [id FA] <CudaNdarrayType(float32, matrix)> ''   \n |   |   | |   |Constant{0} [id HP] <int64>\n |   |   | |GpuDimShuffle{0,x} [id HQ] <CudaNdarrayType(float32, col)> ''   \n |   |   |   |GpuSubtensor{::, int64} [id HR] <CudaNdarrayType(float32, vector)> ''   \n |   |   |     |GpuFromHost [id FA] <CudaNdarrayType(float32, matrix)> ''   \n |   |   |     |Constant{1} [id BT] <int64>\n |   |   |GpuElemwise{mul,no_inplace} [id HS] <CudaNdarrayType(float32, col)> ''   \n |   |   | |GpuDimShuffle{0,x} [id HN] <CudaNdarrayType(float32, col)> ''   \n |   |   | |GpuDimShuffle{0,x} [id HT] <CudaNdarrayType(float32, col)> ''   \n |   |   |   |GpuSubtensor{::, int64} [id HU] <CudaNdarrayType(float32, vector)> ''   \n |   |   |     |GpuFromHost [id FA] <CudaNdarrayType(float32, matrix)> ''   \n |   |   |     |Constant{2} [id HV] <int64>\n |   |   |GpuElemwise{mul,no_inplace} [id HW] <CudaNdarrayType(float32, col)> ''   \n |   |     |GpuDimShuffle{0,x} [id HQ] <CudaNdarrayType(float32, col)> ''   \n |   |     |GpuDimShuffle{0,x} [id HT] <CudaNdarrayType(float32, col)> ''   \n |   |GpuJoin [id HX] <CudaNdarrayType(float32, matrix)> ''   \n |     |TensorConstant{1} [id EN] <TensorType(int8, scalar)>\n |     |GpuFromHost [id FB] <CudaNdarrayType(float32, matrix)> ''   \n |     |GpuElemwise{sqr,no_inplace} [id HY] <CudaNdarrayType(float32, matrix)> ''   \n |     | |GpuFromHost [id FB] <CudaNdarrayType(float32, matrix)> ''   \n |     |GpuJoin [id HZ] <CudaNdarrayType(float32, matrix)> ''   \n |       |TensorConstant{1} [id EN] <TensorType(int8, scalar)>\n |       |GpuElemwise{mul,no_inplace} [id IA] <CudaNdarrayType(float32, col)> ''   \n |       | |GpuDimShuffle{0,x} [id IB] <CudaNdarrayType(float32, col)> ''   \n |       | | |GpuSubtensor{::, int64} [id IC] <CudaNdarrayType(float32, vector)> ''   \n |       | |   |GpuFromHost [id FB] <CudaNdarrayType(float32, matrix)> ''   \n |       | |   |Constant{0} [id HP] <int64>\n |       | |GpuDimShuffle{0,x} [id ID] <CudaNdarrayType(float32, col)> ''   \n |       |   |GpuSubtensor{::, int64} [id IE] <CudaNdarrayType(float32, vector)> ''   \n |       |     |GpuFromHost [id FB] <CudaNdarrayType(float32, matrix)> ''   \n |       |     |Constant{1} [id BT] <int64>\n |       |GpuElemwise{mul,no_inplace} [id IF] <CudaNdarrayType(float32, col)> ''   \n |       | |GpuDimShuffle{0,x} [id IB] <CudaNdarrayType(float32, col)> ''   \n |       | |GpuDimShuffle{0,x} [id IG] <CudaNdarrayType(float32, col)> ''   \n |       |   |GpuSubtensor{::, int64} [id IH] <CudaNdarrayType(float32, vector)> ''   \n |       |     |GpuFromHost [id FB] <CudaNdarrayType(float32, matrix)> ''   \n |       |     |Constant{2} [id HV] <int64>\n |       |GpuElemwise{mul,no_inplace} [id II] <CudaNdarrayType(float32, col)> ''   \n |         |GpuDimShuffle{0,x} [id ID] <CudaNdarrayType(float32, col)> ''   \n |         |GpuDimShuffle{0,x} [id IG] <CudaNdarrayType(float32, col)> ''   \n |GpuIncSubtensor{InplaceSet;:int64:} [id IJ] <CudaNdarrayType(float32, vector)> ''   \n | |GpuReshape{1} [id IK] <CudaNdarrayType(float32, vector)> ''   \n | | |GpuAlloc [id IL] <CudaNdarrayType(float32, row)> ''   \n | | | |GpuDimShuffle{0,x} [id IM] <CudaNdarrayType(float32, (True, True))> ''   \n | | | | |Rebroadcast{1} [id IN] <CudaNdarrayType(float32, (True,))> ''   \n | | | |   |GpuReshape{1} [id IO] <CudaNdarrayType(float32, vector)> ''   \n | | | |     |<CudaNdarrayType(float32, scalar)> [id FK] <CudaNdarrayType(float32, scalar)>\n | | | |     |TensorConstant{(1,) of -1} [id IP] <TensorType(int64, (True,))>\n | | | |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n | | | |TensorConstant{9} [id IQ] <TensorType(int8, scalar)>\n | | |TensorConstant{(1,) of 9} [id IR] <TensorType(int64, vector)>\n | |CudaNdarrayConstant{1.0} [id IS] <CudaNdarrayType(float32, scalar)>\n | |Constant{3} [id IT] <int64>\n |Subtensor{int64:int64:int8} [id IU] <TensorType(int64, vector)> ''   \n | |CumOp{None, add} [id IV] <TensorType(int64, vector)> ''   \n | | |Join [id IW] <TensorType(int64, vector)> ''   \n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |TensorConstant{(1,) of 0} [id IX] <TensorType(int8, vector)>\n | |   |<TensorType(int64, vector)> [id HE] <TensorType(int64, vector)>\n | |ScalarFromTensor [id IY] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}} [id IZ] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{le,no_inplace} [id JA] <TensorType(bool, scalar)> ''   \n | |   | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}[(0, 2)] [id JB] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{lt,no_inplace} [id JC] <TensorType(bool, scalar)> ''   \n | |   | | | |Elemwise{minimum,no_inplace} [id GY] <TensorType(int64, scalar)> ''   \n | |   | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |Elemwise{minimum,no_inplace} [id GY] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{sub,no_inplace} [id HF] <TensorType(int64, scalar)> ''   \n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id HG] <TensorType(int64, scalar)> ''   \n | |   |Prod{axis=None, dtype='int64', acc_dtype='int64'} [id HA] <TensorType(int64, scalar)> ''   \n | |ScalarFromTensor [id JD] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum((i2 + i3), i4))}}[(0, 2)] [id JE] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{le,no_inplace} [id JA] <TensorType(bool, scalar)> ''   \n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id HG] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}[(0, 2)] [id JB] <TensorType(int64, scalar)> ''   \n | |   |Prod{axis=None, dtype='int64', acc_dtype='int64'} [id HA] <TensorType(int64, scalar)> ''   \n | |Constant{1} [id JF] <int8>\n |Subtensor{int64:int64:int8} [id JG] <TensorType(int64, vector)> ''   \n   |CumOp{None, add} [id IV] <TensorType(int64, vector)> ''   \n   |ScalarFromTensor [id JH] <int64> ''   \n   | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 3)] [id JI] <TensorType(int64, scalar)> ''   \n   |   |Elemwise{le,no_inplace} [id JJ] <TensorType(bool, scalar)> ''   \n   |   | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id JK] <TensorType(int64, scalar)> ''   \n   |   | | |Elemwise{lt,no_inplace} [id JC] <TensorType(bool, scalar)> ''   \n   |   | | |Elemwise{minimum,no_inplace} [id GY] <TensorType(int64, scalar)> ''   \n   |   | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id GZ] <TensorType(int64, scalar)> ''   \n   |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n   |   | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n   |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n   |   |TensorConstant{0} [id CD] <TensorType(int64, scalar)>\n   |   |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id GZ] <TensorType(int64, scalar)> ''   \n   |ScalarFromTensor [id JL] <int64> ''   \n   | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id JM] <TensorType(int64, scalar)> ''   \n   |   |Elemwise{le,no_inplace} [id JJ] <TensorType(bool, scalar)> ''   \n   |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n   |   |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id JK] <TensorType(int64, scalar)> ''   \n   |   |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id GZ] <TensorType(int64, scalar)> ''   \n   |Constant{1} [id JF] <int8>\nforall_inplace,gpu,scan_fn}.1 [id A] <CudaNdarrayType(float32, matrix)> ''   \n\nInner graphs of the scan ops:\n\nforall_inplace,gpu,scan_fn}.0 [id A] <CudaNdarrayType(float32, 3D)> ''   \n >GpuFromHost [id JN] <CudaNdarrayType(float32, matrix)> ''   \n > |AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True} [id JO] <TensorType(float32, matrix)> ''   \n >   |AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True} [id JP] <TensorType(float32, matrix)> ''   \n >   | |HostFromGpu [id JQ] <TensorType(float32, matrix)> ''   \n >   | | |<CudaNdarrayType(float32, matrix)> [id JR] <CudaNdarrayType(float32, matrix)> -> [id EH]\n >   | |Subtensor{:int64:} [id JS] <TensorType(int64, vector)> ''   \n >   | | |Sum{axis=[0], acc_dtype=int64} [id JT] <TensorType(int64, vector)> 'The chunk of block model of a specific series'   \n >   | | |<int64> [id JU] <int64> -> [id GQ]\n >   | |TensorConstant{0} [id JV] <TensorType(int64, scalar)>\n >   | |Subtensor{int64} [id JW] <TensorType(int64, vector)> ''   \n >   |   |Nonzero [id JX] <TensorType(int64, matrix)> ''   \n >   |   | |Elemwise{Cast{int8}} [id JY] <TensorType(int8, vector)> ''   \n >   |   |   |Elemwise{eq,no_inplace} [id JZ] <TensorType(bool, vector)> 'Yet simulated LITHOLOGY node'   \n >   |   |Constant{0} [id KA] <int64>\n >   |HostFromGpu [id KB] <TensorType(float32, vector)> ''   \n >   | |GpuSubtensor{:int64:} [id KC] <CudaNdarrayType(float32, vector)> ''   \n >   |   |GpuElemwise{Composite{((((i0 * i1 * i2 * i3) + (-i4)) + i5) + i6)}}[(0, 3)] [id KD] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |CudaNdarrayConstant{[-1.]} [id KE] <CudaNdarrayType(float32, (True,))>\n >   |   | |GpuDimShuffle{x} [id KF] <CudaNdarrayType(float32, (True,))> ''   \n >   |   | | |<CudaNdarrayType(float32, (True, True))> [id KG] <CudaNdarrayType(float32, (True, True))> -> [id FL]\n >   |   | |GpuDimShuffle{x} [id KH] <CudaNdarrayType(float32, (True,))> ''   \n >   |   | | |<CudaNdarrayType(float32, (True, True))> [id KI] <CudaNdarrayType(float32, (True, True))> -> [id GC]\n >   |   | |GpuCAReduce{add}{1,0} [id KJ] <CudaNdarrayType(float32, vector)> ''   \n >   |   | | |GpuElemwise{Composite{(i0 * i1 * i2 * (((i3 + (i4 / i5)) - ((i6 * i7) / i8)) + ((i9 * i10) / i11)))}}[(0, 0)] [id KK] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   |GpuFromHost [id KL] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |Subtensor{:int64:} [id KM] <TensorType(float32, matrix)> ''   \n >   |   | |   |   |InplaceDimShuffle{1,0} [id KN] <TensorType(float32, matrix)> ''   \n >   |   | |   |   | |Reshape{2} [id KO] <TensorType(float32, matrix)> ''   \n >   |   | |   |   |   |Alloc [id KP] <TensorType(float32, (False, True, True, False))> ''   \n >   |   | |   |   |   | |Reshape{1} [id KQ] <TensorType(float32, vector)> 'Dual Kriging parameters'   \n >   |   | |   |   |   | |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id KR] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   | | |Shape_i{1} [id KS] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   | | | |Nonzero [id KT] <TensorType(int64, matrix)> ''   \n >   |   | |   |   |   | | |   |HostFromGpu [id KU] <TensorType(float32, vector)> ''   \n >   |   | |   |   |   | | |     |GpuReshape{1} [id KV] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   |   |   | | |       |GpuElemwise{mul,no_inplace} [id KW] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   |   |   | | |       | |Coordinates of the grid points to interpolate_copy[cuda] [id KX] <CudaNdarrayType(float32, matrix)> -> [id BB]\n >   |   | |   |   |   | | |       | |GpuFromHost [id KY] <CudaNdarrayType(float32, col)> ''   \n >   |   | |   |   |   | | |       |   |Elemwise{Cast{float32}} [id KZ] <TensorType(float32, col)> ''   \n >   |   | |   |   |   | | |       |     |InplaceDimShuffle{0,x} [id LA] <TensorType(bool, col)> ''   \n >   |   | |   |   |   | | |       |       |Elemwise{eq,no_inplace} [id JZ] <TensorType(bool, vector)> 'Yet simulated LITHOLOGY node'   \n >   |   | |   |   |   | | |       |TensorConstant{(1,) of -1} [id LB] <TensorType(int64, (True,))>\n >   |   | |   |   |   | | |TensorConstant{3} [id LC] <TensorType(int64, scalar)>\n >   |   | |   |   |   | | |Shape_i{0} [id LD] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   | | | |Rest of the points of the layers_copy[cuda] [id LE] <CudaNdarrayType(float32, matrix)> -> [id FA]\n >   |   | |   |   |   | | |Shape_i{0} [id LF] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   | |   |Reference points for every layer_copy[cuda] [id LG] <CudaNdarrayType(float32, matrix)> -> [id FB]\n >   |   | |   |   |   | |TensorConstant{1} [id LH] <TensorType(int8, scalar)>\n >   |   | |   |   |   | |TensorConstant{1} [id LH] <TensorType(int8, scalar)>\n >   |   | |   |   |   | |Elemwise{add,no_inplace} [id LI] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   |Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i3 * i4) // (i5 * i3 * i4)), i0)}}[(0, 0)] [id LJ] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | |Elemwise{mul,no_inplace} [id LK] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | | |TensorConstant{3} [id LC] <TensorType(int64, scalar)>\n >   |   | |   |   |   |   | | |Elemwise{sub,no_inplace} [id LL] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id LM] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | |   | |Elemwise{lt,no_inplace} [id LN] <TensorType(bool, scalar)> ''   \n >   |   | |   |   |   |   | |   | | |<TensorType(int64, scalar)> [id LO] <TensorType(int64, scalar)> -> [id CT]\n >   |   | |   |   |   |   | |   | | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   | |   | |<TensorType(int64, scalar)> [id LO] <TensorType(int64, scalar)> -> [id CT]\n >   |   | |   |   |   |   | |   | |Shape_i{0} [id LQ] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | |   | | |Position of the dips_copy[cuda] [id LR] <CudaNdarrayType(float32, matrix)> -> [id EY]\n >   |   | |   |   |   |   | |   | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   | |   | |TensorConstant{-1} [id LS] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4)}}[(0, 2)] [id LT] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | |     |Elemwise{lt,no_inplace} [id LU] <TensorType(bool, scalar)> ''   \n >   |   | |   |   |   |   | |     | |<TensorType(int64, scalar)> [id LV] <TensorType(int64, scalar)> -> [id CJ]\n >   |   | |   |   |   |   | |     | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   | |     |<TensorType(int64, scalar)> [id LV] <TensorType(int64, scalar)> -> [id CJ]\n >   |   | |   |   |   |   | |     |Shape_i{0} [id LQ] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | |     |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   | |     |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id LM] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | |TensorConstant{-1} [id LS] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   | |TensorConstant{3} [id LC] <TensorType(int64, scalar)>\n >   |   | |   |   |   |   | |Elemwise{sub,no_inplace} [id LL] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | |Shape_i{1} [id LW] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | | |Position of the dips_copy[cuda] [id LR] <CudaNdarrayType(float32, matrix)> -> [id EY]\n >   |   | |   |   |   |   | |TensorConstant{-3} [id LX] <TensorType(int64, scalar)>\n >   |   | |   |   |   |   |Elemwise{sub,no_inplace} [id LY] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id LZ] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | | |Elemwise{lt,no_inplace} [id MA] <TensorType(bool, scalar)> ''   \n >   |   | |   |   |   |   | | | |<TensorType(int64, scalar)> [id MB] <TensorType(int64, scalar)> -> [id BH]\n >   |   | |   |   |   |   | | | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   | | |<TensorType(int64, scalar)> [id MB] <TensorType(int64, scalar)> -> [id BH]\n >   |   | |   |   |   |   | | |Shape_i{0} [id LD] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   | | |TensorConstant{-1} [id LS] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4)}}[(0, 2)] [id MC] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   |   |Elemwise{lt,no_inplace} [id MD] <TensorType(bool, scalar)> ''   \n >   |   | |   |   |   |   |   | |<TensorType(int64, scalar)> [id ME] <TensorType(int64, scalar)> -> [id BV]\n >   |   | |   |   |   |   |   | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   |   |<TensorType(int64, scalar)> [id ME] <TensorType(int64, scalar)> -> [id BV]\n >   |   | |   |   |   |   |   |Shape_i{0} [id LD] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   |   |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id LZ] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   |<TensorType(int64, scalar)> [id MF] <TensorType(int64, scalar)> -> [id DX]\n >   |   | |   |   |   |MakeVector{dtype='int64'} [id MG] <TensorType(int64, vector)> ''   \n >   |   | |   |   |     |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id KR] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |     |Elemwise{add,no_inplace} [id LI] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |ScalarFromTensor [id MH] <int64> ''   \n >   |   | |   |     |Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i3 * i4) // (i5 * i3 * i4)), i0)}}[(0, 0)] [id LJ] <TensorType(int64, scalar)> ''   \n >   |   | |   |GpuJoin [id MI] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   | |GpuElemwise{sub,no_inplace} [id MJ] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |GpuDimShuffle{0,x} [id MK] <CudaNdarrayType(float32, col)> ''   \n >   |   | |   | | | |GpuSubtensor{int64:int64:int8, int64} [id ML] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | | |   |Position of the dips_copy[cuda] [id LR] <CudaNdarrayType(float32, matrix)> -> [id EY]\n >   |   | |   | | |   |ScalarFromTensor [id MM] <int64> ''   \n >   |   | |   | | |   | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id MN] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |   |   |Elemwise{le,no_inplace} [id MO] <TensorType(bool, scalar)> ''   \n >   |   | |   | | |   |   | |Elemwise{sub,no_inplace} [id LL] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |   |   | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   | | |   |   |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   | | |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4)}}[(0, 2)] [id LT] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id LM] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |   |ScalarFromTensor [id MP] <int64> ''   \n >   |   | |   | | |   | |Elemwise{Switch}[(0, 2)] [id MQ] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |   |   |Elemwise{le,no_inplace} [id MO] <TensorType(bool, scalar)> ''   \n >   |   | |   | | |   |   |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   | | |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id LM] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |   |Constant{1} [id MR] <int8>\n >   |   | |   | | |   |Constant{0} [id KA] <int64>\n >   |   | |   | | |GpuDimShuffle{x,0} [id MS] <CudaNdarrayType(float32, row)> ''   \n >   |   | |   | |   |GpuSubtensor{::, int64} [id MT] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | |     |GpuJoin [id MU] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |     | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   | |     | |GpuJoin [id MV] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |     | | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   | |     | | |GpuReshape{2} [id MW] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |     | | | |GpuAdvancedSubtensor1 [id MX] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | |     | | | | |GpuReshape{1} [id KV] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | |     | | | | |Subtensor{int64} [id MY] <TensorType(int64, vector)> ''   \n >   |   | |   | |     | | | |   |Nonzero [id KT] <TensorType(int64, matrix)> ''   \n >   |   | |   | |     | | | |   |Constant{0} [id KA] <int64>\n >   |   | |   | |     | | | |TensorConstant{[-1  3]} [id MZ] <TensorType(int64, vector)>\n >   |   | |   | |     | | |Rest of the points of the layers_copy[cuda] [id LE] <CudaNdarrayType(float32, matrix)> -> [id FA]\n >   |   | |   | |     | |Reference points for every layer_copy[cuda] [id LG] <CudaNdarrayType(float32, matrix)> -> [id FB]\n >   |   | |   | |     |Constant{0} [id KA] <int64>\n >   |   | |   | |GpuElemwise{sub,no_inplace} [id NA] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |GpuDimShuffle{0,x} [id NB] <CudaNdarrayType(float32, col)> ''   \n >   |   | |   | | | |GpuSubtensor{int64:int64:int8, int64} [id NC] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | | |   |Position of the dips_copy[cuda] [id LR] <CudaNdarrayType(float32, matrix)> -> [id EY]\n >   |   | |   | | |   |ScalarFromTensor [id MM] <int64> ''   \n >   |   | |   | | |   |ScalarFromTensor [id MP] <int64> ''   \n >   |   | |   | | |   |Constant{1} [id MR] <int8>\n >   |   | |   | | |   |Constant{1} [id ND] <int64>\n >   |   | |   | | |GpuDimShuffle{x,0} [id NE] <CudaNdarrayType(float32, row)> ''   \n >   |   | |   | |   |GpuSubtensor{::, int64} [id NF] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | |     |GpuJoin [id MU] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |     |Constant{1} [id ND] <int64>\n >   |   | |   | |GpuElemwise{sub,no_inplace} [id NG] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   |   |GpuDimShuffle{0,x} [id NH] <CudaNdarrayType(float32, col)> ''   \n >   |   | |   |   | |GpuSubtensor{int64:int64:int8, int64} [id NI] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   |   |   |Position of the dips_copy[cuda] [id LR] <CudaNdarrayType(float32, matrix)> -> [id EY]\n >   |   | |   |   |   |ScalarFromTensor [id MM] <int64> ''   \n >   |   | |   |   |   |ScalarFromTensor [id MP] <int64> ''   \n >   |   | |   |   |   |Constant{1} [id MR] <int8>\n >   |   | |   |   |   |Constant{2} [id NJ] <int64>\n >   |   | |   |   |GpuDimShuffle{x,0} [id NK] <CudaNdarrayType(float32, row)> ''   \n >   |   | |   |     |GpuSubtensor{::, int64} [id NL] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   |       |GpuJoin [id MU] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   |       |Constant{2} [id NJ] <int64>\n >   |   | |   |GpuElemwise{Composite{Cast{float32}(LT(i0, i1))},no_inplace} [id NM] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id NN] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |GpuDimShuffle{0,x} [id NO] <CudaNdarrayType(float32, col)> ''   \n >   |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id NP] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | | |   |GpuReshape{2} [id NQ] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |     |GpuAlloc [id NR] <CudaNdarrayType(float32, (False, True, False, False))> ''   \n >   |   | |   | | |     | |GpuSubtensor{int64:int64:} [id NS] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |     | | |Position of the dips_copy[cuda] [id LR] <CudaNdarrayType(float32, matrix)> -> [id EY]\n >   |   | |   | | |     | | |ScalarFromTensor [id NT] <int64> ''   \n >   |   | |   | | |     | | | |<TensorType(int64, scalar)> [id LV] <TensorType(int64, scalar)> -> [id CJ]\n >   |   | |   | | |     | | |ScalarFromTensor [id NU] <int64> ''   \n >   |   | |   | | |     | |   |<TensorType(int64, scalar)> [id LO] <TensorType(int64, scalar)> -> [id CT]\n >   |   | |   | | |     | |TensorConstant{3} [id NV] <TensorType(int8, scalar)>\n >   |   | |   | | |     | |TensorConstant{1} [id LH] <TensorType(int8, scalar)>\n >   |   | |   | | |     | |Elemwise{sub,no_inplace} [id LL] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |     | |Shape_i{1} [id LW] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |     |MakeVector{dtype='int64'} [id NW] <TensorType(int64, vector)> ''   \n >   |   | |   | | |       |Elemwise{mul,no_inplace} [id LK] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |       |Shape_i{1} [id LW] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |GpuDimShuffle{x,0} [id NX] <CudaNdarrayType(float32, row)> ''   \n >   |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id NY] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | | |   |GpuJoin [id MU] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |GpuDot22Scalar [id NZ] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | |GpuReshape{2} [id NQ] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | |GpuDimShuffle{1,0} [id OA] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | | |GpuJoin [id MU] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | |TensorConstant{2.0} [id OB] <TensorType(float32, scalar)>\n >   |   | |   | | |CudaNdarrayConstant{[[ 0.]]} [id OC] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |<CudaNdarrayType(float32, (True, True))> [id OD] <CudaNdarrayType(float32, (True, True))> -> [id FM]\n >   |   | |   |<CudaNdarrayType(float32, (True, True))> [id OE] <CudaNdarrayType(float32, (True, True))> -> [id GD]\n >   |   | |   |GpuElemwise{mul,no_inplace} [id OF] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 26.25]]} [id OG] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id NN] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   |<CudaNdarrayType(float32, (True, True))> [id OH] <CudaNdarrayType(float32, (True, True))> -> [id FV]\n >   |   | |   |CudaNdarrayConstant{[[ 17.5]]} [id OI] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |GpuElemwise{pow,no_inplace} [id OJ] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id NN] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 3.]]} [id OK] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |<CudaNdarrayType(float32, (True, True))> [id OL] <CudaNdarrayType(float32, (True, True))> -> [id FX]\n >   |   | |   |CudaNdarrayConstant{[[ 5.25]]} [id OM] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |GpuElemwise{Pow}[(0, 0)] [id ON] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id NN] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 5.]]} [id OO] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |<CudaNdarrayType(float32, (True, True))> [id OP] <CudaNdarrayType(float32, (True, True))> -> [id FT]\n >   |   | |GpuCAReduce{add}{1,0} [id OQ] <CudaNdarrayType(float32, vector)> ''   \n >   |   | | |GpuElemwise{Composite{(i0 * (i1 * ((i2 * ((i3 + i4 + i5) - (i6 + i7))) - (i8 * ((i3 + i9 + i10) - i11)))))}}[(0, 2)] [id OR] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   |GpuSubtensor{int64:int64:} [id OS] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |GpuDimShuffle{1,0} [id OT] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |GpuReshape{2} [id OU] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |   |GpuFromHost [id OV] <CudaNdarrayType(float32, (False, True, True, False))> ''   \n >   |   | |   | |   | |Alloc [id KP] <TensorType(float32, (False, True, True, False))> ''   \n >   |   | |   | |   |MakeVector{dtype='int64'} [id MG] <TensorType(int64, vector)> ''   \n >   |   | |   | |ScalarFromTensor [id MH] <int64> ''   \n >   |   | |   | |ScalarFromTensor [id OW] <int64> ''   \n >   |   | |   |   |Elemwise{add,no_inplace} [id OX] <TensorType(int64, scalar)> ''   \n >   |   | |   |     |Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i3 * i4) // (i5 * i3 * i4)), i0)}}[(0, 0)] [id LJ] <TensorType(int64, scalar)> ''   \n >   |   | |   |     |Elemwise{sub,no_inplace} [id LY] <TensorType(int64, scalar)> ''   \n >   |   | |   |<CudaNdarrayType(float32, (True, True))> [id OY] <CudaNdarrayType(float32, (True, True))> -> [id FZ]\n >   |   | |   |GpuElemwise{Composite{Cast{float32}(LT(i0, i1))},no_inplace} [id OZ] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id PA] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |GpuDimShuffle{0,x} [id PB] <CudaNdarrayType(float32, col)> ''   \n >   |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id PC] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | | |   |GpuSubtensor{int64:int64:} [id PD] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |     |Rest of the points of the layers_copy[cuda] [id LE] <CudaNdarrayType(float32, matrix)> -> [id FA]\n >   |   | |   | | |     |ScalarFromTensor [id PE] <int64> ''   \n >   |   | |   | | |     | |<TensorType(int64, scalar)> [id ME] <TensorType(int64, scalar)> -> [id BV]\n >   |   | |   | | |     |ScalarFromTensor [id PF] <int64> ''   \n >   |   | |   | | |       |<TensorType(int64, scalar)> [id MB] <TensorType(int64, scalar)> -> [id BH]\n >   |   | |   | | |GpuDimShuffle{x,0} [id NX] <CudaNdarrayType(float32, row)> ''   \n >   |   | |   | | |GpuDot22Scalar [id PG] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | |GpuSubtensor{int64:int64:} [id PD] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | |GpuDimShuffle{1,0} [id OA] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | |TensorConstant{2.0} [id OB] <TensorType(float32, scalar)>\n >   |   | |   | | |CudaNdarrayConstant{[[ 0.]]} [id OC] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |<CudaNdarrayType(float32, (True, True))> [id OD] <CudaNdarrayType(float32, (True, True))> -> [id FM]\n >   |   | |   |CudaNdarrayConstant{[[ 1.]]} [id PH] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id PI] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 8.75]]} [id PJ] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id PK] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id PA] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |<CudaNdarrayType(float32, (True, True))> [id OD] <CudaNdarrayType(float32, (True, True))> -> [id FM]\n >   |   | |   | |CudaNdarrayConstant{[[ 3.]]} [id OK] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id PL] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 0.75]]} [id PM] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id PK] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 7.]]} [id PN] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace} [id PO] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 7.]]} [id PN] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id PK] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))}}[(0, 1)] [id PP] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 3.5]]} [id PQ] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id PK] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 5.]]} [id OO] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |GpuElemwise{Composite{Cast{float32}(LT(i0, i1))},no_inplace} [id PR] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id PS] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |GpuDimShuffle{0,x} [id PT] <CudaNdarrayType(float32, col)> ''   \n >   |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id PU] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | | |   |GpuSubtensor{int64:int64:} [id PV] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |     |Reference points for every layer_copy[cuda] [id LG] <CudaNdarrayType(float32, matrix)> -> [id FB]\n >   |   | |   | | |     |ScalarFromTensor [id PE] <int64> ''   \n >   |   | |   | | |     |ScalarFromTensor [id PF] <int64> ''   \n >   |   | |   | | |GpuDimShuffle{x,0} [id NX] <CudaNdarrayType(float32, row)> ''   \n >   |   | |   | | |GpuDot22Scalar [id PW] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | |GpuSubtensor{int64:int64:} [id PV] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | |GpuDimShuffle{1,0} [id OA] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | |TensorConstant{2.0} [id OB] <TensorType(float32, scalar)>\n >   |   | |   | | |CudaNdarrayConstant{[[ 0.]]} [id OC] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |<CudaNdarrayType(float32, (True, True))> [id OD] <CudaNdarrayType(float32, (True, True))> -> [id FM]\n >   |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id PX] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 8.75]]} [id PJ] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id PY] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id PS] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |<CudaNdarrayType(float32, (True, True))> [id OD] <CudaNdarrayType(float32, (True, True))> -> [id FM]\n >   |   | |   | |CudaNdarrayConstant{[[ 3.]]} [id OK] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id PZ] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 0.75]]} [id PM] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id PY] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 7.]]} [id PN] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |GpuElemwise{Composite{((i0 * sqr(i1)) + (i2 * (i1 ** i3)))}}[(0, 1)] [id QA] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |     |CudaNdarrayConstant{[[ 7.]]} [id PN] <CudaNdarrayType(float32, (True, True))>\n >   |   | |     |GpuElemwise{TrueDiv}[(0, 0)] [id PY] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |     |CudaNdarrayConstant{[[ 3.5]]} [id PQ] <CudaNdarrayType(float32, (True, True))>\n >   |   | |     |CudaNdarrayConstant{[[ 5.]]} [id OO] <CudaNdarrayType(float32, (True, True))>\n >   |   | |GpuCAReduce{add}{1,0} [id QB] <CudaNdarrayType(float32, vector)> ''   \n >   |   | | |GpuElemwise{Composite{(((i0 * i1) * i2) * i3)}}[(0, 2)] [id QC] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   |GpuSubtensor{int64:int64:} [id QD] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |GpuDimShuffle{1,0} [id OT] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |ScalarFromTensor [id OW] <int64> ''   \n >   |   | |   | |ScalarFromTensor [id QE] <int64> ''   \n >   |   | |   |   |Elemwise{Add}[(0, 0)] [id QF] <TensorType(int64, scalar)> ''   \n >   |   | |   |     |Elemwise{add,no_inplace} [id OX] <TensorType(int64, scalar)> ''   \n >   |   | |   |     |<TensorType(int64, scalar)> [id MF] <TensorType(int64, scalar)> -> [id DX]\n >   |   | |   |<CudaNdarrayType(float32, (True, True))> [id KG] <CudaNdarrayType(float32, (True, True))> -> [id FL]\n >   |   | |   |GpuDimShuffle{1,0} [id QG] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |GpuReshape{2} [id QH] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   |   |GpuAlloc [id QI] <CudaNdarrayType(float32, (False, True, True, False))> ''   \n >   |   | |   |   | |GpuSubtensor{:int64:} [id QJ] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   |   | | |<CudaNdarrayType(float32, vector)> [id QK] <CudaNdarrayType(float32, vector)> -> [id IJ]\n >   |   | |   |   | | |ScalarFromTensor [id QL] <int64> ''   \n >   |   | |   |   | |   |<TensorType(int64, scalar)> [id MF] <TensorType(int64, scalar)> -> [id DX]\n >   |   | |   |   | |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id KR] <TensorType(int64, scalar)> ''   \n >   |   | |   |   | |TensorConstant{1} [id LH] <TensorType(int8, scalar)>\n >   |   | |   |   | |TensorConstant{1} [id LH] <TensorType(int8, scalar)>\n >   |   | |   |   | |Elemwise{Composite{Switch(LT(i0, i1), Switch(LT((i0 + i2), i1), i1, (i0 + i2)), Switch(LT(i0, i2), i0, i2))}}[(0, 2)] [id QM] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |<TensorType(int64, scalar)> [id MF] <TensorType(int64, scalar)> -> [id DX]\n >   |   | |   |   |   |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   |   |   |Shape_i{0} [id QN] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |     |<CudaNdarrayType(float32, vector)> [id QK] <CudaNdarrayType(float32, vector)> -> [id IJ]\n >   |   | |   |   |MakeVector{dtype='int64'} [id QO] <TensorType(int64, vector)> ''   \n >   |   | |   |     |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id KR] <TensorType(int64, scalar)> ''   \n >   |   | |   |     |Elemwise{Composite{Switch(LT(i0, i1), Switch(LT((i0 + i2), i1), i1, (i0 + i2)), Switch(LT(i0, i2), i0, i2))}}[(0, 2)] [id QM] <TensorType(int64, scalar)> ''   \n >   |   | |   |GpuSubtensor{:int64:} [id QP] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |     |GpuJoin [id QQ] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |     | |TensorConstant{1} [id LH] <TensorType(int8, scalar)>\n >   |   | |     | |GpuReshape{2} [id QR] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |     | | |GpuAdvancedSubtensor1 [id QS] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |     | | | |GpuReshape{1} [id QT] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |     | | | | |GpuElemwise{mul,no_inplace} [id QU] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |     | | | | | |<CudaNdarrayType(float32, matrix)> [id QV] <CudaNdarrayType(float32, matrix)> -> [id EV]\n >   |   | |     | | | | | |GpuFromHost [id QW] <CudaNdarrayType(float32, row)> ''   \n >   |   | |     | | | | |   |Elemwise{Cast{float32}} [id QX] <TensorType(float32, row)> ''   \n >   |   | |     | | | | |     |InplaceDimShuffle{x,0} [id QY] <TensorType(bool, row)> ''   \n >   |   | |     | | | | |       |Elemwise{eq,no_inplace} [id JZ] <TensorType(bool, vector)> 'Yet simulated LITHOLOGY node'   \n >   |   | |     | | | | |TensorConstant{(1,) of -1} [id LB] <TensorType(int64, (True,))>\n >   |   | |     | | | |Subtensor{int64} [id QZ] <TensorType(int64, vector)> ''   \n >   |   | |     | | |   |Nonzero [id RA] <TensorType(int64, matrix)> ''   \n >   |   | |     | | |   | |HostFromGpu [id RB] <TensorType(float32, vector)> ''   \n >   |   | |     | | |   |   |GpuReshape{1} [id QT] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |     | | |   |Constant{0} [id KA] <int64>\n >   |   | |     | | |TensorConstant{[ 9 -1]} [id RC] <TensorType(int64, vector)>\n >   |   | |     | |<CudaNdarrayType(float32, matrix)> [id RD] <CudaNdarrayType(float32, matrix)> -> [id HH]\n >   |   | |     |ScalarFromTensor [id QL] <int64> ''   \n >   |   | |GpuCAReduce{add}{1,0} [id RE] <CudaNdarrayType(float32, vector)> ''   \n >   |   |   |GpuElemwise{Mul}[(0, 0)] [id RF] <CudaNdarrayType(float32, matrix)> ''   \n >   |   |     |GpuSubtensor{int64::} [id RG] <CudaNdarrayType(float32, matrix)> ''   \n >   |   |     | |GpuDimShuffle{1,0} [id OT] <CudaNdarrayType(float32, matrix)> ''   \n >   |   |     | |ScalarFromTensor [id QE] <int64> ''   \n >   |   |     |GpuSubtensor{::, :int64:} [id RH] <CudaNdarrayType(float32, matrix)> ''   \n >   |   |       |<CudaNdarrayType(float32, matrix)> [id RI] <CudaNdarrayType(float32, matrix)> -> [id GW]\n >   |   |       |ScalarFromTensor [id RJ] <int64> ''   \n >   |   |         |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id KR] <TensorType(int64, scalar)> ''   \n >   |   |<int64> [id JU] <int64> -> [id GQ]\n >   |TensorConstant{1} [id RK] <TensorType(int64, scalar)>\n >   |Subtensor{int64} [id JW] <TensorType(int64, vector)> ''   \n >GpuAdvancedIncSubtensor1{no_inplace,set} [id RL] <CudaNdarrayType(float32, vector)> ''   \n > |<CudaNdarrayType(float32, vector)> [id RM] <CudaNdarrayType(float32, vector)> -> [id EX]\n > |GpuAdvancedSubtensor1 [id RN] <CudaNdarrayType(float32, vector)> ''   \n > | |for{gpu,scan_fn} [id RO] <CudaNdarrayType(float32, vector)> ''   \n > | | |<TensorType(int64, scalar)> [id RP] <TensorType(int64, scalar)> -> [id GY]\n > | | |Elemwise{Cast{int32}} [id RQ] <TensorType(int32, vector)> ''   \n > | | | |<TensorType(int64, vector)> [id RR] <TensorType(int64, vector)> -> [id JG]\n > | | |Elemwise{Cast{int32}} [id RS] <TensorType(int32, vector)> ''   \n > | | | |<TensorType(int64, vector)> [id RT] <TensorType(int64, vector)> -> [id IU]\n > | | |GpuFromHost [id RU] <CudaNdarrayType(float32, vector)> ''   \n > | | | |Elemwise{Composite{Cast{float32}((i0 - i1))}} [id RV] <TensorType(float32, vector)> ''   \n > | | |   |<TensorType(int64, vector)> [id RT] <TensorType(int64, vector)> -> [id IU]\n > | | |   |<TensorType(int64, vector)> [id RR] <TensorType(int64, vector)> -> [id JG]\n > | | |<TensorType(int64, scalar)> [id RP] <TensorType(int64, scalar)> -> [id GY]\n > | | |GpuSubtensor{int64:int64:} [id RW] <CudaNdarrayType(float32, vector)> ''   \n > | |   |GpuElemwise{Composite{((((i0 * i1 * i2 * i3) + (-i4)) + i5) + i6)}}[(0, 3)] [id KD] <CudaNdarrayType(float32, vector)> ''   \n > | |   |<int64> [id JU] <int64> -> [id GQ]\n > | |   |<int64> [id RX] <int64> -> [id GO]\n > | |Elemwise{add,no_inplace} [id RY] <TensorType(int64, vector)> ''   \n > |   |TensorConstant{(1,) of -1} [id LB] <TensorType(int64, (True,))>\n > |   |Subtensor{int64:int64:} [id RZ] <TensorType(int64, vector)> ''   \n > |     |Value of the formation_copy [id SA] <TensorType(int64, vector)> -> [id EW]\n > |     |ScalarFromTensor [id SB] <int64> ''   \n > |     | |<TensorType(int64, scalar)> [id SC] <TensorType(int64, scalar)> -> [id DD]\n > |     |ScalarFromTensor [id SD] <int64> ''   \n > |       |<TensorType(int64, scalar)> [id SE] <TensorType(int64, scalar)> -> [id DN]\n > |Elemwise{add,no_inplace} [id RY] <TensorType(int64, vector)> ''   \n\nforall_inplace,gpu,scan_fn}.1 [id A] <CudaNdarrayType(float32, matrix)> ''   \n >GpuFromHost [id JN] <CudaNdarrayType(float32, matrix)> ''   \n >GpuAdvancedIncSubtensor1{no_inplace,set} [id RL] <CudaNdarrayType(float32, vector)> ''   \n\nfor{gpu,scan_fn} [id RO] <CudaNdarrayType(float32, vector)> ''   \n >GpuElemwise{true_div,no_inplace} [id SF] <CudaNdarrayType(float32, scalar)> ''   \n > |GpuCAReduce{add}{1} [id SG] <CudaNdarrayType(float32, scalar)> ''   \n > | |GpuSubtensor{int32:int32:} [id SH] <CudaNdarrayType(float32, vector)> ''   \n > |   |<CudaNdarrayType(float32, vector)> [id SI] <CudaNdarrayType(float32, vector)> -> [id RW]\n > |   |ScalarFromTensor [id SJ] <int32> ''   \n > |   | |<TensorType(int32, scalar)> [id SK] <TensorType(int32, scalar)> -> [id RQ]\n > |   |ScalarFromTensor [id SL] <int32> ''   \n > |     |<TensorType(int32, scalar)> [id SM] <TensorType(int32, scalar)> -> [id RS]\n > |<CudaNdarrayType(float32, scalar)> [id SN] <CudaNdarrayType(float32, scalar)> -> [id RU]\n\nStorage map footprint:\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (9, 125000), ElemSize: 4 Byte(s), TotalSize: 4500000 Byte(s)\n - GpuIncSubtensor{InplaceSet;:int64:}.0, Shape: (2, 3, 125000), ElemSize: 4 Byte(s), TotalSize: 3000000 Byte(s)\n - forall_inplace,gpu,scan_fn}.0, Shape: (2, 3, 125000), ElemSize: 4 Byte(s), TotalSize: 3000000 Byte(s)\n - Coordinates of the grid points to interpolate, Shared Input, Shape: (125000, 3), ElemSize: 4 Byte(s), TotalSize: 1500000 Byte(s)\n - final block of lithologies init, Shared Input, Shape: (1, 125000), ElemSize: 4 Byte(s), TotalSize: 500000 Byte(s)\n - GpuDimShuffle{1,0}.0, Shape: (9, 60), ElemSize: 4 Byte(s), TotalSize: 2160 Byte(s)\n - GpuFromHost.0, Shape: (30, 3), ElemSize: 4 Byte(s), TotalSize: 360 Byte(s)\n - Reference points for every layer, Input, Shape: (30, 3), ElemSize: 4 Byte(s), TotalSize: 360 Byte(s)\n - GpuFromHost.0, Shape: (30, 3), ElemSize: 4 Byte(s), TotalSize: 360 Byte(s)\n - Rest of the points of the layers, Input, Shape: (30, 3), ElemSize: 4 Byte(s), TotalSize: 360 Byte(s)\n - GpuIncSubtensor{InplaceSet;:int64:}.0, Shape: (9,), ElemSize: 4 Byte(s), TotalSize: 36 Byte(s)\n - Subtensor{int64:int64:int8}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - Value of the formation, Shared Input, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - <TensorType(int64, vector)>, Shared Input, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - Subtensor{int64:int64:int8}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (4,), ElemSize: 4 Byte(s), TotalSize: 16 Byte(s)\n - List with the number of formations, Shared Input, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - Length of interfaces in every series, Shared Input, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - Length of foliations in every series, Shared Input, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - GpuFromHost.0, Shape: (1, 3), ElemSize: 4 Byte(s), TotalSize: 12 Byte(s)\n - Position of the dips, Input, Shape: (1, 3), ElemSize: 4 Byte(s), TotalSize: 12 Byte(s)\n - Subtensor{int64:int64:int64}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{maximum,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Subtensor{int64:int64:int64}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Grade of the universal drift, Shared Input, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - TensorConstant{(1,) of 9}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Subtensor{int64:int64:int64}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{minimum,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1,) of 2}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Subtensor{int64:int64:int64}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Subtensor{int64:int64:int64}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - TensorConstant{(1,) of -1}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{3}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Subtensor{int64:int64:int64}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Constant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Subtensor{int64:int64:int64}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Polarity, Input, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{mul,no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{true_div,no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{sqr,no_inplace}.0, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Covariance at 0, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 15.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{mul,no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{mul,no_inplace}.0, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{Mul}[(0, 1)].0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuFromHost.0, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuFromHost.0, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 2.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - Range, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 5.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuDimShuffle{x,x}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuDimShuffle{x,x}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 20.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{pow,no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 4.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuDimShuffle{x,x}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - GpuDimShuffle{x}.0, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{pow,no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{neg,no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Angle of every dip, Input, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{14.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - Azimuth, Input, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 3.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{pow,no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{Composite{(((i0 * i1) / sqr(i2)) + i3)},no_inplace}.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[-14.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[ 2.]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuFromHost.0, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 7.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{mul,no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{9}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{(1,) of 0}, Shape: (1,), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (0, 125060), ElemSize: 4 Byte(s), TotalSize: 0 Byte(s)\n TotalSize: 9504211.0 Byte(s) 0.009 GB\n TotalSize inputs: 6501051.0 Byte(s) 0.006 GB\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/miguel/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-jessie-sid-x86_64-3.5.3-64/scan_perform/mod.cpp:4490)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: One of the index value is out of bound. Error code: 65535.\\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    988\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m--> 989\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    990\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mp\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    977\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m                                                 self, node)\n\u001b[0m\u001b[0;32m    979\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/miguel/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-jessie-sid-x86_64-3.5.3-64/scan_perform/mod.cpp:4606)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/theano/gof/link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/miguel/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-jessie-sid-x86_64-3.5.3-64/scan_perform/mod.cpp:4490)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: One of the index value is out of bound. Error code: 65535.\\n\nApply node that caused the error: GpuAdvancedSubtensor1(for{gpu,scan_fn}.0, Elemwise{add,no_inplace}.0)\nToposort index: 409\nInputs types: [CudaNdarrayType(float32, vector), TensorType(int64, vector)]\nInputs shapes: [(4,), (4,)]\nInputs strides: [(1,), (8,)]\nInputs values: [b'CudaNdarray([ 0.03435151  0.11909181 -0.02655532  0.13297006])', array([0, 1, 2, 4])]\nInputs type_num: ['', 7]\nOutputs clients: [[HostFromGpu(GpuAdvancedSubtensor1.0), GpuAdvancedIncSubtensor1{no_inplace,set}(<CudaNdarrayType(float32, vector)>, GpuAdvancedSubtensor1.0, Elemwise{add,no_inplace}.0)]]\n\nDebugprint of the apply node: \nGpuAdvancedSubtensor1 [id A] <CudaNdarrayType(float32, vector)> ''   \n |for{gpu,scan_fn} [id B] <CudaNdarrayType(float32, vector)> ''   \n | |<TensorType(int64, scalar)> [id C] <TensorType(int64, scalar)>\n | |Elemwise{Cast{int32}} [id D] <TensorType(int32, vector)> ''   \n | | |<TensorType(int64, vector)> [id E] <TensorType(int64, vector)>\n | |Elemwise{Cast{int32}} [id F] <TensorType(int32, vector)> ''   \n | | |<TensorType(int64, vector)> [id G] <TensorType(int64, vector)>\n | |GpuFromHost [id H] <CudaNdarrayType(float32, vector)> ''   \n | | |Elemwise{Composite{Cast{float32}((i0 - i1))}} [id I] <TensorType(float32, vector)> ''   \n | |   |<TensorType(int64, vector)> [id G] <TensorType(int64, vector)>\n | |   |<TensorType(int64, vector)> [id E] <TensorType(int64, vector)>\n | |<TensorType(int64, scalar)> [id C] <TensorType(int64, scalar)>\n | |GpuSubtensor{int64:int64:} [id J] <CudaNdarrayType(float32, vector)> ''   \n |   |GpuElemwise{Composite{((((i0 * i1 * i2 * i3) + (-i4)) + i5) + i6)}}[(0, 3)] [id K] <CudaNdarrayType(float32, vector)> ''   \n |   | |CudaNdarrayConstant{[-1.]} [id L] <CudaNdarrayType(float32, (True,))>\n |   | |GpuDimShuffle{x} [id M] <CudaNdarrayType(float32, (True,))> ''   \n |   | | |<CudaNdarrayType(float32, (True, True))> [id N] <CudaNdarrayType(float32, (True, True))>\n |   | |GpuDimShuffle{x} [id O] <CudaNdarrayType(float32, (True,))> ''   \n |   | | |<CudaNdarrayType(float32, (True, True))> [id P] <CudaNdarrayType(float32, (True, True))>\n |   | |GpuCAReduce{add}{1,0} [id Q] <CudaNdarrayType(float32, vector)> ''   \n |   | | |GpuElemwise{Composite{(i0 * i1 * i2 * (((i3 + (i4 / i5)) - ((i6 * i7) / i8)) + ((i9 * i10) / i11)))}}[(0, 0)] [id R] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |GpuFromHost [id S] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |Subtensor{:int64:} [id T] <TensorType(float32, matrix)> ''   \n |   | |   |   |InplaceDimShuffle{1,0} [id U] <TensorType(float32, matrix)> ''   \n |   | |   |   | |Reshape{2} [id V] <TensorType(float32, matrix)> ''   \n |   | |   |   |   |Alloc [id W] <TensorType(float32, (False, True, True, False))> ''   \n |   | |   |   |   | |Reshape{1} [id X] <TensorType(float32, vector)> 'Dual Kriging parameters'   \n |   | |   |   |   | |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id Y] <TensorType(int64, scalar)> ''   \n |   | |   |   |   | | |Shape_i{1} [id Z] <TensorType(int64, scalar)> ''   \n |   | |   |   |   | | | |Nonzero [id BA] <TensorType(int64, matrix)> ''   \n |   | |   |   |   | | |   |HostFromGpu [id BB] <TensorType(float32, vector)> ''   \n |   | |   |   |   | | |     |GpuReshape{1} [id BC] <CudaNdarrayType(float32, vector)> ''   \n |   | |   |   |   | | |       |GpuElemwise{mul,no_inplace} [id BD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |   |   | | |       | |Coordinates of the grid points to interpolate_copy[cuda] [id BE] <CudaNdarrayType(float32, matrix)>\n |   | |   |   |   | | |       | |GpuFromHost [id BF] <CudaNdarrayType(float32, col)> ''   \n |   | |   |   |   | | |       |   |Elemwise{Cast{float32}} [id BG] <TensorType(float32, col)> ''   \n |   | |   |   |   | | |       |     |InplaceDimShuffle{0,x} [id BH] <TensorType(bool, col)> ''   \n |   | |   |   |   | | |       |       |Elemwise{eq,no_inplace} [id BI] <TensorType(bool, vector)> 'Yet simulated LITHOLOGY node'   \n |   | |   |   |   | | |       |TensorConstant{(1,) of -1} [id BJ] <TensorType(int64, (True,))>\n |   | |   |   |   | | |TensorConstant{3} [id BK] <TensorType(int64, scalar)>\n |   | |   |   |   | | |Shape_i{0} [id BL] <TensorType(int64, scalar)> ''   \n |   | |   |   |   | | | |Rest of the points of the layers_copy[cuda] [id BM] <CudaNdarrayType(float32, matrix)>\n |   | |   |   |   | | |Shape_i{0} [id BN] <TensorType(int64, scalar)> ''   \n |   | |   |   |   | |   |Reference points for every layer_copy[cuda] [id BO] <CudaNdarrayType(float32, matrix)>\n |   | |   |   |   | |TensorConstant{1} [id BP] <TensorType(int8, scalar)>\n |   | |   |   |   | |TensorConstant{1} [id BP] <TensorType(int8, scalar)>\n |   | |   |   |   | |Elemwise{add,no_inplace} [id BQ] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   |Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i3 * i4) // (i5 * i3 * i4)), i0)}}[(0, 0)] [id BR] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |Elemwise{mul,no_inplace} [id BS] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | | |TensorConstant{3} [id BK] <TensorType(int64, scalar)>\n |   | |   |   |   |   | | |Elemwise{sub,no_inplace} [id BT] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id BU] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |   | |Elemwise{lt,no_inplace} [id BV] <TensorType(bool, scalar)> ''   \n |   | |   |   |   |   | |   | | |<TensorType(int64, scalar)> [id BW] <TensorType(int64, scalar)>\n |   | |   |   |   |   | |   | | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |   | |<TensorType(int64, scalar)> [id BW] <TensorType(int64, scalar)>\n |   | |   |   |   |   | |   | |Shape_i{0} [id BY] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |   | | |Position of the dips_copy[cuda] [id BZ] <CudaNdarrayType(float32, matrix)>\n |   | |   |   |   |   | |   | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |   | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4)}}[(0, 2)] [id CB] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |     |Elemwise{lt,no_inplace} [id CC] <TensorType(bool, scalar)> ''   \n |   | |   |   |   |   | |     | |<TensorType(int64, scalar)> [id CD] <TensorType(int64, scalar)>\n |   | |   |   |   |   | |     | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |     |<TensorType(int64, scalar)> [id CD] <TensorType(int64, scalar)>\n |   | |   |   |   |   | |     |Shape_i{0} [id BY] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |     |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |     |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id BU] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |TensorConstant{3} [id BK] <TensorType(int64, scalar)>\n |   | |   |   |   |   | |Elemwise{sub,no_inplace} [id BT] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |Shape_i{1} [id CE] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | | |Position of the dips_copy[cuda] [id BZ] <CudaNdarrayType(float32, matrix)>\n |   | |   |   |   |   | |TensorConstant{-3} [id CF] <TensorType(int64, scalar)>\n |   | |   |   |   |   |Elemwise{sub,no_inplace} [id CG] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id CH] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | | |Elemwise{lt,no_inplace} [id CI] <TensorType(bool, scalar)> ''   \n |   | |   |   |   |   | | | |<TensorType(int64, scalar)> [id CJ] <TensorType(int64, scalar)>\n |   | |   |   |   |   | | | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   | | |<TensorType(int64, scalar)> [id CJ] <TensorType(int64, scalar)>\n |   | |   |   |   |   | | |Shape_i{0} [id BL] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4)}}[(0, 2)] [id CK] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   |   |Elemwise{lt,no_inplace} [id CL] <TensorType(bool, scalar)> ''   \n |   | |   |   |   |   |   | |<TensorType(int64, scalar)> [id CM] <TensorType(int64, scalar)>\n |   | |   |   |   |   |   | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   |   |<TensorType(int64, scalar)> [id CM] <TensorType(int64, scalar)>\n |   | |   |   |   |   |   |Shape_i{0} [id BL] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   |   |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id CH] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   |<TensorType(int64, scalar)> [id CN] <TensorType(int64, scalar)>\n |   | |   |   |   |MakeVector{dtype='int64'} [id CO] <TensorType(int64, vector)> ''   \n |   | |   |   |     |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id Y] <TensorType(int64, scalar)> ''   \n |   | |   |   |     |Elemwise{add,no_inplace} [id BQ] <TensorType(int64, scalar)> ''   \n |   | |   |   |ScalarFromTensor [id CP] <int64> ''   \n |   | |   |     |Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i3 * i4) // (i5 * i3 * i4)), i0)}}[(0, 0)] [id BR] <TensorType(int64, scalar)> ''   \n |   | |   |GpuJoin [id CQ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   | |GpuElemwise{sub,no_inplace} [id CR] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuDimShuffle{0,x} [id CS] <CudaNdarrayType(float32, col)> ''   \n |   | |   | | | |GpuSubtensor{int64:int64:int8, int64} [id CT] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | | |   |Position of the dips_copy[cuda] [id BZ] <CudaNdarrayType(float32, matrix)>\n |   | |   | | |   |ScalarFromTensor [id CU] <int64> ''   \n |   | |   | | |   | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id CV] <TensorType(int64, scalar)> ''   \n |   | |   | | |   |   |Elemwise{le,no_inplace} [id CW] <TensorType(bool, scalar)> ''   \n |   | |   | | |   |   | |Elemwise{sub,no_inplace} [id BT] <TensorType(int64, scalar)> ''   \n |   | |   | | |   |   | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   | | |   |   |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   | | |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4)}}[(0, 2)] [id CB] <TensorType(int64, scalar)> ''   \n |   | |   | | |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id BU] <TensorType(int64, scalar)> ''   \n |   | |   | | |   |ScalarFromTensor [id CX] <int64> ''   \n |   | |   | | |   | |Elemwise{Switch}[(0, 2)] [id CY] <TensorType(int64, scalar)> ''   \n |   | |   | | |   |   |Elemwise{le,no_inplace} [id CW] <TensorType(bool, scalar)> ''   \n |   | |   | | |   |   |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   | | |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id BU] <TensorType(int64, scalar)> ''   \n |   | |   | | |   |Constant{1} [id CZ] <int8>\n |   | |   | | |   |Constant{0} [id DA] <int64>\n |   | |   | | |GpuDimShuffle{x,0} [id DB] <CudaNdarrayType(float32, row)> ''   \n |   | |   | |   |GpuSubtensor{::, int64} [id DC] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | |     |GpuJoin [id DD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |     | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   | |     | |GpuJoin [id DE] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |     | | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   | |     | | |GpuReshape{2} [id DF] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |     | | | |GpuAdvancedSubtensor1 [id DG] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | |     | | | | |GpuReshape{1} [id BC] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | |     | | | | |Subtensor{int64} [id DH] <TensorType(int64, vector)> ''   \n |   | |   | |     | | | |   |Nonzero [id BA] <TensorType(int64, matrix)> ''   \n |   | |   | |     | | | |   |Constant{0} [id DA] <int64>\n |   | |   | |     | | | |TensorConstant{[-1  3]} [id DI] <TensorType(int64, vector)>\n |   | |   | |     | | |Rest of the points of the layers_copy[cuda] [id BM] <CudaNdarrayType(float32, matrix)>\n |   | |   | |     | |Reference points for every layer_copy[cuda] [id BO] <CudaNdarrayType(float32, matrix)>\n |   | |   | |     |Constant{0} [id DA] <int64>\n |   | |   | |GpuElemwise{sub,no_inplace} [id DJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuDimShuffle{0,x} [id DK] <CudaNdarrayType(float32, col)> ''   \n |   | |   | | | |GpuSubtensor{int64:int64:int8, int64} [id DL] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | | |   |Position of the dips_copy[cuda] [id BZ] <CudaNdarrayType(float32, matrix)>\n |   | |   | | |   |ScalarFromTensor [id CU] <int64> ''   \n |   | |   | | |   |ScalarFromTensor [id CX] <int64> ''   \n |   | |   | | |   |Constant{1} [id CZ] <int8>\n |   | |   | | |   |Constant{1} [id DM] <int64>\n |   | |   | | |GpuDimShuffle{x,0} [id DN] <CudaNdarrayType(float32, row)> ''   \n |   | |   | |   |GpuSubtensor{::, int64} [id DO] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | |     |GpuJoin [id DD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |     |Constant{1} [id DM] <int64>\n |   | |   | |GpuElemwise{sub,no_inplace} [id DP] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |   |GpuDimShuffle{0,x} [id DQ] <CudaNdarrayType(float32, col)> ''   \n |   | |   |   | |GpuSubtensor{int64:int64:int8, int64} [id DR] <CudaNdarrayType(float32, vector)> ''   \n |   | |   |   |   |Position of the dips_copy[cuda] [id BZ] <CudaNdarrayType(float32, matrix)>\n |   | |   |   |   |ScalarFromTensor [id CU] <int64> ''   \n |   | |   |   |   |ScalarFromTensor [id CX] <int64> ''   \n |   | |   |   |   |Constant{1} [id CZ] <int8>\n |   | |   |   |   |Constant{2} [id DS] <int64>\n |   | |   |   |GpuDimShuffle{x,0} [id DT] <CudaNdarrayType(float32, row)> ''   \n |   | |   |     |GpuSubtensor{::, int64} [id DU] <CudaNdarrayType(float32, vector)> ''   \n |   | |   |       |GpuJoin [id DD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |       |Constant{2} [id DS] <int64>\n |   | |   |GpuElemwise{Composite{Cast{float32}(LT(i0, i1))},no_inplace} [id DV] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id DW] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuDimShuffle{0,x} [id DX] <CudaNdarrayType(float32, col)> ''   \n |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id DY] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | | |   |GpuReshape{2} [id DZ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |     |GpuAlloc [id EA] <CudaNdarrayType(float32, (False, True, False, False))> ''   \n |   | |   | | |     | |GpuSubtensor{int64:int64:} [id EB] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |     | | |Position of the dips_copy[cuda] [id BZ] <CudaNdarrayType(float32, matrix)>\n |   | |   | | |     | | |ScalarFromTensor [id EC] <int64> ''   \n |   | |   | | |     | | | |<TensorType(int64, scalar)> [id CD] <TensorType(int64, scalar)>\n |   | |   | | |     | | |ScalarFromTensor [id ED] <int64> ''   \n |   | |   | | |     | |   |<TensorType(int64, scalar)> [id BW] <TensorType(int64, scalar)>\n |   | |   | | |     | |TensorConstant{3} [id EE] <TensorType(int8, scalar)>\n |   | |   | | |     | |TensorConstant{1} [id BP] <TensorType(int8, scalar)>\n |   | |   | | |     | |Elemwise{sub,no_inplace} [id BT] <TensorType(int64, scalar)> ''   \n |   | |   | | |     | |Shape_i{1} [id CE] <TensorType(int64, scalar)> ''   \n |   | |   | | |     |MakeVector{dtype='int64'} [id EF] <TensorType(int64, vector)> ''   \n |   | |   | | |       |Elemwise{mul,no_inplace} [id BS] <TensorType(int64, scalar)> ''   \n |   | |   | | |       |Shape_i{1} [id CE] <TensorType(int64, scalar)> ''   \n |   | |   | | |GpuDimShuffle{x,0} [id EG] <CudaNdarrayType(float32, row)> ''   \n |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id EH] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | | |   |GpuJoin [id DD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuDot22Scalar [id EI] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |GpuReshape{2} [id DZ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |GpuDimShuffle{1,0} [id EJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | | |GpuJoin [id DD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |TensorConstant{2.0} [id EK] <TensorType(float32, scalar)>\n |   | |   | | |CudaNdarrayConstant{[[ 0.]]} [id EL] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |<CudaNdarrayType(float32, (True, True))> [id EM] <CudaNdarrayType(float32, (True, True))>\n |   | |   |<CudaNdarrayType(float32, (True, True))> [id EN] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{mul,no_inplace} [id EO] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 26.25]]} [id EP] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id DW] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |<CudaNdarrayType(float32, (True, True))> [id EQ] <CudaNdarrayType(float32, (True, True))>\n |   | |   |CudaNdarrayConstant{[[ 17.5]]} [id ER] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{pow,no_inplace} [id ES] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id DW] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 3.]]} [id ET] <CudaNdarrayType(float32, (True, True))>\n |   | |   |<CudaNdarrayType(float32, (True, True))> [id EU] <CudaNdarrayType(float32, (True, True))>\n |   | |   |CudaNdarrayConstant{[[ 5.25]]} [id EV] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Pow}[(0, 0)] [id EW] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id DW] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 5.]]} [id EX] <CudaNdarrayType(float32, (True, True))>\n |   | |   |<CudaNdarrayType(float32, (True, True))> [id EY] <CudaNdarrayType(float32, (True, True))>\n |   | |GpuCAReduce{add}{1,0} [id EZ] <CudaNdarrayType(float32, vector)> ''   \n |   | | |GpuElemwise{Composite{(i0 * (i1 * ((i2 * ((i3 + i4 + i5) - (i6 + i7))) - (i8 * ((i3 + i9 + i10) - i11)))))}}[(0, 2)] [id FA] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |GpuSubtensor{int64:int64:} [id FB] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuDimShuffle{1,0} [id FC] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuReshape{2} [id FD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |   |GpuFromHost [id FE] <CudaNdarrayType(float32, (False, True, True, False))> ''   \n |   | |   | |   | |Alloc [id W] <TensorType(float32, (False, True, True, False))> ''   \n |   | |   | |   |MakeVector{dtype='int64'} [id CO] <TensorType(int64, vector)> ''   \n |   | |   | |ScalarFromTensor [id CP] <int64> ''   \n |   | |   | |ScalarFromTensor [id FF] <int64> ''   \n |   | |   |   |Elemwise{add,no_inplace} [id FG] <TensorType(int64, scalar)> ''   \n |   | |   |     |Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i3 * i4) // (i5 * i3 * i4)), i0)}}[(0, 0)] [id BR] <TensorType(int64, scalar)> ''   \n |   | |   |     |Elemwise{sub,no_inplace} [id CG] <TensorType(int64, scalar)> ''   \n |   | |   |<CudaNdarrayType(float32, (True, True))> [id FH] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{Cast{float32}(LT(i0, i1))},no_inplace} [id FI] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id FJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuDimShuffle{0,x} [id FK] <CudaNdarrayType(float32, col)> ''   \n |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id FL] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | | |   |GpuSubtensor{int64:int64:} [id FM] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |     |Rest of the points of the layers_copy[cuda] [id BM] <CudaNdarrayType(float32, matrix)>\n |   | |   | | |     |ScalarFromTensor [id FN] <int64> ''   \n |   | |   | | |     | |<TensorType(int64, scalar)> [id CM] <TensorType(int64, scalar)>\n |   | |   | | |     |ScalarFromTensor [id FO] <int64> ''   \n |   | |   | | |       |<TensorType(int64, scalar)> [id CJ] <TensorType(int64, scalar)>\n |   | |   | | |GpuDimShuffle{x,0} [id EG] <CudaNdarrayType(float32, row)> ''   \n |   | |   | | |GpuDot22Scalar [id FP] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |GpuSubtensor{int64:int64:} [id FM] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |GpuDimShuffle{1,0} [id EJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |TensorConstant{2.0} [id EK] <TensorType(float32, scalar)>\n |   | |   | | |CudaNdarrayConstant{[[ 0.]]} [id EL] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |<CudaNdarrayType(float32, (True, True))> [id EM] <CudaNdarrayType(float32, (True, True))>\n |   | |   |CudaNdarrayConstant{[[ 1.]]} [id FQ] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id FR] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 8.75]]} [id FS] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id FT] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id FJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |<CudaNdarrayType(float32, (True, True))> [id EM] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |CudaNdarrayConstant{[[ 3.]]} [id ET] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id FU] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 0.75]]} [id FV] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id FT] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 7.]]} [id FW] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace} [id FX] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 7.]]} [id FW] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id FT] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))}}[(0, 1)] [id FY] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 3.5]]} [id FZ] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id FT] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 5.]]} [id EX] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{Cast{float32}(LT(i0, i1))},no_inplace} [id GA] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id GB] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuDimShuffle{0,x} [id GC] <CudaNdarrayType(float32, col)> ''   \n |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id GD] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | | |   |GpuSubtensor{int64:int64:} [id GE] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |     |Reference points for every layer_copy[cuda] [id BO] <CudaNdarrayType(float32, matrix)>\n |   | |   | | |     |ScalarFromTensor [id FN] <int64> ''   \n |   | |   | | |     |ScalarFromTensor [id FO] <int64> ''   \n |   | |   | | |GpuDimShuffle{x,0} [id EG] <CudaNdarrayType(float32, row)> ''   \n |   | |   | | |GpuDot22Scalar [id GF] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |GpuSubtensor{int64:int64:} [id GE] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |GpuDimShuffle{1,0} [id EJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |TensorConstant{2.0} [id EK] <TensorType(float32, scalar)>\n |   | |   | | |CudaNdarrayConstant{[[ 0.]]} [id EL] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |<CudaNdarrayType(float32, (True, True))> [id EM] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id GG] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 8.75]]} [id FS] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id GH] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id GB] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |<CudaNdarrayType(float32, (True, True))> [id EM] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |CudaNdarrayConstant{[[ 3.]]} [id ET] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id GI] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 0.75]]} [id FV] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id GH] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 7.]]} [id FW] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{((i0 * sqr(i1)) + (i2 * (i1 ** i3)))}}[(0, 1)] [id GJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |     |CudaNdarrayConstant{[[ 7.]]} [id FW] <CudaNdarrayType(float32, (True, True))>\n |   | |     |GpuElemwise{TrueDiv}[(0, 0)] [id GH] <CudaNdarrayType(float32, matrix)> ''   \n |   | |     |CudaNdarrayConstant{[[ 3.5]]} [id FZ] <CudaNdarrayType(float32, (True, True))>\n |   | |     |CudaNdarrayConstant{[[ 5.]]} [id EX] <CudaNdarrayType(float32, (True, True))>\n |   | |GpuCAReduce{add}{1,0} [id GK] <CudaNdarrayType(float32, vector)> ''   \n |   | | |GpuElemwise{Composite{(((i0 * i1) * i2) * i3)}}[(0, 2)] [id GL] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |GpuSubtensor{int64:int64:} [id GM] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuDimShuffle{1,0} [id FC] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |ScalarFromTensor [id FF] <int64> ''   \n |   | |   | |ScalarFromTensor [id GN] <int64> ''   \n |   | |   |   |Elemwise{Add}[(0, 0)] [id GO] <TensorType(int64, scalar)> ''   \n |   | |   |     |Elemwise{add,no_inplace} [id FG] <TensorType(int64, scalar)> ''   \n |   | |   |     |<TensorType(int64, scalar)> [id CN] <TensorType(int64, scalar)>\n |   | |   |<CudaNdarrayType(float32, (True, True))> [id N] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuDimShuffle{1,0} [id GP] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuReshape{2} [id GQ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |   |GpuAlloc [id GR] <CudaNdarrayType(float32, (False, True, True, False))> ''   \n |   | |   |   | |GpuSubtensor{:int64:} [id GS] <CudaNdarrayType(float32, vector)> ''   \n |   | |   |   | | |<CudaNdarrayType(float32, vector)> [id GT] <CudaNdarrayType(float32, vector)>\n |   | |   |   | | |ScalarFromTensor [id GU] <int64> ''   \n |   | |   |   | |   |<TensorType(int64, scalar)> [id CN] <TensorType(int64, scalar)>\n |   | |   |   | |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id Y] <TensorType(int64, scalar)> ''   \n |   | |   |   | |TensorConstant{1} [id BP] <TensorType(int8, scalar)>\n |   | |   |   | |TensorConstant{1} [id BP] <TensorType(int8, scalar)>\n |   | |   |   | |Elemwise{Composite{Switch(LT(i0, i1), Switch(LT((i0 + i2), i1), i1, (i0 + i2)), Switch(LT(i0, i2), i0, i2))}}[(0, 2)] [id GV] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |<TensorType(int64, scalar)> [id CN] <TensorType(int64, scalar)>\n |   | |   |   |   |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |Shape_i{0} [id GW] <TensorType(int64, scalar)> ''   \n |   | |   |   |     |<CudaNdarrayType(float32, vector)> [id GT] <CudaNdarrayType(float32, vector)>\n |   | |   |   |MakeVector{dtype='int64'} [id GX] <TensorType(int64, vector)> ''   \n |   | |   |     |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id Y] <TensorType(int64, scalar)> ''   \n |   | |   |     |Elemwise{Composite{Switch(LT(i0, i1), Switch(LT((i0 + i2), i1), i1, (i0 + i2)), Switch(LT(i0, i2), i0, i2))}}[(0, 2)] [id GV] <TensorType(int64, scalar)> ''   \n |   | |   |GpuSubtensor{:int64:} [id GY] <CudaNdarrayType(float32, matrix)> ''   \n |   | |     |GpuJoin [id GZ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |     | |TensorConstant{1} [id BP] <TensorType(int8, scalar)>\n |   | |     | |GpuReshape{2} [id HA] <CudaNdarrayType(float32, matrix)> ''   \n |   | |     | | |GpuAdvancedSubtensor1 [id HB] <CudaNdarrayType(float32, vector)> ''   \n |   | |     | | | |GpuReshape{1} [id HC] <CudaNdarrayType(float32, vector)> ''   \n |   | |     | | | | |GpuElemwise{mul,no_inplace} [id HD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |     | | | | | |<CudaNdarrayType(float32, matrix)> [id HE] <CudaNdarrayType(float32, matrix)>\n |   | |     | | | | | |GpuFromHost [id HF] <CudaNdarrayType(float32, row)> ''   \n |   | |     | | | | |   |Elemwise{Cast{float32}} [id HG] <TensorType(float32, row)> ''   \n |   | |     | | | | |     |InplaceDimShuffle{x,0} [id HH] <TensorType(bool, row)> ''   \n |   | |     | | | | |       |Elemwise{eq,no_inplace} [id BI] <TensorType(bool, vector)> 'Yet simulated LITHOLOGY node'   \n |   | |     | | | | |TensorConstant{(1,) of -1} [id BJ] <TensorType(int64, (True,))>\n |   | |     | | | |Subtensor{int64} [id HI] <TensorType(int64, vector)> ''   \n |   | |     | | |   |Nonzero [id HJ] <TensorType(int64, matrix)> ''   \n |   | |     | | |   | |HostFromGpu [id HK] <TensorType(float32, vector)> ''   \n |   | |     | | |   |   |GpuReshape{1} [id HC] <CudaNdarrayType(float32, vector)> ''   \n |   | |     | | |   |Constant{0} [id DA] <int64>\n |   | |     | | |TensorConstant{[ 9 -1]} [id HL] <TensorType(int64, vector)>\n |   | |     | |<CudaNdarrayType(float32, matrix)> [id HM] <CudaNdarrayType(float32, matrix)>\n |   | |     |ScalarFromTensor [id GU] <int64> ''   \n |   | |GpuCAReduce{add}{1,0} [id HN] <CudaNdarrayType(float32, vector)> ''   \n |   |   |GpuElemwise{Mul}[(0, 0)] [id HO] <CudaNdarrayType(float32, matrix)> ''   \n |   |     |GpuSubtensor{int64::} [id HP] <CudaNdarrayType(float32, matrix)> ''   \n |   |     | |GpuDimShuffle{1,0} [id FC] <CudaNdarrayType(float32, matrix)> ''   \n |   |     | |ScalarFromTensor [id GN] <int64> ''   \n |   |     |GpuSubtensor{::, :int64:} [id HQ] <CudaNdarrayType(float32, matrix)> ''   \n |   |       |<CudaNdarrayType(float32, matrix)> [id HR] <CudaNdarrayType(float32, matrix)>\n |   |       |ScalarFromTensor [id HS] <int64> ''   \n |   |         |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id Y] <TensorType(int64, scalar)> ''   \n |   |<int64> [id HT] <int64>\n |   |<int64> [id HU] <int64>\n |Elemwise{add,no_inplace} [id HV] <TensorType(int64, vector)> ''   \n   |TensorConstant{(1,) of -1} [id BJ] <TensorType(int64, (True,))>\n   |Subtensor{int64:int64:} [id HW] <TensorType(int64, vector)> ''   \n     |Value of the formation_copy [id HX] <TensorType(int64, vector)>\n     |ScalarFromTensor [id HY] <int64> ''   \n     | |<TensorType(int64, scalar)> [id HZ] <TensorType(int64, scalar)>\n     |ScalarFromTensor [id IA] <int64> ''   \n       |<TensorType(int64, scalar)> [id IB] <TensorType(int64, scalar)>\n\nInner graphs of the scan ops:\n\nfor{gpu,scan_fn} [id B] <CudaNdarrayType(float32, vector)> ''   \n >GpuElemwise{true_div,no_inplace} [id IC] <CudaNdarrayType(float32, scalar)> ''   \n > |GpuCAReduce{add}{1} [id ID] <CudaNdarrayType(float32, scalar)> ''   \n > | |GpuSubtensor{int32:int32:} [id IE] <CudaNdarrayType(float32, vector)> ''   \n > |   |<CudaNdarrayType(float32, vector)> [id IF] <CudaNdarrayType(float32, vector)> -> [id J]\n > |   |ScalarFromTensor [id IG] <int32> ''   \n > |   | |<TensorType(int32, scalar)> [id IH] <TensorType(int32, scalar)> -> [id D]\n > |   |ScalarFromTensor [id II] <int32> ''   \n > |     |<TensorType(int32, scalar)> [id IJ] <TensorType(int32, scalar)> -> [id F]\n > |<CudaNdarrayType(float32, scalar)> [id IK] <CudaNdarrayType(float32, scalar)> -> [id H]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d62dcab723c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'timeit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sol = gp.compute_model(interp_data)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2120\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2121\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell)\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m                 \u001b[0mtime_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mworst_tuning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworst_tuning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;32m/home/miguel/PycharmProjects/gempy/gempy/GemPy_f.py\u001b[0m in \u001b[0;36mcompute_model\u001b[1;34m(interp_data, u_grade, get_potential_at_interfaces)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minterp_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_input_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu_grade\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mu_grade\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m     \u001b[0msol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpotential_at_interfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minterp_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mth_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[0m_np\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    896\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    899\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/theano/gof/link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    987\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0;32m    988\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m--> 989\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    990\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mp\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    976\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m                                                 self, node)\n\u001b[0m\u001b[0;32m    979\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/miguel/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-jessie-sid-x86_64-3.5.3-64/scan_perform/mod.cpp:4606)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/theano/gof/link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miguel/anaconda3/lib/python3.5/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/miguel/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-jessie-sid-x86_64-3.5.3-64/scan_perform/mod.cpp:4490)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: One of the index value is out of bound. Error code: 65535.\\n\nApply node that caused the error: GpuAdvancedSubtensor1(for{gpu,scan_fn}.0, Elemwise{add,no_inplace}.0)\nToposort index: 409\nInputs types: [CudaNdarrayType(float32, vector), TensorType(int64, vector)]\nInputs shapes: [(4,), (4,)]\nInputs strides: [(1,), (8,)]\nInputs values: [b'CudaNdarray([ 0.03435151  0.11909181 -0.02655532  0.13297006])', array([0, 1, 2, 4])]\nInputs type_num: ['', 7]\nOutputs clients: [[HostFromGpu(GpuAdvancedSubtensor1.0), GpuAdvancedIncSubtensor1{no_inplace,set}(<CudaNdarrayType(float32, vector)>, GpuAdvancedSubtensor1.0, Elemwise{add,no_inplace}.0)]]\n\nDebugprint of the apply node: \nGpuAdvancedSubtensor1 [id A] <CudaNdarrayType(float32, vector)> ''   \n |for{gpu,scan_fn} [id B] <CudaNdarrayType(float32, vector)> ''   \n | |<TensorType(int64, scalar)> [id C] <TensorType(int64, scalar)>\n | |Elemwise{Cast{int32}} [id D] <TensorType(int32, vector)> ''   \n | | |<TensorType(int64, vector)> [id E] <TensorType(int64, vector)>\n | |Elemwise{Cast{int32}} [id F] <TensorType(int32, vector)> ''   \n | | |<TensorType(int64, vector)> [id G] <TensorType(int64, vector)>\n | |GpuFromHost [id H] <CudaNdarrayType(float32, vector)> ''   \n | | |Elemwise{Composite{Cast{float32}((i0 - i1))}} [id I] <TensorType(float32, vector)> ''   \n | |   |<TensorType(int64, vector)> [id G] <TensorType(int64, vector)>\n | |   |<TensorType(int64, vector)> [id E] <TensorType(int64, vector)>\n | |<TensorType(int64, scalar)> [id C] <TensorType(int64, scalar)>\n | |GpuSubtensor{int64:int64:} [id J] <CudaNdarrayType(float32, vector)> ''   \n |   |GpuElemwise{Composite{((((i0 * i1 * i2 * i3) + (-i4)) + i5) + i6)}}[(0, 3)] [id K] <CudaNdarrayType(float32, vector)> ''   \n |   | |CudaNdarrayConstant{[-1.]} [id L] <CudaNdarrayType(float32, (True,))>\n |   | |GpuDimShuffle{x} [id M] <CudaNdarrayType(float32, (True,))> ''   \n |   | | |<CudaNdarrayType(float32, (True, True))> [id N] <CudaNdarrayType(float32, (True, True))>\n |   | |GpuDimShuffle{x} [id O] <CudaNdarrayType(float32, (True,))> ''   \n |   | | |<CudaNdarrayType(float32, (True, True))> [id P] <CudaNdarrayType(float32, (True, True))>\n |   | |GpuCAReduce{add}{1,0} [id Q] <CudaNdarrayType(float32, vector)> ''   \n |   | | |GpuElemwise{Composite{(i0 * i1 * i2 * (((i3 + (i4 / i5)) - ((i6 * i7) / i8)) + ((i9 * i10) / i11)))}}[(0, 0)] [id R] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |GpuFromHost [id S] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |Subtensor{:int64:} [id T] <TensorType(float32, matrix)> ''   \n |   | |   |   |InplaceDimShuffle{1,0} [id U] <TensorType(float32, matrix)> ''   \n |   | |   |   | |Reshape{2} [id V] <TensorType(float32, matrix)> ''   \n |   | |   |   |   |Alloc [id W] <TensorType(float32, (False, True, True, False))> ''   \n |   | |   |   |   | |Reshape{1} [id X] <TensorType(float32, vector)> 'Dual Kriging parameters'   \n |   | |   |   |   | |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id Y] <TensorType(int64, scalar)> ''   \n |   | |   |   |   | | |Shape_i{1} [id Z] <TensorType(int64, scalar)> ''   \n |   | |   |   |   | | | |Nonzero [id BA] <TensorType(int64, matrix)> ''   \n |   | |   |   |   | | |   |HostFromGpu [id BB] <TensorType(float32, vector)> ''   \n |   | |   |   |   | | |     |GpuReshape{1} [id BC] <CudaNdarrayType(float32, vector)> ''   \n |   | |   |   |   | | |       |GpuElemwise{mul,no_inplace} [id BD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |   |   | | |       | |Coordinates of the grid points to interpolate_copy[cuda] [id BE] <CudaNdarrayType(float32, matrix)>\n |   | |   |   |   | | |       | |GpuFromHost [id BF] <CudaNdarrayType(float32, col)> ''   \n |   | |   |   |   | | |       |   |Elemwise{Cast{float32}} [id BG] <TensorType(float32, col)> ''   \n |   | |   |   |   | | |       |     |InplaceDimShuffle{0,x} [id BH] <TensorType(bool, col)> ''   \n |   | |   |   |   | | |       |       |Elemwise{eq,no_inplace} [id BI] <TensorType(bool, vector)> 'Yet simulated LITHOLOGY node'   \n |   | |   |   |   | | |       |TensorConstant{(1,) of -1} [id BJ] <TensorType(int64, (True,))>\n |   | |   |   |   | | |TensorConstant{3} [id BK] <TensorType(int64, scalar)>\n |   | |   |   |   | | |Shape_i{0} [id BL] <TensorType(int64, scalar)> ''   \n |   | |   |   |   | | | |Rest of the points of the layers_copy[cuda] [id BM] <CudaNdarrayType(float32, matrix)>\n |   | |   |   |   | | |Shape_i{0} [id BN] <TensorType(int64, scalar)> ''   \n |   | |   |   |   | |   |Reference points for every layer_copy[cuda] [id BO] <CudaNdarrayType(float32, matrix)>\n |   | |   |   |   | |TensorConstant{1} [id BP] <TensorType(int8, scalar)>\n |   | |   |   |   | |TensorConstant{1} [id BP] <TensorType(int8, scalar)>\n |   | |   |   |   | |Elemwise{add,no_inplace} [id BQ] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   |Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i3 * i4) // (i5 * i3 * i4)), i0)}}[(0, 0)] [id BR] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |Elemwise{mul,no_inplace} [id BS] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | | |TensorConstant{3} [id BK] <TensorType(int64, scalar)>\n |   | |   |   |   |   | | |Elemwise{sub,no_inplace} [id BT] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id BU] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |   | |Elemwise{lt,no_inplace} [id BV] <TensorType(bool, scalar)> ''   \n |   | |   |   |   |   | |   | | |<TensorType(int64, scalar)> [id BW] <TensorType(int64, scalar)>\n |   | |   |   |   |   | |   | | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |   | |<TensorType(int64, scalar)> [id BW] <TensorType(int64, scalar)>\n |   | |   |   |   |   | |   | |Shape_i{0} [id BY] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |   | | |Position of the dips_copy[cuda] [id BZ] <CudaNdarrayType(float32, matrix)>\n |   | |   |   |   |   | |   | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |   | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4)}}[(0, 2)] [id CB] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |     |Elemwise{lt,no_inplace} [id CC] <TensorType(bool, scalar)> ''   \n |   | |   |   |   |   | |     | |<TensorType(int64, scalar)> [id CD] <TensorType(int64, scalar)>\n |   | |   |   |   |   | |     | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |     |<TensorType(int64, scalar)> [id CD] <TensorType(int64, scalar)>\n |   | |   |   |   |   | |     |Shape_i{0} [id BY] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |     |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |     |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id BU] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |TensorConstant{3} [id BK] <TensorType(int64, scalar)>\n |   | |   |   |   |   | |Elemwise{sub,no_inplace} [id BT] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |Shape_i{1} [id CE] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | | |Position of the dips_copy[cuda] [id BZ] <CudaNdarrayType(float32, matrix)>\n |   | |   |   |   |   | |TensorConstant{-3} [id CF] <TensorType(int64, scalar)>\n |   | |   |   |   |   |Elemwise{sub,no_inplace} [id CG] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id CH] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | | |Elemwise{lt,no_inplace} [id CI] <TensorType(bool, scalar)> ''   \n |   | |   |   |   |   | | | |<TensorType(int64, scalar)> [id CJ] <TensorType(int64, scalar)>\n |   | |   |   |   |   | | | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   | | |<TensorType(int64, scalar)> [id CJ] <TensorType(int64, scalar)>\n |   | |   |   |   |   | | |Shape_i{0} [id BL] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   | | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n |   | |   |   |   |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4)}}[(0, 2)] [id CK] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   |   |Elemwise{lt,no_inplace} [id CL] <TensorType(bool, scalar)> ''   \n |   | |   |   |   |   |   | |<TensorType(int64, scalar)> [id CM] <TensorType(int64, scalar)>\n |   | |   |   |   |   |   | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   |   |<TensorType(int64, scalar)> [id CM] <TensorType(int64, scalar)>\n |   | |   |   |   |   |   |Shape_i{0} [id BL] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   |   |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id CH] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |   |<TensorType(int64, scalar)> [id CN] <TensorType(int64, scalar)>\n |   | |   |   |   |MakeVector{dtype='int64'} [id CO] <TensorType(int64, vector)> ''   \n |   | |   |   |     |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id Y] <TensorType(int64, scalar)> ''   \n |   | |   |   |     |Elemwise{add,no_inplace} [id BQ] <TensorType(int64, scalar)> ''   \n |   | |   |   |ScalarFromTensor [id CP] <int64> ''   \n |   | |   |     |Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i3 * i4) // (i5 * i3 * i4)), i0)}}[(0, 0)] [id BR] <TensorType(int64, scalar)> ''   \n |   | |   |GpuJoin [id CQ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   | |GpuElemwise{sub,no_inplace} [id CR] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuDimShuffle{0,x} [id CS] <CudaNdarrayType(float32, col)> ''   \n |   | |   | | | |GpuSubtensor{int64:int64:int8, int64} [id CT] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | | |   |Position of the dips_copy[cuda] [id BZ] <CudaNdarrayType(float32, matrix)>\n |   | |   | | |   |ScalarFromTensor [id CU] <int64> ''   \n |   | |   | | |   | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id CV] <TensorType(int64, scalar)> ''   \n |   | |   | | |   |   |Elemwise{le,no_inplace} [id CW] <TensorType(bool, scalar)> ''   \n |   | |   | | |   |   | |Elemwise{sub,no_inplace} [id BT] <TensorType(int64, scalar)> ''   \n |   | |   | | |   |   | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   | | |   |   |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   | | |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4)}}[(0, 2)] [id CB] <TensorType(int64, scalar)> ''   \n |   | |   | | |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id BU] <TensorType(int64, scalar)> ''   \n |   | |   | | |   |ScalarFromTensor [id CX] <int64> ''   \n |   | |   | | |   | |Elemwise{Switch}[(0, 2)] [id CY] <TensorType(int64, scalar)> ''   \n |   | |   | | |   |   |Elemwise{le,no_inplace} [id CW] <TensorType(bool, scalar)> ''   \n |   | |   | | |   |   |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   | | |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id BU] <TensorType(int64, scalar)> ''   \n |   | |   | | |   |Constant{1} [id CZ] <int8>\n |   | |   | | |   |Constant{0} [id DA] <int64>\n |   | |   | | |GpuDimShuffle{x,0} [id DB] <CudaNdarrayType(float32, row)> ''   \n |   | |   | |   |GpuSubtensor{::, int64} [id DC] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | |     |GpuJoin [id DD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |     | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   | |     | |GpuJoin [id DE] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |     | | |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   | |     | | |GpuReshape{2} [id DF] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |     | | | |GpuAdvancedSubtensor1 [id DG] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | |     | | | | |GpuReshape{1} [id BC] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | |     | | | | |Subtensor{int64} [id DH] <TensorType(int64, vector)> ''   \n |   | |   | |     | | | |   |Nonzero [id BA] <TensorType(int64, matrix)> ''   \n |   | |   | |     | | | |   |Constant{0} [id DA] <int64>\n |   | |   | |     | | | |TensorConstant{[-1  3]} [id DI] <TensorType(int64, vector)>\n |   | |   | |     | | |Rest of the points of the layers_copy[cuda] [id BM] <CudaNdarrayType(float32, matrix)>\n |   | |   | |     | |Reference points for every layer_copy[cuda] [id BO] <CudaNdarrayType(float32, matrix)>\n |   | |   | |     |Constant{0} [id DA] <int64>\n |   | |   | |GpuElemwise{sub,no_inplace} [id DJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuDimShuffle{0,x} [id DK] <CudaNdarrayType(float32, col)> ''   \n |   | |   | | | |GpuSubtensor{int64:int64:int8, int64} [id DL] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | | |   |Position of the dips_copy[cuda] [id BZ] <CudaNdarrayType(float32, matrix)>\n |   | |   | | |   |ScalarFromTensor [id CU] <int64> ''   \n |   | |   | | |   |ScalarFromTensor [id CX] <int64> ''   \n |   | |   | | |   |Constant{1} [id CZ] <int8>\n |   | |   | | |   |Constant{1} [id DM] <int64>\n |   | |   | | |GpuDimShuffle{x,0} [id DN] <CudaNdarrayType(float32, row)> ''   \n |   | |   | |   |GpuSubtensor{::, int64} [id DO] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | |     |GpuJoin [id DD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |     |Constant{1} [id DM] <int64>\n |   | |   | |GpuElemwise{sub,no_inplace} [id DP] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |   |GpuDimShuffle{0,x} [id DQ] <CudaNdarrayType(float32, col)> ''   \n |   | |   |   | |GpuSubtensor{int64:int64:int8, int64} [id DR] <CudaNdarrayType(float32, vector)> ''   \n |   | |   |   |   |Position of the dips_copy[cuda] [id BZ] <CudaNdarrayType(float32, matrix)>\n |   | |   |   |   |ScalarFromTensor [id CU] <int64> ''   \n |   | |   |   |   |ScalarFromTensor [id CX] <int64> ''   \n |   | |   |   |   |Constant{1} [id CZ] <int8>\n |   | |   |   |   |Constant{2} [id DS] <int64>\n |   | |   |   |GpuDimShuffle{x,0} [id DT] <CudaNdarrayType(float32, row)> ''   \n |   | |   |     |GpuSubtensor{::, int64} [id DU] <CudaNdarrayType(float32, vector)> ''   \n |   | |   |       |GpuJoin [id DD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |       |Constant{2} [id DS] <int64>\n |   | |   |GpuElemwise{Composite{Cast{float32}(LT(i0, i1))},no_inplace} [id DV] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id DW] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuDimShuffle{0,x} [id DX] <CudaNdarrayType(float32, col)> ''   \n |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id DY] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | | |   |GpuReshape{2} [id DZ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |     |GpuAlloc [id EA] <CudaNdarrayType(float32, (False, True, False, False))> ''   \n |   | |   | | |     | |GpuSubtensor{int64:int64:} [id EB] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |     | | |Position of the dips_copy[cuda] [id BZ] <CudaNdarrayType(float32, matrix)>\n |   | |   | | |     | | |ScalarFromTensor [id EC] <int64> ''   \n |   | |   | | |     | | | |<TensorType(int64, scalar)> [id CD] <TensorType(int64, scalar)>\n |   | |   | | |     | | |ScalarFromTensor [id ED] <int64> ''   \n |   | |   | | |     | |   |<TensorType(int64, scalar)> [id BW] <TensorType(int64, scalar)>\n |   | |   | | |     | |TensorConstant{3} [id EE] <TensorType(int8, scalar)>\n |   | |   | | |     | |TensorConstant{1} [id BP] <TensorType(int8, scalar)>\n |   | |   | | |     | |Elemwise{sub,no_inplace} [id BT] <TensorType(int64, scalar)> ''   \n |   | |   | | |     | |Shape_i{1} [id CE] <TensorType(int64, scalar)> ''   \n |   | |   | | |     |MakeVector{dtype='int64'} [id EF] <TensorType(int64, vector)> ''   \n |   | |   | | |       |Elemwise{mul,no_inplace} [id BS] <TensorType(int64, scalar)> ''   \n |   | |   | | |       |Shape_i{1} [id CE] <TensorType(int64, scalar)> ''   \n |   | |   | | |GpuDimShuffle{x,0} [id EG] <CudaNdarrayType(float32, row)> ''   \n |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id EH] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | | |   |GpuJoin [id DD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuDot22Scalar [id EI] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |GpuReshape{2} [id DZ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |GpuDimShuffle{1,0} [id EJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | | |GpuJoin [id DD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |TensorConstant{2.0} [id EK] <TensorType(float32, scalar)>\n |   | |   | | |CudaNdarrayConstant{[[ 0.]]} [id EL] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |<CudaNdarrayType(float32, (True, True))> [id EM] <CudaNdarrayType(float32, (True, True))>\n |   | |   |<CudaNdarrayType(float32, (True, True))> [id EN] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{mul,no_inplace} [id EO] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 26.25]]} [id EP] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id DW] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |<CudaNdarrayType(float32, (True, True))> [id EQ] <CudaNdarrayType(float32, (True, True))>\n |   | |   |CudaNdarrayConstant{[[ 17.5]]} [id ER] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{pow,no_inplace} [id ES] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id DW] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 3.]]} [id ET] <CudaNdarrayType(float32, (True, True))>\n |   | |   |<CudaNdarrayType(float32, (True, True))> [id EU] <CudaNdarrayType(float32, (True, True))>\n |   | |   |CudaNdarrayConstant{[[ 5.25]]} [id EV] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Pow}[(0, 0)] [id EW] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id DW] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 5.]]} [id EX] <CudaNdarrayType(float32, (True, True))>\n |   | |   |<CudaNdarrayType(float32, (True, True))> [id EY] <CudaNdarrayType(float32, (True, True))>\n |   | |GpuCAReduce{add}{1,0} [id EZ] <CudaNdarrayType(float32, vector)> ''   \n |   | | |GpuElemwise{Composite{(i0 * (i1 * ((i2 * ((i3 + i4 + i5) - (i6 + i7))) - (i8 * ((i3 + i9 + i10) - i11)))))}}[(0, 2)] [id FA] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |GpuSubtensor{int64:int64:} [id FB] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuDimShuffle{1,0} [id FC] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuReshape{2} [id FD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |   |GpuFromHost [id FE] <CudaNdarrayType(float32, (False, True, True, False))> ''   \n |   | |   | |   | |Alloc [id W] <TensorType(float32, (False, True, True, False))> ''   \n |   | |   | |   |MakeVector{dtype='int64'} [id CO] <TensorType(int64, vector)> ''   \n |   | |   | |ScalarFromTensor [id CP] <int64> ''   \n |   | |   | |ScalarFromTensor [id FF] <int64> ''   \n |   | |   |   |Elemwise{add,no_inplace} [id FG] <TensorType(int64, scalar)> ''   \n |   | |   |     |Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i3 * i4) // (i5 * i3 * i4)), i0)}}[(0, 0)] [id BR] <TensorType(int64, scalar)> ''   \n |   | |   |     |Elemwise{sub,no_inplace} [id CG] <TensorType(int64, scalar)> ''   \n |   | |   |<CudaNdarrayType(float32, (True, True))> [id FH] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{Cast{float32}(LT(i0, i1))},no_inplace} [id FI] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id FJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuDimShuffle{0,x} [id FK] <CudaNdarrayType(float32, col)> ''   \n |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id FL] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | | |   |GpuSubtensor{int64:int64:} [id FM] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |     |Rest of the points of the layers_copy[cuda] [id BM] <CudaNdarrayType(float32, matrix)>\n |   | |   | | |     |ScalarFromTensor [id FN] <int64> ''   \n |   | |   | | |     | |<TensorType(int64, scalar)> [id CM] <TensorType(int64, scalar)>\n |   | |   | | |     |ScalarFromTensor [id FO] <int64> ''   \n |   | |   | | |       |<TensorType(int64, scalar)> [id CJ] <TensorType(int64, scalar)>\n |   | |   | | |GpuDimShuffle{x,0} [id EG] <CudaNdarrayType(float32, row)> ''   \n |   | |   | | |GpuDot22Scalar [id FP] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |GpuSubtensor{int64:int64:} [id FM] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |GpuDimShuffle{1,0} [id EJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |TensorConstant{2.0} [id EK] <TensorType(float32, scalar)>\n |   | |   | | |CudaNdarrayConstant{[[ 0.]]} [id EL] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |<CudaNdarrayType(float32, (True, True))> [id EM] <CudaNdarrayType(float32, (True, True))>\n |   | |   |CudaNdarrayConstant{[[ 1.]]} [id FQ] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id FR] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 8.75]]} [id FS] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id FT] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id FJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |<CudaNdarrayType(float32, (True, True))> [id EM] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |CudaNdarrayConstant{[[ 3.]]} [id ET] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id FU] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 0.75]]} [id FV] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id FT] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 7.]]} [id FW] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace} [id FX] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 7.]]} [id FW] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id FT] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))}}[(0, 1)] [id FY] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 3.5]]} [id FZ] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id FT] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 5.]]} [id EX] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{Cast{float32}(LT(i0, i1))},no_inplace} [id GA] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id GB] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuDimShuffle{0,x} [id GC] <CudaNdarrayType(float32, col)> ''   \n |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id GD] <CudaNdarrayType(float32, vector)> ''   \n |   | |   | | |   |GpuSubtensor{int64:int64:} [id GE] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |     |Reference points for every layer_copy[cuda] [id BO] <CudaNdarrayType(float32, matrix)>\n |   | |   | | |     |ScalarFromTensor [id FN] <int64> ''   \n |   | |   | | |     |ScalarFromTensor [id FO] <int64> ''   \n |   | |   | | |GpuDimShuffle{x,0} [id EG] <CudaNdarrayType(float32, row)> ''   \n |   | |   | | |GpuDot22Scalar [id GF] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |GpuSubtensor{int64:int64:} [id GE] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |GpuDimShuffle{1,0} [id EJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | | |TensorConstant{2.0} [id EK] <TensorType(float32, scalar)>\n |   | |   | | |CudaNdarrayConstant{[[ 0.]]} [id EL] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |<CudaNdarrayType(float32, (True, True))> [id EM] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id GG] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 8.75]]} [id FS] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id GH] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id GB] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | | |<CudaNdarrayType(float32, (True, True))> [id EM] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |CudaNdarrayConstant{[[ 3.]]} [id ET] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id GI] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 0.75]]} [id FV] <CudaNdarrayType(float32, (True, True))>\n |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id GH] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |CudaNdarrayConstant{[[ 7.]]} [id FW] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuElemwise{Composite{((i0 * sqr(i1)) + (i2 * (i1 ** i3)))}}[(0, 1)] [id GJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |     |CudaNdarrayConstant{[[ 7.]]} [id FW] <CudaNdarrayType(float32, (True, True))>\n |   | |     |GpuElemwise{TrueDiv}[(0, 0)] [id GH] <CudaNdarrayType(float32, matrix)> ''   \n |   | |     |CudaNdarrayConstant{[[ 3.5]]} [id FZ] <CudaNdarrayType(float32, (True, True))>\n |   | |     |CudaNdarrayConstant{[[ 5.]]} [id EX] <CudaNdarrayType(float32, (True, True))>\n |   | |GpuCAReduce{add}{1,0} [id GK] <CudaNdarrayType(float32, vector)> ''   \n |   | | |GpuElemwise{Composite{(((i0 * i1) * i2) * i3)}}[(0, 2)] [id GL] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |GpuSubtensor{int64:int64:} [id GM] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuDimShuffle{1,0} [id FC] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |ScalarFromTensor [id FF] <int64> ''   \n |   | |   | |ScalarFromTensor [id GN] <int64> ''   \n |   | |   |   |Elemwise{Add}[(0, 0)] [id GO] <TensorType(int64, scalar)> ''   \n |   | |   |     |Elemwise{add,no_inplace} [id FG] <TensorType(int64, scalar)> ''   \n |   | |   |     |<TensorType(int64, scalar)> [id CN] <TensorType(int64, scalar)>\n |   | |   |<CudaNdarrayType(float32, (True, True))> [id N] <CudaNdarrayType(float32, (True, True))>\n |   | |   |GpuDimShuffle{1,0} [id GP] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   | |GpuReshape{2} [id GQ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |   |   |GpuAlloc [id GR] <CudaNdarrayType(float32, (False, True, True, False))> ''   \n |   | |   |   | |GpuSubtensor{:int64:} [id GS] <CudaNdarrayType(float32, vector)> ''   \n |   | |   |   | | |<CudaNdarrayType(float32, vector)> [id GT] <CudaNdarrayType(float32, vector)>\n |   | |   |   | | |ScalarFromTensor [id GU] <int64> ''   \n |   | |   |   | |   |<TensorType(int64, scalar)> [id CN] <TensorType(int64, scalar)>\n |   | |   |   | |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id Y] <TensorType(int64, scalar)> ''   \n |   | |   |   | |TensorConstant{1} [id BP] <TensorType(int8, scalar)>\n |   | |   |   | |TensorConstant{1} [id BP] <TensorType(int8, scalar)>\n |   | |   |   | |Elemwise{Composite{Switch(LT(i0, i1), Switch(LT((i0 + i2), i1), i1, (i0 + i2)), Switch(LT(i0, i2), i0, i2))}}[(0, 2)] [id GV] <TensorType(int64, scalar)> ''   \n |   | |   |   |   |<TensorType(int64, scalar)> [id CN] <TensorType(int64, scalar)>\n |   | |   |   |   |TensorConstant{0} [id BX] <TensorType(int8, scalar)>\n |   | |   |   |   |Shape_i{0} [id GW] <TensorType(int64, scalar)> ''   \n |   | |   |   |     |<CudaNdarrayType(float32, vector)> [id GT] <CudaNdarrayType(float32, vector)>\n |   | |   |   |MakeVector{dtype='int64'} [id GX] <TensorType(int64, vector)> ''   \n |   | |   |     |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id Y] <TensorType(int64, scalar)> ''   \n |   | |   |     |Elemwise{Composite{Switch(LT(i0, i1), Switch(LT((i0 + i2), i1), i1, (i0 + i2)), Switch(LT(i0, i2), i0, i2))}}[(0, 2)] [id GV] <TensorType(int64, scalar)> ''   \n |   | |   |GpuSubtensor{:int64:} [id GY] <CudaNdarrayType(float32, matrix)> ''   \n |   | |     |GpuJoin [id GZ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |     | |TensorConstant{1} [id BP] <TensorType(int8, scalar)>\n |   | |     | |GpuReshape{2} [id HA] <CudaNdarrayType(float32, matrix)> ''   \n |   | |     | | |GpuAdvancedSubtensor1 [id HB] <CudaNdarrayType(float32, vector)> ''   \n |   | |     | | | |GpuReshape{1} [id HC] <CudaNdarrayType(float32, vector)> ''   \n |   | |     | | | | |GpuElemwise{mul,no_inplace} [id HD] <CudaNdarrayType(float32, matrix)> ''   \n |   | |     | | | | | |<CudaNdarrayType(float32, matrix)> [id HE] <CudaNdarrayType(float32, matrix)>\n |   | |     | | | | | |GpuFromHost [id HF] <CudaNdarrayType(float32, row)> ''   \n |   | |     | | | | |   |Elemwise{Cast{float32}} [id HG] <TensorType(float32, row)> ''   \n |   | |     | | | | |     |InplaceDimShuffle{x,0} [id HH] <TensorType(bool, row)> ''   \n |   | |     | | | | |       |Elemwise{eq,no_inplace} [id BI] <TensorType(bool, vector)> 'Yet simulated LITHOLOGY node'   \n |   | |     | | | | |TensorConstant{(1,) of -1} [id BJ] <TensorType(int64, (True,))>\n |   | |     | | | |Subtensor{int64} [id HI] <TensorType(int64, vector)> ''   \n |   | |     | | |   |Nonzero [id HJ] <TensorType(int64, matrix)> ''   \n |   | |     | | |   | |HostFromGpu [id HK] <TensorType(float32, vector)> ''   \n |   | |     | | |   |   |GpuReshape{1} [id HC] <CudaNdarrayType(float32, vector)> ''   \n |   | |     | | |   |Constant{0} [id DA] <int64>\n |   | |     | | |TensorConstant{[ 9 -1]} [id HL] <TensorType(int64, vector)>\n |   | |     | |<CudaNdarrayType(float32, matrix)> [id HM] <CudaNdarrayType(float32, matrix)>\n |   | |     |ScalarFromTensor [id GU] <int64> ''   \n |   | |GpuCAReduce{add}{1,0} [id HN] <CudaNdarrayType(float32, vector)> ''   \n |   |   |GpuElemwise{Mul}[(0, 0)] [id HO] <CudaNdarrayType(float32, matrix)> ''   \n |   |     |GpuSubtensor{int64::} [id HP] <CudaNdarrayType(float32, matrix)> ''   \n |   |     | |GpuDimShuffle{1,0} [id FC] <CudaNdarrayType(float32, matrix)> ''   \n |   |     | |ScalarFromTensor [id GN] <int64> ''   \n |   |     |GpuSubtensor{::, :int64:} [id HQ] <CudaNdarrayType(float32, matrix)> ''   \n |   |       |<CudaNdarrayType(float32, matrix)> [id HR] <CudaNdarrayType(float32, matrix)>\n |   |       |ScalarFromTensor [id HS] <int64> ''   \n |   |         |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id Y] <TensorType(int64, scalar)> ''   \n |   |<int64> [id HT] <int64>\n |   |<int64> [id HU] <int64>\n |Elemwise{add,no_inplace} [id HV] <TensorType(int64, vector)> ''   \n   |TensorConstant{(1,) of -1} [id BJ] <TensorType(int64, (True,))>\n   |Subtensor{int64:int64:} [id HW] <TensorType(int64, vector)> ''   \n     |Value of the formation_copy [id HX] <TensorType(int64, vector)>\n     |ScalarFromTensor [id HY] <int64> ''   \n     | |<TensorType(int64, scalar)> [id HZ] <TensorType(int64, scalar)>\n     |ScalarFromTensor [id IA] <int64> ''   \n       |<TensorType(int64, scalar)> [id IB] <TensorType(int64, scalar)>\n\nInner graphs of the scan ops:\n\nfor{gpu,scan_fn} [id B] <CudaNdarrayType(float32, vector)> ''   \n >GpuElemwise{true_div,no_inplace} [id IC] <CudaNdarrayType(float32, scalar)> ''   \n > |GpuCAReduce{add}{1} [id ID] <CudaNdarrayType(float32, scalar)> ''   \n > | |GpuSubtensor{int32:int32:} [id IE] <CudaNdarrayType(float32, vector)> ''   \n > |   |<CudaNdarrayType(float32, vector)> [id IF] <CudaNdarrayType(float32, vector)> -> [id J]\n > |   |ScalarFromTensor [id IG] <int32> ''   \n > |   | |<TensorType(int32, scalar)> [id IH] <TensorType(int32, scalar)> -> [id D]\n > |   |ScalarFromTensor [id II] <int32> ''   \n > |     |<TensorType(int32, scalar)> [id IJ] <TensorType(int32, scalar)> -> [id F]\n > |<CudaNdarrayType(float32, scalar)> [id IK] <CudaNdarrayType(float32, scalar)> -> [id H]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.\nApply node that caused the error: forall_inplace,gpu,scan_fn}(Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0, Subtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, GpuIncSubtensor{InplaceSet;:int64:}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}}.0, Coordinates of the grid points to interpolate, <CudaNdarrayType(float32, matrix)>, Value of the formation, <CudaNdarrayType(float32, vector)>, GpuFromHost.0, GpuFromHost.0, GpuFromHost.0, GpuFromHost.0, GpuFromHost.0, GpuFromHost.0, GpuDimShuffle{x}.0, GpuDimShuffle{x,x}.0, GpuDimShuffle{x,x}.0, GpuDimShuffle{x,x}.0, GpuElemwise{sqr,no_inplace}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{pow,no_inplace}.0, GpuElemwise{pow,no_inplace}.0, GpuElemwise{pow,no_inplace}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{neg,no_inplace}.0, GpuElemwise{true_div,no_inplace}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{Mul}[(0, 1)].0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace}.0, ScalarFromTensor.0, ScalarFromTensor.0, GpuElemwise{Composite{(((i0 * i1) / sqr(i2)) + i3)},no_inplace}.0, GpuAlloc{memset_0=True}.0, Elemwise{minimum,no_inplace}.0, GpuDimShuffle{1,0}.0, GpuIncSubtensor{InplaceSet;:int64:}.0, Subtensor{int64:int64:int8}.0, Subtensor{int64:int64:int8}.0)\nToposort index: 200\nInputs types: [TensorType(int64, scalar), TensorType(int64, vector), TensorType(int64, vector), TensorType(int64, vector), TensorType(int64, vector), TensorType(int64, vector), TensorType(int64, vector), TensorType(int64, vector), TensorType(int64, vector), TensorType(int64, vector), TensorType(int64, vector), TensorType(int64, vector), CudaNdarrayType(float32, 3D), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(int64, vector), CudaNdarrayType(float32, vector), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, vector), CudaNdarrayType(float32, vector), CudaNdarrayType(float32, vector), CudaNdarrayType(float32, (True,)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True,)), CudaNdarrayType(float32, (True,)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), CudaNdarrayType(float32, (True, True)), Scalar(int64), Scalar(int64), CudaNdarrayType(float32, scalar), CudaNdarrayType(float32, matrix), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, vector), TensorType(int64, vector), TensorType(int64, vector)]\nInputs shapes: [(), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (2, 3, 125000), (), (125000, 3), (9, 125000), (4,), (4,), (1, 3), (30, 3), (30, 3), (1,), (1,), (1,), (1,), (1, 1), (1, 1), (1, 1), (1,), (1,), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (), (), (), (0, 125060), (), (9, 60), (9,), (4,), (4,)]\nInputs strides: [(), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (375000, 125000, 1), (), (3, 1), (125000, 1), (8,), (1,), (0, 1), (3, 1), (3, 1), (0,), (0,), (0,), (0,), (0, 0), (0, 0), (0, 0), (0,), (0,), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (), (), (), (125060, 1), (), (1, 9), (1,), (8,), (8,)]\nInputs values: [array(1), array([125030]), array([125000]), array([125060]), array([125030]), array([0]), array([30]), array([0]), array([1]), array([0]), array([4]), array([3]), 'not shown', array(1), 'not shown', 'not shown', array([1, 2, 3, 5]), b'CudaNdarray([ 0.  0.  0.  0.])', b'CudaNdarray([[ 0.57702309  0.50010002  0.48086923]])', 'not shown', 'not shown', b'CudaNdarray([ 18.43499947])', b'CudaNdarray([ 90.])', b'CudaNdarray([ 1.])', b'CudaNdarray([ 2.])', b'CudaNdarray([[ 2.]])', b'CudaNdarray([[ 0.88823116]])', b'CudaNdarray([[ 0.01878463]])', b'CudaNdarray([ 4.])', b'CudaNdarray([ 4.])', b'CudaNdarray([[ 0.43619636]])', b'CudaNdarray([[ 0.70077407]])', b'CudaNdarray([[ 0.55287892]])', b'CudaNdarray([[ 0.07513854]])', b'CudaNdarray([[-0.01878463]])', b'CudaNdarray([[-17.74500084]])', b'CudaNdarray([[ 0.87239271]])', b'CudaNdarray([[ 15.77909279]])', b'CudaNdarray([[ 2.21151567]])', b'CudaNdarray([[ 9.33673954]])', -30, -60, b'CudaNdarray(0.34333333373069763)', b'CudaNdarray([])', array(4), 'not shown', 'not shown', array([13, 18, 25, 30]), array([ 0, 13, 18, 25])]\nInputs type_num: [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, '', 7, '', '', 7, '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 7, 7, '', '', 7, '', '', 7, 7]\nOutputs clients: [[GpuSubtensor{int64:int64:int8}(forall_inplace,gpu,scan_fn}.0, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})], [HostFromGpu(forall_inplace,gpu,scan_fn}.1)]]\n\nDebugprint of the apply node: \nforall_inplace,gpu,scan_fn}.0 [id A] <CudaNdarrayType(float32, 3D)> ''   \n |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id C] <TensorType(int64, scalar)> ''   \n | | |TensorConstant{-1} [id D] <TensorType(int64, scalar)>\n | | |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n | | | |Length of interfaces in every series [id F] <TensorType(int64, vector)>\n | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |Elemwise{sub,no_inplace} [id H] <TensorType(int64, scalar)> ''   \n | | |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id I] <TensorType(int64, scalar)> ''   \n | |   |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n | |   |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id K] <TensorType(int64, scalar)> ''   \n | | |TensorConstant{-1} [id D] <TensorType(int64, scalar)>\n | | |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | | | |Length of foliations in every series [id M] <TensorType(int64, vector)>\n | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |Elemwise{sub,no_inplace} [id N] <TensorType(int64, scalar)> ''   \n | | |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id O] <TensorType(int64, scalar)> ''   \n | |   |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n | |   |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id P] <TensorType(int64, scalar)> ''   \n | | |TensorConstant{-1} [id D] <TensorType(int64, scalar)>\n | | |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | | | |List with the number of formations [id R] <TensorType(int64, vector)>\n | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |Elemwise{sub,no_inplace} [id S] <TensorType(int64, scalar)> ''   \n | | |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id T] <TensorType(int64, scalar)> ''   \n | |   |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n | |   |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |Shape_i{0} [id U] <TensorType(int64, scalar)> ''   \n |   |Grade of the universal drift [id V] <TensorType(int64, vector)>\n |Elemwise{add,no_inplace} [id W] <TensorType(int64, vector)> ''   \n | |Elemwise{Composite{(i0 - (i1 * i2))}}[(0, 0)] [id X] <TensorType(int64, (True,))> ''   \n | | |InplaceDimShuffle{x} [id Y] <TensorType(int64, (True,))> ''   \n | | | |Elemwise{Composite{(i0 + (i1 * i2))}}[(0, 0)] [id Z] <TensorType(int64, scalar)> ''   \n | | |   |Shape_i{0} [id BA] <TensorType(int64, scalar)> ''   \n | | |   | |Coordinates of the grid points to interpolate [id BB] <CudaNdarrayType(float32, matrix)>\n | | |   |TensorConstant{2} [id BC] <TensorType(int64, scalar)>\n | | |   |Shape_i{0} [id BD] <TensorType(int64, scalar)> ''   \n | | |     |Rest of the points of the layers [id BE] <TensorType(float32, matrix)>\n | | |TensorConstant{(1,) of 2} [id BF] <TensorType(int64, (True,))>\n | | |InplaceDimShuffle{x} [id BG] <TensorType(int64, (True,))> ''   \n | |   |Shape_i{0} [id BD] <TensorType(int64, scalar)> ''   \n | |Subtensor{int64:int64:int64} [id BH] <TensorType(int64, vector)> ''   \n |   |Length of interfaces in every series [id F] <TensorType(int64, vector)>\n |   |ScalarFromTensor [id BI] <int64> ''   \n |   | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id BJ] <TensorType(int64, scalar)> ''   \n |   |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id BK] <TensorType(bool, scalar)> ''   \n |   |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4))}}[(0, 3)] [id BL] <TensorType(int64, scalar)> ''   \n |   |   | | |Elemwise{le,no_inplace} [id BM] <TensorType(bool, scalar)> ''   \n |   |   | | | |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i1, i5), i1, i5))}}[(0, 5)] [id BN] <TensorType(int64, scalar)> ''   \n |   |   | | | | |Elemwise{lt,no_inplace} [id BO] <TensorType(bool, scalar)> ''   \n |   |   | | | | | |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n |   |   | | | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   | | | | |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n |   |   | | | | |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n |   |   | | | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id I] <TensorType(int64, scalar)> ''   \n |   |   | | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   | | | | |Elemwise{sub,no_inplace} [id H] <TensorType(int64, scalar)> ''   \n |   |   | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id I] <TensorType(int64, scalar)> ''   \n |   |   | | |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i1, i5), i1, i5))}}[(0, 5)] [id BN] <TensorType(int64, scalar)> ''   \n |   |   | | |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n |   |   | | |TensorConstant{-1} [id BP] <TensorType(int8, scalar)>\n |   |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4)}}[(0, 2)] [id BQ] <TensorType(int64, scalar)> ''   \n |   |   | | |Elemwise{le,no_inplace} [id BM] <TensorType(bool, scalar)> ''   \n |   |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id I] <TensorType(int64, scalar)> ''   \n |   |   | | |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n |   |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4))}}[(0, 3)] [id BL] <TensorType(int64, scalar)> ''   \n |   |   | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4)}}[(0, 2)] [id BQ] <TensorType(int64, scalar)> ''   \n |   |   |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n |   |ScalarFromTensor [id BR] <int64> ''   \n |   | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id BS] <TensorType(int64, scalar)> ''   \n |   |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id BK] <TensorType(bool, scalar)> ''   \n |   |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4))}}[(0, 3)] [id BL] <TensorType(int64, scalar)> ''   \n |   |   |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n |   |Constant{1} [id BT] <int64>\n |Elemwise{add,no_inplace} [id BU] <TensorType(int64, vector)> ''   \n | |Elemwise{Composite{(i0 - (i1 * i2))}}[(0, 0)] [id X] <TensorType(int64, (True,))> ''   \n | |Subtensor{int64:int64:int64} [id BV] <TensorType(int64, vector)> ''   \n |   |Length of interfaces in every series [id F] <TensorType(int64, vector)>\n |   |ScalarFromTensor [id BW] <int64> ''   \n |   | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id BX] <TensorType(int64, scalar)> ''   \n |   |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id BY] <TensorType(bool, scalar)> ''   \n |   |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}}[(0, 2)] [id BZ] <TensorType(int64, scalar)> ''   \n |   |   | | |Elemwise{le,no_inplace} [id CA] <TensorType(bool, scalar)> ''   \n |   |   | | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id CB] <TensorType(int64, scalar)> ''   \n |   |   | | | | |Elemwise{lt,no_inplace} [id BO] <TensorType(bool, scalar)> ''   \n |   |   | | | | |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n |   |   | | | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id C] <TensorType(int64, scalar)> ''   \n |   |   | | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id CB] <TensorType(int64, scalar)> ''   \n |   |   | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id C] <TensorType(int64, scalar)> ''   \n |   |   | | |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n |   |   | | |TensorConstant{-1} [id BP] <TensorType(int8, scalar)>\n |   |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5)}}[(0, 3)] [id CC] <TensorType(int64, scalar)> ''   \n |   |   | | |Elemwise{le,no_inplace} [id CA] <TensorType(bool, scalar)> ''   \n |   |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   | | |TensorConstant{0} [id CD] <TensorType(int64, scalar)>\n |   |   | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id C] <TensorType(int64, scalar)> ''   \n |   |   | | |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n |   |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}}[(0, 2)] [id BZ] <TensorType(int64, scalar)> ''   \n |   |   | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5)}}[(0, 3)] [id CC] <TensorType(int64, scalar)> ''   \n |   |   |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n |   |ScalarFromTensor [id CE] <int64> ''   \n |   | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id CF] <TensorType(int64, scalar)> ''   \n |   |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id BY] <TensorType(bool, scalar)> ''   \n |   |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}}[(0, 2)] [id BZ] <TensorType(int64, scalar)> ''   \n |   |   |Shape_i{0} [id E] <TensorType(int64, scalar)> ''   \n |   |Constant{1} [id BT] <int64>\n |Elemwise{add,no_inplace} [id CG] <TensorType(int64, vector)> ''   \n | |Elemwise{Add}[(0, 0)] [id CH] <TensorType(int64, (True,))> ''   \n | | |Elemwise{Composite{(i0 - (i1 * i2))}}[(0, 0)] [id X] <TensorType(int64, (True,))> ''   \n | | |InplaceDimShuffle{x} [id BG] <TensorType(int64, (True,))> ''   \n | |Subtensor{int64:int64:int64} [id BH] <TensorType(int64, vector)> ''   \n |Elemwise{add,no_inplace} [id CI] <TensorType(int64, vector)> ''   \n | |Elemwise{Add}[(0, 0)] [id CH] <TensorType(int64, (True,))> ''   \n | |Subtensor{int64:int64:int64} [id BV] <TensorType(int64, vector)> ''   \n |Subtensor{int64:int64:int64} [id BV] <TensorType(int64, vector)> ''   \n |Subtensor{int64:int64:int64} [id BH] <TensorType(int64, vector)> ''   \n |Subtensor{int64:int64:int64} [id CJ] <TensorType(int64, vector)> ''   \n | |Length of foliations in every series [id M] <TensorType(int64, vector)>\n | |ScalarFromTensor [id CK] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id CL] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id CM] <TensorType(bool, scalar)> ''   \n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}}[(0, 2)] [id CN] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id CO] <TensorType(bool, scalar)> ''   \n | |   | | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id CP] <TensorType(int64, scalar)> ''   \n | |   | | | | |Elemwise{lt,no_inplace} [id BO] <TensorType(bool, scalar)> ''   \n | |   | | | | |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n | |   | | | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id K] <TensorType(int64, scalar)> ''   \n | |   | | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id CP] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id K] <TensorType(int64, scalar)> ''   \n | |   | | |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |   | | |TensorConstant{-1} [id BP] <TensorType(int8, scalar)>\n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5)}}[(0, 3)] [id CQ] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id CO] <TensorType(bool, scalar)> ''   \n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |TensorConstant{0} [id CD] <TensorType(int64, scalar)>\n | |   | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id K] <TensorType(int64, scalar)> ''   \n | |   | | |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}}[(0, 2)] [id CN] <TensorType(int64, scalar)> ''   \n | |   | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5)}}[(0, 3)] [id CQ] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |ScalarFromTensor [id CR] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id CS] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id CM] <TensorType(bool, scalar)> ''   \n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}}[(0, 2)] [id CN] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |Constant{1} [id BT] <int64>\n |Subtensor{int64:int64:int64} [id CT] <TensorType(int64, vector)> ''   \n | |Length of foliations in every series [id M] <TensorType(int64, vector)>\n | |ScalarFromTensor [id CU] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id CV] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id CW] <TensorType(bool, scalar)> ''   \n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4))}}[(0, 3)] [id CX] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id CY] <TensorType(bool, scalar)> ''   \n | |   | | | |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i1, i5), i1, i5))}}[(0, 5)] [id CZ] <TensorType(int64, scalar)> ''   \n | |   | | | | |Elemwise{lt,no_inplace} [id BO] <TensorType(bool, scalar)> ''   \n | |   | | | | |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n | |   | | | | |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |   | | | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id O] <TensorType(int64, scalar)> ''   \n | |   | | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | | | |Elemwise{sub,no_inplace} [id N] <TensorType(int64, scalar)> ''   \n | |   | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id O] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i1, i5), i1, i5))}}[(0, 5)] [id CZ] <TensorType(int64, scalar)> ''   \n | |   | | |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |   | | |TensorConstant{-1} [id BP] <TensorType(int8, scalar)>\n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4)}}[(0, 2)] [id DA] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id CY] <TensorType(bool, scalar)> ''   \n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id O] <TensorType(int64, scalar)> ''   \n | |   | | |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4))}}[(0, 3)] [id CX] <TensorType(int64, scalar)> ''   \n | |   | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4)}}[(0, 2)] [id DA] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |ScalarFromTensor [id DB] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id DC] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id CW] <TensorType(bool, scalar)> ''   \n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4))}}[(0, 3)] [id CX] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id L] <TensorType(int64, scalar)> ''   \n | |Constant{1} [id BT] <int64>\n |Subtensor{int64:int64:int64} [id DD] <TensorType(int64, vector)> ''   \n | |List with the number of formations [id R] <TensorType(int64, vector)>\n | |ScalarFromTensor [id DE] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id DF] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id DG] <TensorType(bool, scalar)> ''   \n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}}[(0, 2)] [id DH] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id DI] <TensorType(bool, scalar)> ''   \n | |   | | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id DJ] <TensorType(int64, scalar)> ''   \n | |   | | | | |Elemwise{lt,no_inplace} [id BO] <TensorType(bool, scalar)> ''   \n | |   | | | | |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n | |   | | | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id P] <TensorType(int64, scalar)> ''   \n | |   | | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id DJ] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id P] <TensorType(int64, scalar)> ''   \n | |   | | |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |   | | |TensorConstant{-1} [id BP] <TensorType(int8, scalar)>\n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5)}}[(0, 3)] [id DK] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id DI] <TensorType(bool, scalar)> ''   \n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |TensorConstant{0} [id CD] <TensorType(int64, scalar)>\n | |   | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id P] <TensorType(int64, scalar)> ''   \n | |   | | |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}}[(0, 2)] [id DH] <TensorType(int64, scalar)> ''   \n | |   | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5)}}[(0, 3)] [id DK] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |ScalarFromTensor [id DL] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id DM] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id DG] <TensorType(bool, scalar)> ''   \n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}}[(0, 2)] [id DH] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |Constant{1} [id BT] <int64>\n |Subtensor{int64:int64:int64} [id DN] <TensorType(int64, vector)> ''   \n | |List with the number of formations [id R] <TensorType(int64, vector)>\n | |ScalarFromTensor [id DO] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id DP] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id DQ] <TensorType(bool, scalar)> ''   \n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4))}}[(0, 3)] [id DR] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id DS] <TensorType(bool, scalar)> ''   \n | |   | | | |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i1, i5), i1, i5))}}[(0, 5)] [id DT] <TensorType(int64, scalar)> ''   \n | |   | | | | |Elemwise{lt,no_inplace} [id BO] <TensorType(bool, scalar)> ''   \n | |   | | | | |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n | |   | | | | |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |   | | | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id T] <TensorType(int64, scalar)> ''   \n | |   | | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | | | |Elemwise{sub,no_inplace} [id S] <TensorType(int64, scalar)> ''   \n | |   | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id T] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i1, i5), i1, i5))}}[(0, 5)] [id DT] <TensorType(int64, scalar)> ''   \n | |   | | |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |   | | |TensorConstant{-1} [id BP] <TensorType(int8, scalar)>\n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4)}}[(0, 2)] [id DU] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id DS] <TensorType(bool, scalar)> ''   \n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id T] <TensorType(int64, scalar)> ''   \n | |   | | |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4))}}[(0, 3)] [id DR] <TensorType(int64, scalar)> ''   \n | |   | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1), i3), i1), i4)}}[(0, 2)] [id DU] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |ScalarFromTensor [id DV] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id DW] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id DQ] <TensorType(bool, scalar)> ''   \n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum((i2 + i3), i4))}(i0, i1, i2, i3, i4), i1, i4), i1, i5), i4))}}[(0, 3)] [id DR] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id Q] <TensorType(int64, scalar)> ''   \n | |Constant{1} [id BT] <int64>\n |Subtensor{int64:int64:int64} [id DX] <TensorType(int64, vector)> ''   \n | |Grade of the universal drift [id V] <TensorType(int64, vector)>\n | |ScalarFromTensor [id DY] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id DZ] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id EA] <TensorType(bool, scalar)> ''   \n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1, i4), i3), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1, i4), i3))}}[(0, 2)] [id EB] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id EC] <TensorType(bool, scalar)> ''   \n | |   | | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id ED] <TensorType(int64, scalar)> ''   \n | |   | | | | |Elemwise{lt,no_inplace} [id BO] <TensorType(bool, scalar)> ''   \n | |   | | | | |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n | |   | | | | |Shape_i{0} [id U] <TensorType(int64, scalar)> ''   \n | |   | | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id ED] <TensorType(int64, scalar)> ''   \n | |   | | |Shape_i{0} [id U] <TensorType(int64, scalar)> ''   \n | |   | | |TensorConstant{-1} [id BP] <TensorType(int8, scalar)>\n | |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1), i3), i1), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1), i3), i1), i4)}} [id EE] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{le,no_inplace} [id EC] <TensorType(bool, scalar)> ''   \n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |TensorConstant{0} [id CD] <TensorType(int64, scalar)>\n | |   | | |Shape_i{0} [id U] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1, i4), i3), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1, i4), i3))}}[(0, 2)] [id EB] <TensorType(int64, scalar)> ''   \n | |   | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1), i3), i1), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1), i3), i1), i4)}} [id EE] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id U] <TensorType(int64, scalar)> ''   \n | |ScalarFromTensor [id EF] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id EG] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{LE((i0 - i1), i2)}} [id EA] <TensorType(bool, scalar)> ''   \n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1, i4), i3), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i3), i1, i4), i3))}}[(0, 2)] [id EB] <TensorType(int64, scalar)> ''   \n | |   |Shape_i{0} [id U] <TensorType(int64, scalar)> ''   \n | |Constant{1} [id BT] <int64>\n |GpuIncSubtensor{InplaceSet;:int64:} [id EH] <CudaNdarrayType(float32, 3D)> ''   \n | |GpuAllocEmpty [id EI] <CudaNdarrayType(float32, 3D)> ''   \n | | |Elemwise{Composite{(Switch(LT(maximum(i0, i1), i2), (maximum(i0, i1) + i3), (maximum(i0, i1) - i2)) + i3)}}[(0, 0)] [id EJ] <TensorType(int64, scalar)> ''   \n | | | |Elemwise{Composite{((i0 - i1) + i2)}} [id EK] <TensorType(int64, scalar)> ''   \n | | | | |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n | | | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id EL] <TensorType(int64, scalar)> ''   \n | | | | | |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n | | | | | |Elemwise{add,no_inplace} [id EM] <TensorType(int64, scalar)> ''   \n | | | | |   |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n | | | | |   |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n | | | | |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n | | | |TensorConstant{2} [id BC] <TensorType(int64, scalar)>\n | | | |TensorConstant{1} [id EN] <TensorType(int8, scalar)>\n | | | |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n | | |Elemwise{add,no_inplace} [id EO] <TensorType(int64, scalar)> ''   \n | | | |Shape_i{0} [id EP] <TensorType(int64, scalar)> ''   \n | | | | |final block of lithologies init [id EQ] <CudaNdarrayType(float32, matrix)>\n | | | |Shape_i{0} [id EP] <TensorType(int64, scalar)> ''   \n | | | |Shape_i{0} [id EP] <TensorType(int64, scalar)> ''   \n | | |Shape_i{1} [id ER] <TensorType(int64, scalar)> ''   \n | |   |final block of lithologies init [id EQ] <CudaNdarrayType(float32, matrix)>\n | |Rebroadcast{0} [id ES] <CudaNdarrayType(float32, 3D)> ''   \n | | |GpuDimShuffle{x,0,1} [id ET] <CudaNdarrayType(float32, (True, False, False))> ''   \n | |   |GpuJoin [id EU] <CudaNdarrayType(float32, matrix)> ''   \n | |     |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |     |final block of lithologies init [id EQ] <CudaNdarrayType(float32, matrix)>\n | |     |final block of lithologies init [id EQ] <CudaNdarrayType(float32, matrix)>\n | |     |final block of lithologies init [id EQ] <CudaNdarrayType(float32, matrix)>\n | |Constant{1} [id BT] <int64>\n |Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}} [id B] <TensorType(int64, scalar)> ''   \n |Coordinates of the grid points to interpolate [id BB] <CudaNdarrayType(float32, matrix)>\n |<CudaNdarrayType(float32, matrix)> [id EV] <CudaNdarrayType(float32, matrix)>\n |Value of the formation [id EW] <TensorType(int64, vector)>\n |<CudaNdarrayType(float32, vector)> [id EX] <CudaNdarrayType(float32, vector)>\n |GpuFromHost [id EY] <CudaNdarrayType(float32, matrix)> ''   \n | |Position of the dips [id EZ] <TensorType(float32, matrix)>\n |GpuFromHost [id FA] <CudaNdarrayType(float32, matrix)> ''   \n | |Rest of the points of the layers [id BE] <TensorType(float32, matrix)>\n |GpuFromHost [id FB] <CudaNdarrayType(float32, matrix)> ''   \n | |Reference points for every layer [id FC] <TensorType(float32, matrix)>\n |GpuFromHost [id FD] <CudaNdarrayType(float32, vector)> ''   \n | |Angle of every dip [id FE] <TensorType(float32, vector)>\n |GpuFromHost [id FF] <CudaNdarrayType(float32, vector)> ''   \n | |Azimuth [id FG] <TensorType(float32, vector)>\n |GpuFromHost [id FH] <CudaNdarrayType(float32, vector)> ''   \n | |Polarity [id FI] <TensorType(float32, vector)>\n |GpuDimShuffle{x} [id FJ] <CudaNdarrayType(float32, (True,))> ''   \n | |<CudaNdarrayType(float32, scalar)> [id FK] <CudaNdarrayType(float32, scalar)>\n |GpuDimShuffle{x,x} [id FL] <CudaNdarrayType(float32, (True, True))> ''   \n | |<CudaNdarrayType(float32, scalar)> [id FK] <CudaNdarrayType(float32, scalar)>\n |GpuDimShuffle{x,x} [id FM] <CudaNdarrayType(float32, (True, True))> ''   \n | |Range [id FN] <CudaNdarrayType(float32, scalar)>\n |GpuDimShuffle{x,x} [id FO] <CudaNdarrayType(float32, (True, True))> ''   \n | |Covariance at 0 [id FP] <CudaNdarrayType(float32, scalar)>\n |GpuElemwise{sqr,no_inplace} [id FQ] <CudaNdarrayType(float32, (True,))> ''   \n | |GpuDimShuffle{x} [id FJ] <CudaNdarrayType(float32, (True,))> ''   \n |GpuElemwise{mul,no_inplace} [id FR] <CudaNdarrayType(float32, (True,))> ''   \n | |CudaNdarrayConstant{[ 2.]} [id FS] <CudaNdarrayType(float32, (True,))>\n | |GpuDimShuffle{x} [id FJ] <CudaNdarrayType(float32, (True,))> ''   \n |GpuElemwise{pow,no_inplace} [id FT] <CudaNdarrayType(float32, (True, True))> ''   \n | |GpuDimShuffle{x,x} [id FM] <CudaNdarrayType(float32, (True, True))> ''   \n | |CudaNdarrayConstant{[[ 7.]]} [id FU] <CudaNdarrayType(float32, (True, True))>\n |GpuElemwise{pow,no_inplace} [id FV] <CudaNdarrayType(float32, (True, True))> ''   \n | |GpuDimShuffle{x,x} [id FM] <CudaNdarrayType(float32, (True, True))> ''   \n | |CudaNdarrayConstant{[[ 3.]]} [id FW] <CudaNdarrayType(float32, (True, True))>\n |GpuElemwise{pow,no_inplace} [id FX] <CudaNdarrayType(float32, (True, True))> ''   \n | |GpuDimShuffle{x,x} [id FM] <CudaNdarrayType(float32, (True, True))> ''   \n | |CudaNdarrayConstant{[[ 5.]]} [id FY] <CudaNdarrayType(float32, (True, True))>\n |GpuElemwise{mul,no_inplace} [id FZ] <CudaNdarrayType(float32, (True, True))> ''   \n | |GpuDimShuffle{x,x} [id FO] <CudaNdarrayType(float32, (True, True))> ''   \n | |GpuDimShuffle{x,x} [id GA] <CudaNdarrayType(float32, (True, True))> ''   \n |   |<CudaNdarrayType(float32, scalar)> [id GB] <CudaNdarrayType(float32, scalar)>\n |GpuElemwise{neg,no_inplace} [id GC] <CudaNdarrayType(float32, (True, True))> ''   \n | |GpuDimShuffle{x,x} [id FO] <CudaNdarrayType(float32, (True, True))> ''   \n |GpuElemwise{true_div,no_inplace} [id GD] <CudaNdarrayType(float32, (True, True))> ''   \n | |CudaNdarrayConstant{[[-14.]]} [id GE] <CudaNdarrayType(float32, (True, True))>\n | |GpuElemwise{sqr,no_inplace} [id GF] <CudaNdarrayType(float32, (True, True))> ''   \n |   |GpuDimShuffle{x,x} [id FM] <CudaNdarrayType(float32, (True, True))> ''   \n |GpuElemwise{mul,no_inplace} [id GG] <CudaNdarrayType(float32, (True, True))> ''   \n | |CudaNdarrayConstant{[[ 2.]]} [id GH] <CudaNdarrayType(float32, (True, True))>\n | |GpuElemwise{pow,no_inplace} [id FT] <CudaNdarrayType(float32, (True, True))> ''   \n |GpuElemwise{Mul}[(0, 1)] [id GI] <CudaNdarrayType(float32, (True, True))> ''   \n | |CudaNdarrayConstant{[[ 20.]]} [id GJ] <CudaNdarrayType(float32, (True, True))>\n | |GpuElemwise{sqr,no_inplace} [id GF] <CudaNdarrayType(float32, (True, True))> ''   \n |GpuElemwise{mul,no_inplace} [id GK] <CudaNdarrayType(float32, (True, True))> ''   \n | |CudaNdarrayConstant{[[ 4.]]} [id GL] <CudaNdarrayType(float32, (True, True))>\n | |GpuElemwise{pow,no_inplace} [id FX] <CudaNdarrayType(float32, (True, True))> ''   \n |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id GM] <CudaNdarrayType(float32, (True, True))> ''   \n | |CudaNdarrayConstant{[[ 15.]]} [id GN] <CudaNdarrayType(float32, (True, True))>\n | |GpuDimShuffle{x,x} [id FM] <CudaNdarrayType(float32, (True, True))> ''   \n | |CudaNdarrayConstant{[[ 4.]]} [id GL] <CudaNdarrayType(float32, (True, True))>\n |ScalarFromTensor [id GO] <int64> ''   \n | |Elemwise{neg,no_inplace} [id GP] <TensorType(int64, scalar)> ''   \n |   |Shape_i{0} [id BD] <TensorType(int64, scalar)> ''   \n |ScalarFromTensor [id GQ] <int64> ''   \n | |Elemwise{Mul}[(0, 1)] [id GR] <TensorType(int64, scalar)> ''   \n |   |TensorConstant{-2} [id GS] <TensorType(int64, scalar)>\n |   |Shape_i{0} [id BD] <TensorType(int64, scalar)> ''   \n |GpuElemwise{Composite{(((i0 * i1) / sqr(i2)) + i3)},no_inplace} [id GT] <CudaNdarrayType(float32, scalar)> ''   \n | |CudaNdarrayConstant{14.0} [id GU] <CudaNdarrayType(float32, scalar)>\n | |Covariance at 0 [id FP] <CudaNdarrayType(float32, scalar)>\n | |Range [id FN] <CudaNdarrayType(float32, scalar)>\n | |<CudaNdarrayType(float32, scalar)> [id GV] <CudaNdarrayType(float32, scalar)>\n |GpuAlloc{memset_0=True} [id GW] <CudaNdarrayType(float32, matrix)> ''   \n | |CudaNdarrayConstant{0.0} [id GX] <CudaNdarrayType(float32, scalar)>\n | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |Elemwise{Composite{(i0 + (i1 * i2))}}[(0, 0)] [id Z] <TensorType(int64, scalar)> ''   \n |Elemwise{minimum,no_inplace} [id GY] <TensorType(int64, scalar)> ''   \n | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id GZ] <TensorType(int64, scalar)> ''   \n | | |TensorConstant{-1} [id D] <TensorType(int64, scalar)>\n | | |Prod{axis=None, dtype='int64', acc_dtype='int64'} [id HA] <TensorType(int64, scalar)> ''   \n | | | |MakeVector{dtype='int64'} [id HB] <TensorType(int64, vector)> ''   \n | | |   |Elemwise{Add}[(0, 1)] [id HC] <TensorType(int64, scalar)> ''   \n | | |     |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n | | |     |Shape_i{0} [id HD] <TensorType(int64, scalar)> ''   \n | | |       |<TensorType(int64, vector)> [id HE] <TensorType(int64, vector)>\n | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |Elemwise{sub,no_inplace} [id HF] <TensorType(int64, scalar)> ''   \n |   |Prod{axis=None, dtype='int64', acc_dtype='int64'} [id HA] <TensorType(int64, scalar)> ''   \n |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id HG] <TensorType(int64, scalar)> ''   \n |     |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n |     |Prod{axis=None, dtype='int64', acc_dtype='int64'} [id HA] <TensorType(int64, scalar)> ''   \n |GpuDimShuffle{1,0} [id HH] <CudaNdarrayType(float32, matrix)> ''   \n | |GpuJoin [id HI] <CudaNdarrayType(float32, matrix)> ''   \n |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n |   |GpuJoin [id HJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | |TensorConstant{1} [id EN] <TensorType(int8, scalar)>\n |   | |GpuFromHost [id FA] <CudaNdarrayType(float32, matrix)> ''   \n |   | |GpuElemwise{sqr,no_inplace} [id HK] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |GpuFromHost [id FA] <CudaNdarrayType(float32, matrix)> ''   \n |   | |GpuJoin [id HL] <CudaNdarrayType(float32, matrix)> ''   \n |   |   |TensorConstant{1} [id EN] <TensorType(int8, scalar)>\n |   |   |GpuElemwise{mul,no_inplace} [id HM] <CudaNdarrayType(float32, col)> ''   \n |   |   | |GpuDimShuffle{0,x} [id HN] <CudaNdarrayType(float32, col)> ''   \n |   |   | | |GpuSubtensor{::, int64} [id HO] <CudaNdarrayType(float32, vector)> ''   \n |   |   | |   |GpuFromHost [id FA] <CudaNdarrayType(float32, matrix)> ''   \n |   |   | |   |Constant{0} [id HP] <int64>\n |   |   | |GpuDimShuffle{0,x} [id HQ] <CudaNdarrayType(float32, col)> ''   \n |   |   |   |GpuSubtensor{::, int64} [id HR] <CudaNdarrayType(float32, vector)> ''   \n |   |   |     |GpuFromHost [id FA] <CudaNdarrayType(float32, matrix)> ''   \n |   |   |     |Constant{1} [id BT] <int64>\n |   |   |GpuElemwise{mul,no_inplace} [id HS] <CudaNdarrayType(float32, col)> ''   \n |   |   | |GpuDimShuffle{0,x} [id HN] <CudaNdarrayType(float32, col)> ''   \n |   |   | |GpuDimShuffle{0,x} [id HT] <CudaNdarrayType(float32, col)> ''   \n |   |   |   |GpuSubtensor{::, int64} [id HU] <CudaNdarrayType(float32, vector)> ''   \n |   |   |     |GpuFromHost [id FA] <CudaNdarrayType(float32, matrix)> ''   \n |   |   |     |Constant{2} [id HV] <int64>\n |   |   |GpuElemwise{mul,no_inplace} [id HW] <CudaNdarrayType(float32, col)> ''   \n |   |     |GpuDimShuffle{0,x} [id HQ] <CudaNdarrayType(float32, col)> ''   \n |   |     |GpuDimShuffle{0,x} [id HT] <CudaNdarrayType(float32, col)> ''   \n |   |GpuJoin [id HX] <CudaNdarrayType(float32, matrix)> ''   \n |     |TensorConstant{1} [id EN] <TensorType(int8, scalar)>\n |     |GpuFromHost [id FB] <CudaNdarrayType(float32, matrix)> ''   \n |     |GpuElemwise{sqr,no_inplace} [id HY] <CudaNdarrayType(float32, matrix)> ''   \n |     | |GpuFromHost [id FB] <CudaNdarrayType(float32, matrix)> ''   \n |     |GpuJoin [id HZ] <CudaNdarrayType(float32, matrix)> ''   \n |       |TensorConstant{1} [id EN] <TensorType(int8, scalar)>\n |       |GpuElemwise{mul,no_inplace} [id IA] <CudaNdarrayType(float32, col)> ''   \n |       | |GpuDimShuffle{0,x} [id IB] <CudaNdarrayType(float32, col)> ''   \n |       | | |GpuSubtensor{::, int64} [id IC] <CudaNdarrayType(float32, vector)> ''   \n |       | |   |GpuFromHost [id FB] <CudaNdarrayType(float32, matrix)> ''   \n |       | |   |Constant{0} [id HP] <int64>\n |       | |GpuDimShuffle{0,x} [id ID] <CudaNdarrayType(float32, col)> ''   \n |       |   |GpuSubtensor{::, int64} [id IE] <CudaNdarrayType(float32, vector)> ''   \n |       |     |GpuFromHost [id FB] <CudaNdarrayType(float32, matrix)> ''   \n |       |     |Constant{1} [id BT] <int64>\n |       |GpuElemwise{mul,no_inplace} [id IF] <CudaNdarrayType(float32, col)> ''   \n |       | |GpuDimShuffle{0,x} [id IB] <CudaNdarrayType(float32, col)> ''   \n |       | |GpuDimShuffle{0,x} [id IG] <CudaNdarrayType(float32, col)> ''   \n |       |   |GpuSubtensor{::, int64} [id IH] <CudaNdarrayType(float32, vector)> ''   \n |       |     |GpuFromHost [id FB] <CudaNdarrayType(float32, matrix)> ''   \n |       |     |Constant{2} [id HV] <int64>\n |       |GpuElemwise{mul,no_inplace} [id II] <CudaNdarrayType(float32, col)> ''   \n |         |GpuDimShuffle{0,x} [id ID] <CudaNdarrayType(float32, col)> ''   \n |         |GpuDimShuffle{0,x} [id IG] <CudaNdarrayType(float32, col)> ''   \n |GpuIncSubtensor{InplaceSet;:int64:} [id IJ] <CudaNdarrayType(float32, vector)> ''   \n | |GpuReshape{1} [id IK] <CudaNdarrayType(float32, vector)> ''   \n | | |GpuAlloc [id IL] <CudaNdarrayType(float32, row)> ''   \n | | | |GpuDimShuffle{0,x} [id IM] <CudaNdarrayType(float32, (True, True))> ''   \n | | | | |Rebroadcast{1} [id IN] <CudaNdarrayType(float32, (True,))> ''   \n | | | |   |GpuReshape{1} [id IO] <CudaNdarrayType(float32, vector)> ''   \n | | | |     |<CudaNdarrayType(float32, scalar)> [id FK] <CudaNdarrayType(float32, scalar)>\n | | | |     |TensorConstant{(1,) of -1} [id IP] <TensorType(int64, (True,))>\n | | | |TensorConstant{1} [id J] <TensorType(int64, scalar)>\n | | | |TensorConstant{9} [id IQ] <TensorType(int8, scalar)>\n | | |TensorConstant{(1,) of 9} [id IR] <TensorType(int64, vector)>\n | |CudaNdarrayConstant{1.0} [id IS] <CudaNdarrayType(float32, scalar)>\n | |Constant{3} [id IT] <int64>\n |Subtensor{int64:int64:int8} [id IU] <TensorType(int64, vector)> ''   \n | |CumOp{None, add} [id IV] <TensorType(int64, vector)> ''   \n | | |Join [id IW] <TensorType(int64, vector)> ''   \n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |TensorConstant{(1,) of 0} [id IX] <TensorType(int8, vector)>\n | |   |<TensorType(int64, vector)> [id HE] <TensorType(int64, vector)>\n | |ScalarFromTensor [id IY] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}} [id IZ] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{le,no_inplace} [id JA] <TensorType(bool, scalar)> ''   \n | |   | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}[(0, 2)] [id JB] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{lt,no_inplace} [id JC] <TensorType(bool, scalar)> ''   \n | |   | | | |Elemwise{minimum,no_inplace} [id GY] <TensorType(int64, scalar)> ''   \n | |   | | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | | |Elemwise{minimum,no_inplace} [id GY] <TensorType(int64, scalar)> ''   \n | |   | | |Elemwise{sub,no_inplace} [id HF] <TensorType(int64, scalar)> ''   \n | |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id HG] <TensorType(int64, scalar)> ''   \n | |   |Prod{axis=None, dtype='int64', acc_dtype='int64'} [id HA] <TensorType(int64, scalar)> ''   \n | |ScalarFromTensor [id JD] <int64> ''   \n | | |Elemwise{Composite{Switch(i0, i1, minimum((i2 + i3), i4))}}[(0, 2)] [id JE] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{le,no_inplace} [id JA] <TensorType(bool, scalar)> ''   \n | |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id HG] <TensorType(int64, scalar)> ''   \n | |   |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}[(0, 2)] [id JB] <TensorType(int64, scalar)> ''   \n | |   |Prod{axis=None, dtype='int64', acc_dtype='int64'} [id HA] <TensorType(int64, scalar)> ''   \n | |Constant{1} [id JF] <int8>\n |Subtensor{int64:int64:int8} [id JG] <TensorType(int64, vector)> ''   \n   |CumOp{None, add} [id IV] <TensorType(int64, vector)> ''   \n   |ScalarFromTensor [id JH] <int64> ''   \n   | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 3)] [id JI] <TensorType(int64, scalar)> ''   \n   |   |Elemwise{le,no_inplace} [id JJ] <TensorType(bool, scalar)> ''   \n   |   | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id JK] <TensorType(int64, scalar)> ''   \n   |   | | |Elemwise{lt,no_inplace} [id JC] <TensorType(bool, scalar)> ''   \n   |   | | |Elemwise{minimum,no_inplace} [id GY] <TensorType(int64, scalar)> ''   \n   |   | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id GZ] <TensorType(int64, scalar)> ''   \n   |   | | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n   |   | |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n   |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n   |   |TensorConstant{0} [id CD] <TensorType(int64, scalar)>\n   |   |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id GZ] <TensorType(int64, scalar)> ''   \n   |ScalarFromTensor [id JL] <int64> ''   \n   | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id JM] <TensorType(int64, scalar)> ''   \n   |   |Elemwise{le,no_inplace} [id JJ] <TensorType(bool, scalar)> ''   \n   |   |TensorConstant{0} [id G] <TensorType(int8, scalar)>\n   |   |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}} [id JK] <TensorType(int64, scalar)> ''   \n   |   |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id GZ] <TensorType(int64, scalar)> ''   \n   |Constant{1} [id JF] <int8>\nforall_inplace,gpu,scan_fn}.1 [id A] <CudaNdarrayType(float32, matrix)> ''   \n\nInner graphs of the scan ops:\n\nforall_inplace,gpu,scan_fn}.0 [id A] <CudaNdarrayType(float32, 3D)> ''   \n >GpuFromHost [id JN] <CudaNdarrayType(float32, matrix)> ''   \n > |AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True} [id JO] <TensorType(float32, matrix)> ''   \n >   |AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True} [id JP] <TensorType(float32, matrix)> ''   \n >   | |HostFromGpu [id JQ] <TensorType(float32, matrix)> ''   \n >   | | |<CudaNdarrayType(float32, matrix)> [id JR] <CudaNdarrayType(float32, matrix)> -> [id EH]\n >   | |Subtensor{:int64:} [id JS] <TensorType(int64, vector)> ''   \n >   | | |Sum{axis=[0], acc_dtype=int64} [id JT] <TensorType(int64, vector)> 'The chunk of block model of a specific series'   \n >   | | |<int64> [id JU] <int64> -> [id GQ]\n >   | |TensorConstant{0} [id JV] <TensorType(int64, scalar)>\n >   | |Subtensor{int64} [id JW] <TensorType(int64, vector)> ''   \n >   |   |Nonzero [id JX] <TensorType(int64, matrix)> ''   \n >   |   | |Elemwise{Cast{int8}} [id JY] <TensorType(int8, vector)> ''   \n >   |   |   |Elemwise{eq,no_inplace} [id JZ] <TensorType(bool, vector)> 'Yet simulated LITHOLOGY node'   \n >   |   |Constant{0} [id KA] <int64>\n >   |HostFromGpu [id KB] <TensorType(float32, vector)> ''   \n >   | |GpuSubtensor{:int64:} [id KC] <CudaNdarrayType(float32, vector)> ''   \n >   |   |GpuElemwise{Composite{((((i0 * i1 * i2 * i3) + (-i4)) + i5) + i6)}}[(0, 3)] [id KD] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |CudaNdarrayConstant{[-1.]} [id KE] <CudaNdarrayType(float32, (True,))>\n >   |   | |GpuDimShuffle{x} [id KF] <CudaNdarrayType(float32, (True,))> ''   \n >   |   | | |<CudaNdarrayType(float32, (True, True))> [id KG] <CudaNdarrayType(float32, (True, True))> -> [id FL]\n >   |   | |GpuDimShuffle{x} [id KH] <CudaNdarrayType(float32, (True,))> ''   \n >   |   | | |<CudaNdarrayType(float32, (True, True))> [id KI] <CudaNdarrayType(float32, (True, True))> -> [id GC]\n >   |   | |GpuCAReduce{add}{1,0} [id KJ] <CudaNdarrayType(float32, vector)> ''   \n >   |   | | |GpuElemwise{Composite{(i0 * i1 * i2 * (((i3 + (i4 / i5)) - ((i6 * i7) / i8)) + ((i9 * i10) / i11)))}}[(0, 0)] [id KK] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   |GpuFromHost [id KL] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |Subtensor{:int64:} [id KM] <TensorType(float32, matrix)> ''   \n >   |   | |   |   |InplaceDimShuffle{1,0} [id KN] <TensorType(float32, matrix)> ''   \n >   |   | |   |   | |Reshape{2} [id KO] <TensorType(float32, matrix)> ''   \n >   |   | |   |   |   |Alloc [id KP] <TensorType(float32, (False, True, True, False))> ''   \n >   |   | |   |   |   | |Reshape{1} [id KQ] <TensorType(float32, vector)> 'Dual Kriging parameters'   \n >   |   | |   |   |   | |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id KR] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   | | |Shape_i{1} [id KS] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   | | | |Nonzero [id KT] <TensorType(int64, matrix)> ''   \n >   |   | |   |   |   | | |   |HostFromGpu [id KU] <TensorType(float32, vector)> ''   \n >   |   | |   |   |   | | |     |GpuReshape{1} [id KV] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   |   |   | | |       |GpuElemwise{mul,no_inplace} [id KW] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   |   |   | | |       | |Coordinates of the grid points to interpolate_copy[cuda] [id KX] <CudaNdarrayType(float32, matrix)> -> [id BB]\n >   |   | |   |   |   | | |       | |GpuFromHost [id KY] <CudaNdarrayType(float32, col)> ''   \n >   |   | |   |   |   | | |       |   |Elemwise{Cast{float32}} [id KZ] <TensorType(float32, col)> ''   \n >   |   | |   |   |   | | |       |     |InplaceDimShuffle{0,x} [id LA] <TensorType(bool, col)> ''   \n >   |   | |   |   |   | | |       |       |Elemwise{eq,no_inplace} [id JZ] <TensorType(bool, vector)> 'Yet simulated LITHOLOGY node'   \n >   |   | |   |   |   | | |       |TensorConstant{(1,) of -1} [id LB] <TensorType(int64, (True,))>\n >   |   | |   |   |   | | |TensorConstant{3} [id LC] <TensorType(int64, scalar)>\n >   |   | |   |   |   | | |Shape_i{0} [id LD] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   | | | |Rest of the points of the layers_copy[cuda] [id LE] <CudaNdarrayType(float32, matrix)> -> [id FA]\n >   |   | |   |   |   | | |Shape_i{0} [id LF] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   | |   |Reference points for every layer_copy[cuda] [id LG] <CudaNdarrayType(float32, matrix)> -> [id FB]\n >   |   | |   |   |   | |TensorConstant{1} [id LH] <TensorType(int8, scalar)>\n >   |   | |   |   |   | |TensorConstant{1} [id LH] <TensorType(int8, scalar)>\n >   |   | |   |   |   | |Elemwise{add,no_inplace} [id LI] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   |Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i3 * i4) // (i5 * i3 * i4)), i0)}}[(0, 0)] [id LJ] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | |Elemwise{mul,no_inplace} [id LK] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | | |TensorConstant{3} [id LC] <TensorType(int64, scalar)>\n >   |   | |   |   |   |   | | |Elemwise{sub,no_inplace} [id LL] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id LM] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | |   | |Elemwise{lt,no_inplace} [id LN] <TensorType(bool, scalar)> ''   \n >   |   | |   |   |   |   | |   | | |<TensorType(int64, scalar)> [id LO] <TensorType(int64, scalar)> -> [id CT]\n >   |   | |   |   |   |   | |   | | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   | |   | |<TensorType(int64, scalar)> [id LO] <TensorType(int64, scalar)> -> [id CT]\n >   |   | |   |   |   |   | |   | |Shape_i{0} [id LQ] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | |   | | |Position of the dips_copy[cuda] [id LR] <CudaNdarrayType(float32, matrix)> -> [id EY]\n >   |   | |   |   |   |   | |   | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   | |   | |TensorConstant{-1} [id LS] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4)}}[(0, 2)] [id LT] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | |     |Elemwise{lt,no_inplace} [id LU] <TensorType(bool, scalar)> ''   \n >   |   | |   |   |   |   | |     | |<TensorType(int64, scalar)> [id LV] <TensorType(int64, scalar)> -> [id CJ]\n >   |   | |   |   |   |   | |     | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   | |     |<TensorType(int64, scalar)> [id LV] <TensorType(int64, scalar)> -> [id CJ]\n >   |   | |   |   |   |   | |     |Shape_i{0} [id LQ] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | |     |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   | |     |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id LM] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | |TensorConstant{-1} [id LS] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   | |TensorConstant{3} [id LC] <TensorType(int64, scalar)>\n >   |   | |   |   |   |   | |Elemwise{sub,no_inplace} [id LL] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | |Shape_i{1} [id LW] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | | |Position of the dips_copy[cuda] [id LR] <CudaNdarrayType(float32, matrix)> -> [id EY]\n >   |   | |   |   |   |   | |TensorConstant{-3} [id LX] <TensorType(int64, scalar)>\n >   |   | |   |   |   |   |Elemwise{sub,no_inplace} [id LY] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id LZ] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | | |Elemwise{lt,no_inplace} [id MA] <TensorType(bool, scalar)> ''   \n >   |   | |   |   |   |   | | | |<TensorType(int64, scalar)> [id MB] <TensorType(int64, scalar)> -> [id BH]\n >   |   | |   |   |   |   | | | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   | | |<TensorType(int64, scalar)> [id MB] <TensorType(int64, scalar)> -> [id BH]\n >   |   | |   |   |   |   | | |Shape_i{0} [id LD] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   | | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   | | |TensorConstant{-1} [id LS] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4)}}[(0, 2)] [id MC] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   |   |Elemwise{lt,no_inplace} [id MD] <TensorType(bool, scalar)> ''   \n >   |   | |   |   |   |   |   | |<TensorType(int64, scalar)> [id ME] <TensorType(int64, scalar)> -> [id BV]\n >   |   | |   |   |   |   |   | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   |   |<TensorType(int64, scalar)> [id ME] <TensorType(int64, scalar)> -> [id BV]\n >   |   | |   |   |   |   |   |Shape_i{0} [id LD] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   |   |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   |   |   |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id LZ] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |   |<TensorType(int64, scalar)> [id MF] <TensorType(int64, scalar)> -> [id DX]\n >   |   | |   |   |   |MakeVector{dtype='int64'} [id MG] <TensorType(int64, vector)> ''   \n >   |   | |   |   |     |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id KR] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |     |Elemwise{add,no_inplace} [id LI] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |ScalarFromTensor [id MH] <int64> ''   \n >   |   | |   |     |Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i3 * i4) // (i5 * i3 * i4)), i0)}}[(0, 0)] [id LJ] <TensorType(int64, scalar)> ''   \n >   |   | |   |GpuJoin [id MI] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   | |GpuElemwise{sub,no_inplace} [id MJ] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |GpuDimShuffle{0,x} [id MK] <CudaNdarrayType(float32, col)> ''   \n >   |   | |   | | | |GpuSubtensor{int64:int64:int8, int64} [id ML] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | | |   |Position of the dips_copy[cuda] [id LR] <CudaNdarrayType(float32, matrix)> -> [id EY]\n >   |   | |   | | |   |ScalarFromTensor [id MM] <int64> ''   \n >   |   | |   | | |   | |Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)] [id MN] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |   |   |Elemwise{le,no_inplace} [id MO] <TensorType(bool, scalar)> ''   \n >   |   | |   | | |   |   | |Elemwise{sub,no_inplace} [id LL] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |   |   | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   | | |   |   |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   | | |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3), i2), i3), i4)}}[(0, 2)] [id LT] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id LM] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |   |ScalarFromTensor [id MP] <int64> ''   \n >   |   | |   | | |   | |Elemwise{Switch}[(0, 2)] [id MQ] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |   |   |Elemwise{le,no_inplace} [id MO] <TensorType(bool, scalar)> ''   \n >   |   | |   | | |   |   |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   | | |   |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i3), i3, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2))}} [id LM] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |   |Constant{1} [id MR] <int8>\n >   |   | |   | | |   |Constant{0} [id KA] <int64>\n >   |   | |   | | |GpuDimShuffle{x,0} [id MS] <CudaNdarrayType(float32, row)> ''   \n >   |   | |   | |   |GpuSubtensor{::, int64} [id MT] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | |     |GpuJoin [id MU] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |     | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   | |     | |GpuJoin [id MV] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |     | | |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   | |     | | |GpuReshape{2} [id MW] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |     | | | |GpuAdvancedSubtensor1 [id MX] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | |     | | | | |GpuReshape{1} [id KV] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | |     | | | | |Subtensor{int64} [id MY] <TensorType(int64, vector)> ''   \n >   |   | |   | |     | | | |   |Nonzero [id KT] <TensorType(int64, matrix)> ''   \n >   |   | |   | |     | | | |   |Constant{0} [id KA] <int64>\n >   |   | |   | |     | | | |TensorConstant{[-1  3]} [id MZ] <TensorType(int64, vector)>\n >   |   | |   | |     | | |Rest of the points of the layers_copy[cuda] [id LE] <CudaNdarrayType(float32, matrix)> -> [id FA]\n >   |   | |   | |     | |Reference points for every layer_copy[cuda] [id LG] <CudaNdarrayType(float32, matrix)> -> [id FB]\n >   |   | |   | |     |Constant{0} [id KA] <int64>\n >   |   | |   | |GpuElemwise{sub,no_inplace} [id NA] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |GpuDimShuffle{0,x} [id NB] <CudaNdarrayType(float32, col)> ''   \n >   |   | |   | | | |GpuSubtensor{int64:int64:int8, int64} [id NC] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | | |   |Position of the dips_copy[cuda] [id LR] <CudaNdarrayType(float32, matrix)> -> [id EY]\n >   |   | |   | | |   |ScalarFromTensor [id MM] <int64> ''   \n >   |   | |   | | |   |ScalarFromTensor [id MP] <int64> ''   \n >   |   | |   | | |   |Constant{1} [id MR] <int8>\n >   |   | |   | | |   |Constant{1} [id ND] <int64>\n >   |   | |   | | |GpuDimShuffle{x,0} [id NE] <CudaNdarrayType(float32, row)> ''   \n >   |   | |   | |   |GpuSubtensor{::, int64} [id NF] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | |     |GpuJoin [id MU] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |     |Constant{1} [id ND] <int64>\n >   |   | |   | |GpuElemwise{sub,no_inplace} [id NG] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   |   |GpuDimShuffle{0,x} [id NH] <CudaNdarrayType(float32, col)> ''   \n >   |   | |   |   | |GpuSubtensor{int64:int64:int8, int64} [id NI] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   |   |   |Position of the dips_copy[cuda] [id LR] <CudaNdarrayType(float32, matrix)> -> [id EY]\n >   |   | |   |   |   |ScalarFromTensor [id MM] <int64> ''   \n >   |   | |   |   |   |ScalarFromTensor [id MP] <int64> ''   \n >   |   | |   |   |   |Constant{1} [id MR] <int8>\n >   |   | |   |   |   |Constant{2} [id NJ] <int64>\n >   |   | |   |   |GpuDimShuffle{x,0} [id NK] <CudaNdarrayType(float32, row)> ''   \n >   |   | |   |     |GpuSubtensor{::, int64} [id NL] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   |       |GpuJoin [id MU] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   |       |Constant{2} [id NJ] <int64>\n >   |   | |   |GpuElemwise{Composite{Cast{float32}(LT(i0, i1))},no_inplace} [id NM] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id NN] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |GpuDimShuffle{0,x} [id NO] <CudaNdarrayType(float32, col)> ''   \n >   |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id NP] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | | |   |GpuReshape{2} [id NQ] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |     |GpuAlloc [id NR] <CudaNdarrayType(float32, (False, True, False, False))> ''   \n >   |   | |   | | |     | |GpuSubtensor{int64:int64:} [id NS] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |     | | |Position of the dips_copy[cuda] [id LR] <CudaNdarrayType(float32, matrix)> -> [id EY]\n >   |   | |   | | |     | | |ScalarFromTensor [id NT] <int64> ''   \n >   |   | |   | | |     | | | |<TensorType(int64, scalar)> [id LV] <TensorType(int64, scalar)> -> [id CJ]\n >   |   | |   | | |     | | |ScalarFromTensor [id NU] <int64> ''   \n >   |   | |   | | |     | |   |<TensorType(int64, scalar)> [id LO] <TensorType(int64, scalar)> -> [id CT]\n >   |   | |   | | |     | |TensorConstant{3} [id NV] <TensorType(int8, scalar)>\n >   |   | |   | | |     | |TensorConstant{1} [id LH] <TensorType(int8, scalar)>\n >   |   | |   | | |     | |Elemwise{sub,no_inplace} [id LL] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |     | |Shape_i{1} [id LW] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |     |MakeVector{dtype='int64'} [id NW] <TensorType(int64, vector)> ''   \n >   |   | |   | | |       |Elemwise{mul,no_inplace} [id LK] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |       |Shape_i{1} [id LW] <TensorType(int64, scalar)> ''   \n >   |   | |   | | |GpuDimShuffle{x,0} [id NX] <CudaNdarrayType(float32, row)> ''   \n >   |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id NY] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | | |   |GpuJoin [id MU] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |GpuDot22Scalar [id NZ] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | |GpuReshape{2} [id NQ] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | |GpuDimShuffle{1,0} [id OA] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | | |GpuJoin [id MU] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | |TensorConstant{2.0} [id OB] <TensorType(float32, scalar)>\n >   |   | |   | | |CudaNdarrayConstant{[[ 0.]]} [id OC] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |<CudaNdarrayType(float32, (True, True))> [id OD] <CudaNdarrayType(float32, (True, True))> -> [id FM]\n >   |   | |   |<CudaNdarrayType(float32, (True, True))> [id OE] <CudaNdarrayType(float32, (True, True))> -> [id GD]\n >   |   | |   |GpuElemwise{mul,no_inplace} [id OF] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 26.25]]} [id OG] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id NN] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   |<CudaNdarrayType(float32, (True, True))> [id OH] <CudaNdarrayType(float32, (True, True))> -> [id FV]\n >   |   | |   |CudaNdarrayConstant{[[ 17.5]]} [id OI] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |GpuElemwise{pow,no_inplace} [id OJ] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id NN] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 3.]]} [id OK] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |<CudaNdarrayType(float32, (True, True))> [id OL] <CudaNdarrayType(float32, (True, True))> -> [id FX]\n >   |   | |   |CudaNdarrayConstant{[[ 5.25]]} [id OM] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |GpuElemwise{Pow}[(0, 0)] [id ON] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id NN] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 5.]]} [id OO] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |<CudaNdarrayType(float32, (True, True))> [id OP] <CudaNdarrayType(float32, (True, True))> -> [id FT]\n >   |   | |GpuCAReduce{add}{1,0} [id OQ] <CudaNdarrayType(float32, vector)> ''   \n >   |   | | |GpuElemwise{Composite{(i0 * (i1 * ((i2 * ((i3 + i4 + i5) - (i6 + i7))) - (i8 * ((i3 + i9 + i10) - i11)))))}}[(0, 2)] [id OR] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   |GpuSubtensor{int64:int64:} [id OS] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |GpuDimShuffle{1,0} [id OT] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |GpuReshape{2} [id OU] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |   |GpuFromHost [id OV] <CudaNdarrayType(float32, (False, True, True, False))> ''   \n >   |   | |   | |   | |Alloc [id KP] <TensorType(float32, (False, True, True, False))> ''   \n >   |   | |   | |   |MakeVector{dtype='int64'} [id MG] <TensorType(int64, vector)> ''   \n >   |   | |   | |ScalarFromTensor [id MH] <int64> ''   \n >   |   | |   | |ScalarFromTensor [id OW] <int64> ''   \n >   |   | |   |   |Elemwise{add,no_inplace} [id OX] <TensorType(int64, scalar)> ''   \n >   |   | |   |     |Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i3 * i4) // (i5 * i3 * i4)), i0)}}[(0, 0)] [id LJ] <TensorType(int64, scalar)> ''   \n >   |   | |   |     |Elemwise{sub,no_inplace} [id LY] <TensorType(int64, scalar)> ''   \n >   |   | |   |<CudaNdarrayType(float32, (True, True))> [id OY] <CudaNdarrayType(float32, (True, True))> -> [id FZ]\n >   |   | |   |GpuElemwise{Composite{Cast{float32}(LT(i0, i1))},no_inplace} [id OZ] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id PA] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |GpuDimShuffle{0,x} [id PB] <CudaNdarrayType(float32, col)> ''   \n >   |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id PC] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | | |   |GpuSubtensor{int64:int64:} [id PD] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |     |Rest of the points of the layers_copy[cuda] [id LE] <CudaNdarrayType(float32, matrix)> -> [id FA]\n >   |   | |   | | |     |ScalarFromTensor [id PE] <int64> ''   \n >   |   | |   | | |     | |<TensorType(int64, scalar)> [id ME] <TensorType(int64, scalar)> -> [id BV]\n >   |   | |   | | |     |ScalarFromTensor [id PF] <int64> ''   \n >   |   | |   | | |       |<TensorType(int64, scalar)> [id MB] <TensorType(int64, scalar)> -> [id BH]\n >   |   | |   | | |GpuDimShuffle{x,0} [id NX] <CudaNdarrayType(float32, row)> ''   \n >   |   | |   | | |GpuDot22Scalar [id PG] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | |GpuSubtensor{int64:int64:} [id PD] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | |GpuDimShuffle{1,0} [id OA] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | |TensorConstant{2.0} [id OB] <TensorType(float32, scalar)>\n >   |   | |   | | |CudaNdarrayConstant{[[ 0.]]} [id OC] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |<CudaNdarrayType(float32, (True, True))> [id OD] <CudaNdarrayType(float32, (True, True))> -> [id FM]\n >   |   | |   |CudaNdarrayConstant{[[ 1.]]} [id PH] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id PI] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 8.75]]} [id PJ] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id PK] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id PA] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |<CudaNdarrayType(float32, (True, True))> [id OD] <CudaNdarrayType(float32, (True, True))> -> [id FM]\n >   |   | |   | |CudaNdarrayConstant{[[ 3.]]} [id OK] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id PL] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 0.75]]} [id PM] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id PK] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 7.]]} [id PN] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |GpuElemwise{Composite{(i0 * sqr(i1))},no_inplace} [id PO] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 7.]]} [id PN] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id PK] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))}}[(0, 1)] [id PP] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 3.5]]} [id PQ] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id PK] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 5.]]} [id OO] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |GpuElemwise{Composite{Cast{float32}(LT(i0, i1))},no_inplace} [id PR] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id PS] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |GpuDimShuffle{0,x} [id PT] <CudaNdarrayType(float32, col)> ''   \n >   |   | |   | | | |GpuCAReduce{pre=sqr,red=add}{0,1} [id PU] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   | | |   |GpuSubtensor{int64:int64:} [id PV] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |     |Reference points for every layer_copy[cuda] [id LG] <CudaNdarrayType(float32, matrix)> -> [id FB]\n >   |   | |   | | |     |ScalarFromTensor [id PE] <int64> ''   \n >   |   | |   | | |     |ScalarFromTensor [id PF] <int64> ''   \n >   |   | |   | | |GpuDimShuffle{x,0} [id NX] <CudaNdarrayType(float32, row)> ''   \n >   |   | |   | | |GpuDot22Scalar [id PW] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | |GpuSubtensor{int64:int64:} [id PV] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | |GpuDimShuffle{1,0} [id OA] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | | |TensorConstant{2.0} [id OB] <TensorType(float32, scalar)>\n >   |   | |   | | |CudaNdarrayConstant{[[ 0.]]} [id OC] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |<CudaNdarrayType(float32, (True, True))> [id OD] <CudaNdarrayType(float32, (True, True))> -> [id FM]\n >   |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id PX] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 8.75]]} [id PJ] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id PY] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |GpuElemwise{Composite{sqrt(maximum(((i0 + i1) - i2), i3))}}[(0, 2)] [id PS] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | | |<CudaNdarrayType(float32, (True, True))> [id OD] <CudaNdarrayType(float32, (True, True))> -> [id FM]\n >   |   | |   | |CudaNdarrayConstant{[[ 3.]]} [id OK] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace} [id PZ] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 0.75]]} [id PM] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   | |GpuElemwise{TrueDiv}[(0, 0)] [id PY] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |CudaNdarrayConstant{[[ 7.]]} [id PN] <CudaNdarrayType(float32, (True, True))>\n >   |   | |   |GpuElemwise{Composite{((i0 * sqr(i1)) + (i2 * (i1 ** i3)))}}[(0, 1)] [id QA] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |     |CudaNdarrayConstant{[[ 7.]]} [id PN] <CudaNdarrayType(float32, (True, True))>\n >   |   | |     |GpuElemwise{TrueDiv}[(0, 0)] [id PY] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |     |CudaNdarrayConstant{[[ 3.5]]} [id PQ] <CudaNdarrayType(float32, (True, True))>\n >   |   | |     |CudaNdarrayConstant{[[ 5.]]} [id OO] <CudaNdarrayType(float32, (True, True))>\n >   |   | |GpuCAReduce{add}{1,0} [id QB] <CudaNdarrayType(float32, vector)> ''   \n >   |   | | |GpuElemwise{Composite{(((i0 * i1) * i2) * i3)}}[(0, 2)] [id QC] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   |GpuSubtensor{int64:int64:} [id QD] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |GpuDimShuffle{1,0} [id OT] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |ScalarFromTensor [id OW] <int64> ''   \n >   |   | |   | |ScalarFromTensor [id QE] <int64> ''   \n >   |   | |   |   |Elemwise{Add}[(0, 0)] [id QF] <TensorType(int64, scalar)> ''   \n >   |   | |   |     |Elemwise{add,no_inplace} [id OX] <TensorType(int64, scalar)> ''   \n >   |   | |   |     |<TensorType(int64, scalar)> [id MF] <TensorType(int64, scalar)> -> [id DX]\n >   |   | |   |<CudaNdarrayType(float32, (True, True))> [id KG] <CudaNdarrayType(float32, (True, True))> -> [id FL]\n >   |   | |   |GpuDimShuffle{1,0} [id QG] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   | |GpuReshape{2} [id QH] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |   |   |GpuAlloc [id QI] <CudaNdarrayType(float32, (False, True, True, False))> ''   \n >   |   | |   |   | |GpuSubtensor{:int64:} [id QJ] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |   |   | | |<CudaNdarrayType(float32, vector)> [id QK] <CudaNdarrayType(float32, vector)> -> [id IJ]\n >   |   | |   |   | | |ScalarFromTensor [id QL] <int64> ''   \n >   |   | |   |   | |   |<TensorType(int64, scalar)> [id MF] <TensorType(int64, scalar)> -> [id DX]\n >   |   | |   |   | |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id KR] <TensorType(int64, scalar)> ''   \n >   |   | |   |   | |TensorConstant{1} [id LH] <TensorType(int8, scalar)>\n >   |   | |   |   | |TensorConstant{1} [id LH] <TensorType(int8, scalar)>\n >   |   | |   |   | |Elemwise{Composite{Switch(LT(i0, i1), Switch(LT((i0 + i2), i1), i1, (i0 + i2)), Switch(LT(i0, i2), i0, i2))}}[(0, 2)] [id QM] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |   |<TensorType(int64, scalar)> [id MF] <TensorType(int64, scalar)> -> [id DX]\n >   |   | |   |   |   |TensorConstant{0} [id LP] <TensorType(int8, scalar)>\n >   |   | |   |   |   |Shape_i{0} [id QN] <TensorType(int64, scalar)> ''   \n >   |   | |   |   |     |<CudaNdarrayType(float32, vector)> [id QK] <CudaNdarrayType(float32, vector)> -> [id IJ]\n >   |   | |   |   |MakeVector{dtype='int64'} [id QO] <TensorType(int64, vector)> ''   \n >   |   | |   |     |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id KR] <TensorType(int64, scalar)> ''   \n >   |   | |   |     |Elemwise{Composite{Switch(LT(i0, i1), Switch(LT((i0 + i2), i1), i1, (i0 + i2)), Switch(LT(i0, i2), i0, i2))}}[(0, 2)] [id QM] <TensorType(int64, scalar)> ''   \n >   |   | |   |GpuSubtensor{:int64:} [id QP] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |     |GpuJoin [id QQ] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |     | |TensorConstant{1} [id LH] <TensorType(int8, scalar)>\n >   |   | |     | |GpuReshape{2} [id QR] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |     | | |GpuAdvancedSubtensor1 [id QS] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |     | | | |GpuReshape{1} [id QT] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |     | | | | |GpuElemwise{mul,no_inplace} [id QU] <CudaNdarrayType(float32, matrix)> ''   \n >   |   | |     | | | | | |<CudaNdarrayType(float32, matrix)> [id QV] <CudaNdarrayType(float32, matrix)> -> [id EV]\n >   |   | |     | | | | | |GpuFromHost [id QW] <CudaNdarrayType(float32, row)> ''   \n >   |   | |     | | | | |   |Elemwise{Cast{float32}} [id QX] <TensorType(float32, row)> ''   \n >   |   | |     | | | | |     |InplaceDimShuffle{x,0} [id QY] <TensorType(bool, row)> ''   \n >   |   | |     | | | | |       |Elemwise{eq,no_inplace} [id JZ] <TensorType(bool, vector)> 'Yet simulated LITHOLOGY node'   \n >   |   | |     | | | | |TensorConstant{(1,) of -1} [id LB] <TensorType(int64, (True,))>\n >   |   | |     | | | |Subtensor{int64} [id QZ] <TensorType(int64, vector)> ''   \n >   |   | |     | | |   |Nonzero [id RA] <TensorType(int64, matrix)> ''   \n >   |   | |     | | |   | |HostFromGpu [id RB] <TensorType(float32, vector)> ''   \n >   |   | |     | | |   |   |GpuReshape{1} [id QT] <CudaNdarrayType(float32, vector)> ''   \n >   |   | |     | | |   |Constant{0} [id KA] <int64>\n >   |   | |     | | |TensorConstant{[ 9 -1]} [id RC] <TensorType(int64, vector)>\n >   |   | |     | |<CudaNdarrayType(float32, matrix)> [id RD] <CudaNdarrayType(float32, matrix)> -> [id HH]\n >   |   | |     |ScalarFromTensor [id QL] <int64> ''   \n >   |   | |GpuCAReduce{add}{1,0} [id RE] <CudaNdarrayType(float32, vector)> ''   \n >   |   |   |GpuElemwise{Mul}[(0, 0)] [id RF] <CudaNdarrayType(float32, matrix)> ''   \n >   |   |     |GpuSubtensor{int64::} [id RG] <CudaNdarrayType(float32, matrix)> ''   \n >   |   |     | |GpuDimShuffle{1,0} [id OT] <CudaNdarrayType(float32, matrix)> ''   \n >   |   |     | |ScalarFromTensor [id QE] <int64> ''   \n >   |   |     |GpuSubtensor{::, :int64:} [id RH] <CudaNdarrayType(float32, matrix)> ''   \n >   |   |       |<CudaNdarrayType(float32, matrix)> [id RI] <CudaNdarrayType(float32, matrix)> -> [id GW]\n >   |   |       |ScalarFromTensor [id RJ] <int64> ''   \n >   |   |         |Elemwise{Composite{((i0 // i1) + i2 + i3)}}[(0, 0)] [id KR] <TensorType(int64, scalar)> ''   \n >   |   |<int64> [id JU] <int64> -> [id GQ]\n >   |TensorConstant{1} [id RK] <TensorType(int64, scalar)>\n >   |Subtensor{int64} [id JW] <TensorType(int64, vector)> ''   \n >GpuAdvancedIncSubtensor1{no_inplace,set} [id RL] <CudaNdarrayType(float32, vector)> ''   \n > |<CudaNdarrayType(float32, vector)> [id RM] <CudaNdarrayType(float32, vector)> -> [id EX]\n > |GpuAdvancedSubtensor1 [id RN] <CudaNdarrayType(float32, vector)> ''   \n > | |for{gpu,scan_fn} [id RO] <CudaNdarrayType(float32, vector)> ''   \n > | | |<TensorType(int64, scalar)> [id RP] <TensorType(int64, scalar)> -> [id GY]\n > | | |Elemwise{Cast{int32}} [id RQ] <TensorType(int32, vector)> ''   \n > | | | |<TensorType(int64, vector)> [id RR] <TensorType(int64, vector)> -> [id JG]\n > | | |Elemwise{Cast{int32}} [id RS] <TensorType(int32, vector)> ''   \n > | | | |<TensorType(int64, vector)> [id RT] <TensorType(int64, vector)> -> [id IU]\n > | | |GpuFromHost [id RU] <CudaNdarrayType(float32, vector)> ''   \n > | | | |Elemwise{Composite{Cast{float32}((i0 - i1))}} [id RV] <TensorType(float32, vector)> ''   \n > | | |   |<TensorType(int64, vector)> [id RT] <TensorType(int64, vector)> -> [id IU]\n > | | |   |<TensorType(int64, vector)> [id RR] <TensorType(int64, vector)> -> [id JG]\n > | | |<TensorType(int64, scalar)> [id RP] <TensorType(int64, scalar)> -> [id GY]\n > | | |GpuSubtensor{int64:int64:} [id RW] <CudaNdarrayType(float32, vector)> ''   \n > | |   |GpuElemwise{Composite{((((i0 * i1 * i2 * i3) + (-i4)) + i5) + i6)}}[(0, 3)] [id KD] <CudaNdarrayType(float32, vector)> ''   \n > | |   |<int64> [id JU] <int64> -> [id GQ]\n > | |   |<int64> [id RX] <int64> -> [id GO]\n > | |Elemwise{add,no_inplace} [id RY] <TensorType(int64, vector)> ''   \n > |   |TensorConstant{(1,) of -1} [id LB] <TensorType(int64, (True,))>\n > |   |Subtensor{int64:int64:} [id RZ] <TensorType(int64, vector)> ''   \n > |     |Value of the formation_copy [id SA] <TensorType(int64, vector)> -> [id EW]\n > |     |ScalarFromTensor [id SB] <int64> ''   \n > |     | |<TensorType(int64, scalar)> [id SC] <TensorType(int64, scalar)> -> [id DD]\n > |     |ScalarFromTensor [id SD] <int64> ''   \n > |       |<TensorType(int64, scalar)> [id SE] <TensorType(int64, scalar)> -> [id DN]\n > |Elemwise{add,no_inplace} [id RY] <TensorType(int64, vector)> ''   \n\nforall_inplace,gpu,scan_fn}.1 [id A] <CudaNdarrayType(float32, matrix)> ''   \n >GpuFromHost [id JN] <CudaNdarrayType(float32, matrix)> ''   \n >GpuAdvancedIncSubtensor1{no_inplace,set} [id RL] <CudaNdarrayType(float32, vector)> ''   \n\nfor{gpu,scan_fn} [id RO] <CudaNdarrayType(float32, vector)> ''   \n >GpuElemwise{true_div,no_inplace} [id SF] <CudaNdarrayType(float32, scalar)> ''   \n > |GpuCAReduce{add}{1} [id SG] <CudaNdarrayType(float32, scalar)> ''   \n > | |GpuSubtensor{int32:int32:} [id SH] <CudaNdarrayType(float32, vector)> ''   \n > |   |<CudaNdarrayType(float32, vector)> [id SI] <CudaNdarrayType(float32, vector)> -> [id RW]\n > |   |ScalarFromTensor [id SJ] <int32> ''   \n > |   | |<TensorType(int32, scalar)> [id SK] <TensorType(int32, scalar)> -> [id RQ]\n > |   |ScalarFromTensor [id SL] <int32> ''   \n > |     |<TensorType(int32, scalar)> [id SM] <TensorType(int32, scalar)> -> [id RS]\n > |<CudaNdarrayType(float32, scalar)> [id SN] <CudaNdarrayType(float32, scalar)> -> [id RU]\n\nStorage map footprint:\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (9, 125000), ElemSize: 4 Byte(s), TotalSize: 4500000 Byte(s)\n - GpuIncSubtensor{InplaceSet;:int64:}.0, Shape: (2, 3, 125000), ElemSize: 4 Byte(s), TotalSize: 3000000 Byte(s)\n - forall_inplace,gpu,scan_fn}.0, Shape: (2, 3, 125000), ElemSize: 4 Byte(s), TotalSize: 3000000 Byte(s)\n - Coordinates of the grid points to interpolate, Shared Input, Shape: (125000, 3), ElemSize: 4 Byte(s), TotalSize: 1500000 Byte(s)\n - final block of lithologies init, Shared Input, Shape: (1, 125000), ElemSize: 4 Byte(s), TotalSize: 500000 Byte(s)\n - GpuDimShuffle{1,0}.0, Shape: (9, 60), ElemSize: 4 Byte(s), TotalSize: 2160 Byte(s)\n - GpuFromHost.0, Shape: (30, 3), ElemSize: 4 Byte(s), TotalSize: 360 Byte(s)\n - Reference points for every layer, Input, Shape: (30, 3), ElemSize: 4 Byte(s), TotalSize: 360 Byte(s)\n - GpuFromHost.0, Shape: (30, 3), ElemSize: 4 Byte(s), TotalSize: 360 Byte(s)\n - Rest of the points of the layers, Input, Shape: (30, 3), ElemSize: 4 Byte(s), TotalSize: 360 Byte(s)\n - GpuIncSubtensor{InplaceSet;:int64:}.0, Shape: (9,), ElemSize: 4 Byte(s), TotalSize: 36 Byte(s)\n - Subtensor{int64:int64:int8}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - Value of the formation, Shared Input, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - <TensorType(int64, vector)>, Shared Input, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - Subtensor{int64:int64:int8}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (4,), ElemSize: 4 Byte(s), TotalSize: 16 Byte(s)\n - List with the number of formations, Shared Input, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - Length of interfaces in every series, Shared Input, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - Length of foliations in every series, Shared Input, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - GpuFromHost.0, Shape: (1, 3), ElemSize: 4 Byte(s), TotalSize: 12 Byte(s)\n - Position of the dips, Input, Shape: (1, 3), ElemSize: 4 Byte(s), TotalSize: 12 Byte(s)\n - Subtensor{int64:int64:int64}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{maximum,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Subtensor{int64:int64:int64}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Grade of the universal drift, Shared Input, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - TensorConstant{(1,) of 9}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Subtensor{int64:int64:int64}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{minimum,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{minimum(minimum(minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4), i5), i6)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1,) of 2}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Subtensor{int64:int64:int64}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Subtensor{int64:int64:int64}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - TensorConstant{(1,) of -1}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{3}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Subtensor{int64:int64:int64}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Constant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Subtensor{int64:int64:int64}.0, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Polarity, Input, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{mul,no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{true_div,no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{sqr,no_inplace}.0, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Covariance at 0, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 15.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - GpuElemwise{Composite{(i0 * (i1 ** i2))},no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{mul,no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{mul,no_inplace}.0, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{Mul}[(0, 1)].0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuFromHost.0, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuFromHost.0, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 2.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - Range, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 5.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuDimShuffle{x,x}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuDimShuffle{x,x}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 20.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{pow,no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 4.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuDimShuffle{x,x}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - GpuDimShuffle{x}.0, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{pow,no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{neg,no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Angle of every dip, Input, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{14.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - Azimuth, Input, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 3.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{pow,no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{Composite{(((i0 * i1) / sqr(i2)) + i3)},no_inplace}.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[-14.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[ 2.]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuFromHost.0, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 7.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{mul,no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{9}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{(1,) of 0}, Shape: (1,), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (0, 125060), ElemSize: 4 Byte(s), TotalSize: 0 Byte(s)\n TotalSize: 9504211.0 Byte(s) 0.009 GB\n TotalSize inputs: 6501051.0 Byte(s) 0.006 GB\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'."
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sol = gp.compute_model(interp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 125000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution can be plot with the correspondent plotting function. Blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/anaconda3/lib/python3.5/site-packages/matplotlib/axes/_axes.py:519: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n",
      "/home/miguel/anaconda3/lib/python3.5/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAEdCAYAAACVAAuoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fefbfdd8e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gp.plot_section(geo_data, sol[-1, 0, :], 25, plot_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/anaconda3/lib/python3.5/site-packages/matplotlib/axes/_axes.py:519: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n",
      "/home/miguel/anaconda3/lib/python3.5/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAFrCAYAAABIe+V0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYRPIBBsOv4flxvGfZg29UUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa810b23048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gp.plot_potential_field(geo_data, sol[-1, 1], 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ver, sim = gp.get_surfaces(sol[-1, 1], interp_data, original_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#interp_data.geo_data_res.interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1450.0 1000.0 -1150.0\n",
      "1450.0 1000.0 -1150.0\n",
      "1450.0 1000.0 -1150.0\n",
      "1450.0 1000.0 -1150.0\n"
     ]
    }
   ],
   "source": [
    "gp.plot_surfaces_3D(geo_data, ver, sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Visualization' from '../gempy/Visualization.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append(\"../gempy\")\n",
    "\n",
    "import Visualization \n",
    "import importlib\n",
    "importlib.reload(Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5770230769230769 0.5001 0.48086923076923077\n",
      "0.5770230769230769 0.5001 0.48086923076923077\n",
      "0.5770230769230769 0.5001 0.48086923076923077\n",
      "0.5770230769230769 0.5001 0.48086923076923077\n",
      "[ 0.20522821  0.43856154  0.456121  ]\n",
      "[ 0.20522821  0.43856154  0.456121  ]\n",
      "[ 0.20522821  0.43856154  0.456121  ]\n",
      "[ 0.21548462  0.43856154  0.45418294]\n",
      "[ 0.21548462  0.45907436  0.46132124]\n",
      "[ 0.21548462  0.43856154  0.45376262]\n",
      "[ 0.21548462  0.43856154  0.45376262]\n",
      "[ 0.21548462  0.43856154  0.45376262]\n",
      "[ 0.21548462  0.43856154  0.45373339]\n",
      "[ 0.21548462  0.42830513  0.44860485]\n",
      "[ 0.21548462  0.45907436  0.46175689]\n",
      "[ 0.21548462  0.45907436  0.46174287]\n",
      "[ 0.21548462  0.45907436  0.4616673 ]\n",
      "[ 0.21548462  0.45907436  0.46165366]\n",
      "[ 0.20522821  0.41804872  0.44566828]\n",
      "[ 0.20522821  0.41804872  0.44571897]\n",
      "[ 0.20522821  0.42055372  0.4475359 ]\n",
      "[ 0.20522821  0.42049343  0.4475359 ]\n",
      "[ 0.21548462  0.43856154  0.45553111]\n",
      "[ 0.21548462  0.43856154  0.4555156 ]\n",
      "[ 0.21548462  0.4442005   0.45779231]\n"
     ]
    }
   ],
   "source": [
    "w = Visualization.vtkVisualization(interp_data.geo_data_res, real_time=True )\n",
    "w.set_surfaces(ver, sim,\n",
    "               #formations_names_l, formation_numbers_l,\n",
    "                )\n",
    "w.interp_data  = interp_data\n",
    "if True:\n",
    "    w.set_interfaces()\n",
    "    w.set_foliations()\n",
    "w.render_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.20522821,  0.27670608,  0.76548462],\n",
       "        [ 0.21548462,  0.28471538,  0.76164953],\n",
       "        [ 0.21548462,  0.27746809,  0.76548462],\n",
       "        ..., \n",
       "        [ 0.70779231,  0.67445897,  0.74813737],\n",
       "        [ 0.70779231,  0.67689486,  0.75522821],\n",
       "        [ 0.70779231,  0.68013614,  0.76548462]]),\n",
       " array([[ 0.21042899,  0.24368974,  0.73471538],\n",
       "        [ 0.21548462,  0.25394615,  0.73064673],\n",
       "        [ 0.21548462,  0.24510343,  0.73471538],\n",
       "        ..., \n",
       "        [ 0.70779231,  0.70525696,  0.74497179],\n",
       "        [ 0.70779231,  0.70906552,  0.75522821],\n",
       "        [ 0.70779231,  0.71263995,  0.76548462]]),\n",
       " array([[ 0.21379464,  0.24368974,  0.41676667],\n",
       "        [ 0.21548462,  0.24422234,  0.41676667],\n",
       "        [ 0.21548462,  0.24368974,  0.41537432],\n",
       "        ..., \n",
       "        [ 0.70779231,  0.73599744,  0.52782487],\n",
       "        [ 0.70779231,  0.7382485 ,  0.52958718],\n",
       "        [ 0.70779231,  0.74625385,  0.53617301]]),\n",
       " array([[ 0.20522821,  0.35608629,  0.26292051],\n",
       "        [ 0.20522821,  0.35549842,  0.27317692],\n",
       "        [ 0.20929252,  0.35651026,  0.27317692],\n",
       "        ..., \n",
       "        [ 0.70779231,  0.73599744,  0.37631415],\n",
       "        [ 0.70531659,  0.74625385,  0.37574103],\n",
       "        [ 0.70779231,  0.74625385,  0.37736847]])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = w.ren_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.RemoveActor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "67px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
