{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11 - Improving the distance algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance algorithm is now working in general. This notebook intends to wrap it up and make it work faster if possible. Following problems are still not completely resolved:\n",
    "- a step size of at least 2 ist still required to get results\n",
    "- to avoid singular matrices, I had to round the value of the scalar field I am handing to the marching cubes method\n",
    "  to 2 decimals.\n",
    "      - not sure if that is robust for every possible case\n",
    "      - increases the error that comes from choosing the closest point of the triangular mesh\n",
    "\n",
    "Following ideas may speed up the calculation process:\n",
    "In general:\n",
    "- the triangular mesh for the basic point can be reused, as well as its prefactorization\n",
    "- a limited amount of triangular meshes could be used (and reused)\n",
    "- increase step size for forward simulation - this helps a LOT (20s for 50 points)\n",
    "- parallelization ???\n",
    "\n",
    "For Kriging:\n",
    "- mix of eucl. dist and this function, as this becomes only important for distances, where layer curvature plays a role\n",
    "- reduce number of points used \n",
    "\n",
    "Other things to do:\n",
    "- add the factors for anisotropy\n",
    "- check error tolerance and relevance\n",
    "- rounding to reasonable decimal (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# These lines are necessary only if GemPy is not installed\n",
    "import sys, os\n",
    "sys.path.append(\"../../..\")\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
    "\n",
    "# Importing GemPy, which takes really long\n",
    "import gempy as gp\n",
    "\n",
    "# Importing auxiliary libraries\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import splu\n",
    "\n",
    "from skimage import measure\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "# Importing the data from CSV-files and setting extent and resolution, example without faults\n",
    "geo_data = gp.create_data([0,3000,0,200,0,2000],resolution=[120,4,80], \n",
    "                         path_o = \"C:/Users/Jan/gempy/notebooks/input_data/tut_chapter3/tutorial_ch3_foliations\", # importing orientation (foliation) data\n",
    "                         path_i = \"C:/Users/Jan/gempy/notebooks/input_data/tut_chapter3/tutorial_ch3_interfaces\") # importing point-positional interface data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling theano function...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation Done!\n",
      "Level of Optimization:  fast_compile\n",
      "Device:  cpu\n",
      "Precision:  float32\n",
      "Number of faults:  0\n",
      "Compiling theano function...\n",
      "Compilation Done!\n",
      "Level of Optimization:  fast_compile\n",
      "Device:  cpu\n",
      "Precision:  float32\n",
      "Number of faults:  0\n"
     ]
    }
   ],
   "source": [
    "interp_data = gp.InterpolatorData(geo_data, u_grade=[1], output='geology', compile_theano=True,\n",
    "                                  theano_optimizer='fast_compile')\n",
    "\n",
    "interp_data_grad = gp.InterpolatorData(geo_data, u_grade=[1], output='gradients', compile_theano=True,\n",
    "                                  theano_optimizer='fast_compile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\Anaconda3\\lib\\site-packages\\theano\\tensor\\subtensor.py:2320: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[0][inputs[2:]] = inputs[1]\n"
     ]
    }
   ],
   "source": [
    "lith_block, fault_block = gp.compute_model(interp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_domain (geomodel, grid, formation):\n",
    "        \"\"\"\n",
    "        Method to create a new pandas dataframe containing a grid for the SGS. Grid from complete geologic model is\n",
    "        down to a certain formation of interest.\n",
    "        Args:\n",
    "            geomodel (numpy.ndarray): lithological block model created with gempy\n",
    "            grid (gempy.data_management.GridClass): Grid created for geologic model\n",
    "            formation (int): Number of formation to perform CoKriging on\n",
    "        Returns:\n",
    "            pandas.dataframe: Dataframe with all relevant data for grid, cut to one lith\n",
    "        \"\"\"\n",
    "    \n",
    "        # convert lith block values to int, thats what Miguel suggested\n",
    "        lith_block_int = np.round(lith_block)\n",
    "    \n",
    "        # create the dataframe and populate with data\n",
    "        d = {'X': grid.values[:,0], 'Y': grid.values[:,1], 'Z': grid.values[:,2], 'lith': lith_block_int[0], 'grad': lith_block[1]}\n",
    "        df_cokr = pd.DataFrame(data=d)\n",
    "\n",
    "        # cut down to wanted lithology and reset dataframne\n",
    "        df_sgs_grid = df_cokr.loc[df_cokr['lith'] == formation]\n",
    "        df_sgs_grid = df_sgs_grid.reset_index() # reset indicies\n",
    "        del df_sgs_grid['index'] # reset indices\n",
    "\n",
    "        return df_sgs_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def veclen(vectors):\n",
    "    \"\"\" return L2 norm (vector length) along the last axis, for example to compute the length of an array of vectors \"\"\"\n",
    "    return np.sqrt(np.sum(vectors**2, axis=-1))\n",
    "\n",
    "def normalized(vectors):\n",
    "    \"\"\" normalize array of vectors along the last axis \"\"\"\n",
    "    return vectors / veclen(vectors)[..., np.newaxis]\n",
    "\n",
    "\n",
    "def compute_mesh_laplacian(verts, tris):\n",
    "    \"\"\"\n",
    "    computes a sparse matrix representing the discretized laplace-beltrami operator of the mesh\n",
    "    given by n vertex positions (\"verts\") and a m triangles (\"tris\") \n",
    "    \n",
    "    verts: (n, 3) array (float)\n",
    "    tris: (m, 3) array (int) - indices into the verts array\n",
    "    computes the conformal weights (\"cotangent weights\") for the mesh, ie:\n",
    "    w_ij = - .5 * (cot \\alpha + cot \\beta)\n",
    "    See:\n",
    "        Olga Sorkine, \"Laplacian Mesh Processing\"\n",
    "        and for theoretical comparison of different discretizations, see \n",
    "        Max Wardetzky et al., \"Discrete Laplace operators: No free lunch\"\n",
    "    returns matrix L that computes the laplacian coordinates, e.g. L * x = delta\n",
    "    \"\"\"\n",
    "    n = len(verts)\n",
    "    W_ij = np.empty(0)\n",
    "    I = np.empty(0, np.int32)\n",
    "    J = np.empty(0, np.int32)\n",
    "    for i1, i2, i3 in [(0, 1, 2), (1, 2, 0), (2, 0, 1)]: # for edge i2 --> i3 facing vertex i1\n",
    "        vi1 = tris[:,i1] # vertex index of i1\n",
    "        vi2 = tris[:,i2]\n",
    "        vi3 = tris[:,i3]\n",
    "        # vertex vi1 faces the edge between vi2--vi3\n",
    "        # compute the angle at v1\n",
    "        # add cotangent angle at v1 to opposite edge v2--v3\n",
    "        # the cotangent weights are symmetric\n",
    "        u = verts[vi2] - verts[vi1]\n",
    "        v = verts[vi3] - verts[vi1]\n",
    "        cotan = (u * v).sum(axis=1) / veclen(np.cross(u, v))\n",
    "        W_ij = np.append(W_ij, 0.5 * cotan)\n",
    "        I = np.append(I, vi2)\n",
    "        J = np.append(J, vi3)\n",
    "        W_ij = np.append(W_ij, 0.5 * cotan)\n",
    "        I = np.append(I, vi3)\n",
    "        J = np.append(J, vi2)\n",
    "    L = sparse.csr_matrix((W_ij, (I, J)), shape=(n, n)) \n",
    "    \n",
    "    # compute diagonal entries\n",
    "    L = L - sparse.spdiags(L * np.ones(n), 0, n, n)\n",
    "    L = L.tocsr()\n",
    "    # area matrix\n",
    "    e1 = verts[tris[:,1]] - verts[tris[:,0]]\n",
    "    e2 = verts[tris[:,2]] - verts[tris[:,0]]\n",
    "    n = np.cross(e1, e2)\n",
    "    triangle_area = .5 * veclen(n)\n",
    "    # compute per-vertex area\n",
    "    vertex_area = np.zeros(len(verts))\n",
    "    ta3 = triangle_area / 3\n",
    "    for i in range(tris.shape[1]): # Jan: changed xrange to range\n",
    "        bc = np.bincount(tris[:,i].astype(int), ta3)\n",
    "        vertex_area[:len(bc)] += bc  \n",
    "    VA = sparse.spdiags(vertex_area, 0, len(verts), len(verts))\n",
    "    \n",
    "    return L, VA\n",
    "\n",
    "\n",
    "class GeodesicDistanceComputation(object):\n",
    "    \"\"\" \n",
    "    Computation of geodesic distances on triangle meshes using the heat method from the impressive paper\n",
    "        Geodesics in Heat: A New Approach to Computing Distance Based on Heat Flow\n",
    "        Keenan Crane, Clarisse Weischedel, Max Wardetzky\n",
    "        ACM Transactions on Graphics (SIGGRAPH 2013)\n",
    "    Example usage:\n",
    "        >>> compute_distance = GeodesicDistanceComputation(vertices, triangles)\n",
    "        >>> distance_of_each_vertex_to_vertex_0 = compute_distance(0)\n",
    "    \"\"\"\n",
    "    def __init__(self, verts, tris, m=10.0):\n",
    "        self._verts = verts\n",
    "        self._tris = tris\n",
    "        # precompute some stuff needed later on\n",
    "        e01 = verts[tris[:,1]] - verts[tris[:,0]]\n",
    "        e12 = verts[tris[:,2]] - verts[tris[:,1]]\n",
    "        e20 = verts[tris[:,0]] - verts[tris[:,2]]\n",
    "        self._triangle_area = .5 * veclen(np.cross(e01, e12))\n",
    "        unit_normal = normalized(np.cross(normalized(e01), normalized(e12)))\n",
    "        self._unit_normal_cross_e01 = np.cross(unit_normal, e01)\n",
    "        self._unit_normal_cross_e12 = np.cross(unit_normal, e12)\n",
    "        self._unit_normal_cross_e20 = np.cross(unit_normal, e20)\n",
    "        # parameters for heat method\n",
    "        h = np.mean(list(map(veclen, [e01, e12, e20]))) # Jan: converted to list\n",
    "        \n",
    "        # Jan: m is constant optimized at 1, here 10 is used\n",
    "        # Jan: h is mean distance between nodes/length of edges\n",
    "        t = m * h ** 2\n",
    "        \n",
    "        # pre-factorize poisson systems\n",
    "        Lc, A = compute_mesh_laplacian(verts, tris) \n",
    "        self._factored_AtLc = splu((A - t * Lc).tocsc()).solve\n",
    "        self._factored_L = splu(Lc.tocsc()).solve\n",
    "        \n",
    "    def __call__(self, idx):\n",
    "        \"\"\" \n",
    "        computes geodesic distances to all vertices in the mesh\n",
    "        idx can be either an integer (single vertex index) or a list of vertex indices\n",
    "        or an array of bools of length n (with n the number of vertices in the mesh) \n",
    "        \"\"\"\n",
    "        u0 = np.zeros(len(self._verts))\n",
    "        u0[idx] = 1.0\n",
    "        # heat method, step 1\n",
    "        u = self._factored_AtLc(u0).ravel()\n",
    "        # heat method step 2\n",
    "        grad_u = 1 / (2 * self._triangle_area)[:,np.newaxis] * (\n",
    "              self._unit_normal_cross_e01 * u[self._tris[:,2]][:,np.newaxis]\n",
    "            + self._unit_normal_cross_e12 * u[self._tris[:,0]][:,np.newaxis]\n",
    "            + self._unit_normal_cross_e20 * u[self._tris[:,1]][:,np.newaxis]\n",
    "        )\n",
    "        X = - grad_u / veclen(grad_u)[:,np.newaxis]\n",
    "        # heat method step 3\n",
    "        div_Xs = np.zeros(len(self._verts))\n",
    "        for i1, i2, i3 in [(0, 1, 2), (1, 2, 0), (2, 0, 1)]: # for edge i2 --> i3 facing vertex i1\n",
    "            vi1, vi2, vi3 = self._tris[:,i1], self._tris[:,i2], self._tris[:,i3]\n",
    "            e1 = self._verts[vi2] - self._verts[vi1]\n",
    "            e2 = self._verts[vi3] - self._verts[vi1]\n",
    "            e_opp = self._verts[vi3] - self._verts[vi2]\n",
    "            cot1 = 1 / np.tan(np.arccos( \n",
    "                (normalized(-e2) * normalized(-e_opp)).sum(axis=1)))\n",
    "            cot2 = 1 / np.tan(np.arccos(\n",
    "                (normalized(-e1) * normalized( e_opp)).sum(axis=1)))\n",
    "            div_Xs += np.bincount(\n",
    "                vi1.astype(int), \n",
    "        0.5 * (cot1 * (e1 * X).sum(axis=1) + cot2 * (e2 * X).sum(axis=1)), \n",
    "        minlength=len(self._verts))\n",
    "        phi = self._factored_L(div_Xs).ravel()\n",
    "        phi -= phi.min()\n",
    "        return phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perpendicular_dist(start_point, grad_val1, grad_val2, interp_data_grad):\n",
    "    \n",
    "    step_size = 50\n",
    "    step = 0\n",
    "    a = start_point\n",
    "    \n",
    "    if grad_val1 < grad_val2:\n",
    "        for i in range (1000):\n",
    "            # calculate scalar field vector at point\n",
    "            grad_vec = gp.compute_model_at(a, interp_data_grad)\n",
    "            # break condition if surface was crossed\n",
    "            if grad_vec[0][1] > grad_val2:\n",
    "                break\n",
    "            step += 1\n",
    "            grad_vec =np.array([grad_vec[0][2],grad_vec[0][3],grad_vec[0][4]])\n",
    "            # normalize to step size and set direction\n",
    "            vec_len = np.linalg.norm((grad_vec), ord=1)\n",
    "            grad_vec_norm = step_size*grad_vec/vec_len\n",
    "            grad_vec_norm = np.reshape(grad_vec_norm, (1, 3))\n",
    "            a = a+grad_vec_norm\n",
    "            \n",
    "    else:\n",
    "        for i in range (1000):\n",
    "            # calculate scalar field vector at point\n",
    "            grad_vec = gp.compute_model_at(a, interp_data_grad)\n",
    "            # break condition if surface was crossed\n",
    "            if grad_vec[0][1] < grad_val2:\n",
    "                break\n",
    "            step += 1\n",
    "            grad_vec =np.array([grad_vec[0][2],grad_vec[0][3],grad_vec[0][4]])\n",
    "            # normalize to step size and set direction\n",
    "            vec_len = np.linalg.norm((grad_vec), ord=1)\n",
    "            grad_vec_norm = step_size*grad_vec/vec_len\n",
    "            grad_vec_norm = np.reshape(grad_vec_norm, (1, 3))\n",
    "            grad_vec_norm = grad_vec_norm*(-1)\n",
    "            a = a+grad_vec_norm\n",
    "    \n",
    "    dist = step*step_size\n",
    "    point = a\n",
    "    return dist, point\n",
    "\n",
    "def parallel_dist(vertices, simplices, point1, point2):\n",
    "    compute_distance = GeodesicDistanceComputation(vertices, simplices)\n",
    "    distance_of_each_vertex_to_vertex_0 = compute_distance(point1)\n",
    "    dist = distance_of_each_vertex_to_vertex_0[point2]\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(pointA, pointB, geo_data, interp_data_grad, a, res, gradA, vertices_pA, simplices_pA):\n",
    "    \n",
    "    # compute value of scalar field at given points, rounded to avoid singular matrices\n",
    "    gradB = np.round(gp.compute_model_at(pointB, interp_data)[0][1], 2)\n",
    "\n",
    "    # get mesh plane for second point\n",
    "    vertices_pB, simplices_pB, normalsB, valuesB = measure.marching_cubes_lewiner(\n",
    "            a,\n",
    "            gradB,\n",
    "            step_size=3,\n",
    "            spacing=((geo_data.extent[1]/geo_data.resolution[0]),(geo_data.extent[3]/geo_data.resolution[1]),(geo_data.extent[5]/geo_data.resolution[2])))\n",
    "\n",
    "    # select closest points in mesh\n",
    "    closeA = cdist(pointA, vertices_pA).argmin()\n",
    "    closeB = cdist(pointB, vertices_pB).argmin()\n",
    "    \n",
    "    # calculate perpendicular distance towards each triangular mesh respectively\n",
    "    dist_perpA, pointA2 = perpendicular_dist(pointA, gradA, gradB, interp_data_grad)\n",
    "    dist_perpB, pointB2 = perpendicular_dist(pointB, gradB, gradA, interp_data_grad)\n",
    "    closeA2, distA2 = closest_node(pointA2, vertices_pB)\n",
    "    closeB2, distA2 = closest_node(pointB2, vertices_pA)\n",
    "    \n",
    "    # calculate parallel distance\n",
    "    dist_paraA = parallel_dist(vertices_pA, simplices_pA, closeA, closeB2)\n",
    "    dist_paraB = parallel_dist(vertices_pB, simplices_pB, closeB, closeA2)\n",
    "    \n",
    "    # calculate full distance\n",
    "    total_dist = 0.5*(dist_paraA+dist_paraB)+0.5*(dist_perpA+dist_perpB)\n",
    "    \n",
    "    return total_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_set(point, points):\n",
    "    result = np.zeros((len(points)))\n",
    "    \n",
    "    # do precalculations, mesh through basic point (only once)\n",
    "    res = gp.get_resolution(geo_data)\n",
    "    a = lith_block[1].reshape(res)\n",
    "    gradA = np.round(gp.compute_model_at(pointA, interp_data)[0][1], 2)\n",
    "    vertices_pA, simplices_pA, normalsA, valuesA = measure.marching_cubes_lewiner(\n",
    "            a,\n",
    "            gradA,\n",
    "            step_size=3,\n",
    "            spacing=((geo_data.extent[1]/geo_data.resolution[0]),(geo_data.extent[3]/geo_data.resolution[1]),(geo_data.extent[5]/geo_data.resolution[2])))\n",
    "    \n",
    "    for i in range (len(points)):\n",
    "        result[i] = get_distance(point, points[[i]], geo_data, interp_data_grad, a, res, gradA, vertices_pA, simplices_pA)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create domain data for certain lithology\n",
    "domain_data = init_domain(lith_block, geo_data.grid, formation=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = np.array([[domain_data.X[100], domain_data.Y[100], domain_data.Z[100]]])\n",
    "n = 50\n",
    "dist_points = np.zeros((n, 3))\n",
    "for i in range (n):\n",
    "    rand = np.random.randint(0,3750)\n",
    "    dist_points[i][0] = domain_data.X[rand]\n",
    "    dist_points[i][1] = domain_data.Y[rand]\n",
    "    dist_points[i][2] = domain_data.Z[rand]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where I ceck my speed with 50 points:\n",
    "\n",
    "For following parameters i get the following results (approximately)\n",
    "- step size mesh: 2 - only thing that works in general\n",
    "- step_size vert_dist: 5 - 24s, 20 - 7s, 50 - 3.5s --- obviuosly great impact on speed\n",
    "- got 1s by taking out one compute-model at in the vert. dist.\n",
    "- removed closest node function - no improvement\n",
    "- got another 1-2s by only calculating the surface for the basic point once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\Anaconda3\\lib\\site-packages\\theano\\tensor\\subtensor.py:2320: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[0][inputs[2:]] = inputs[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.46 s ± 44.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "[2509.06876133 2776.41615869 2684.69641385  297.78886782 1302.17941446\n",
      "  198.11045859  919.4939678   890.83521082  783.83693471 3128.35010784\n",
      " 2836.62876444  512.04062596 3106.44396755 2140.62050759 1665.43673989\n",
      " 2094.36866136  302.59688992 2140.62050759 2577.29476519 2177.58667226\n",
      "  586.08494565 2165.62050759  284.3211291   986.42858548 2984.29377857\n",
      " 1714.78349135 2145.67212326  214.85353406 1243.33917806 3226.93235724\n",
      " 3121.07287577 1380.24092373 1439.95300374  931.48562213 2388.23223831\n",
      " 1068.67521758 1954.01513622 3164.43185836  474.89860611 3124.19475683\n",
      " 1134.26602262 1524.62012809 3209.43913919 1533.22876915 2333.47285639\n",
      " 1777.40319591 1680.87350713 1327.26592683  737.06974869 2748.74417511]\n"
     ]
    }
   ],
   "source": [
    "%timeit test = calculate_distance_set(point, dist_points)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2378.31498012  450.16818425 2559.67198648 1305.6942708   673.91464267\n",
      "  1438.9326131  1741.24346687  282.7833052   989.43664325  199.9027592\n",
      "  1260.2245231  2342.07160407 2700.46683709 2240.27582237   90.25595961\n",
      "  2779.16899212 1654.42131001  933.7578673   268.18030944  375.3394\n",
      "  1514.40448882 2883.58209149 2675.47120044 2080.42257149 2011.47921738\n",
      "  2360.83737945 2147.00609293  554.81618755  695.96856936  554.81618755\n",
      "  2129.21016943 2903.12125153  764.10277044 2137.5913844  1978.65058364\n",
      "  1535.89871769 1914.69283227 1138.17335855  882.87074948 1951.17280254\n",
      "   693.81995064 2807.01551708  472.25898409 1298.08158158 1347.07616422\n",
      "   447.40697076 1903.17505904  397.18341505 2119.46883095 1849.38419716]]\n",
      "Wall time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "compare = cdist(point, dist_points)\n",
    "print(compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
