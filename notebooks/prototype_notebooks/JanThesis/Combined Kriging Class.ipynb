{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Kriging Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# These lines are necessary only if GemPy is not installed\n",
    "import sys, os\n",
    "sys.path.append(\"../../..\")\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
    "\n",
    "# Importing GemPy, which takes really long\n",
    "import gempy as gp\n",
    "\n",
    "# Importing auxiliary libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from scipy import spatial\n",
    "from scipy import optimize\n",
    "from scipy import special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-2-1e4244081fa7>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-1e4244081fa7>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    # cdist or my distance\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class Kriging():\n",
    "    # What do I want: \n",
    "    # passing: Data with properties, layer, geo_data --> meaning that I have to cut everything in here!\n",
    "    # possibility to read in data - check gempy how to do best\n",
    "    # analyzing data part needs to be in here somewhere, have to check how \"OK\" that is,\n",
    "    # and if I can switch between covariance function (SK) and variogram function (OK, UK) in a reasonable manner\n",
    "    # Selection:\n",
    "    # SK, OK, UK\n",
    "    # cdist or my distance\n",
    "    # SGS or not?\n",
    "    def __init__(self, **kwds):\n",
    "    # here I want to put the basic variables and also the data analysis\n",
    "        if '' in kwds:\n",
    "            self.set_nxny(kwds['nx'], kwds['ny'])\n",
    "    \n",
    "    def get_data():\n",
    "        # method to read data from given csv and create pandas dataframe\n",
    "        \n",
    "    def set_domain():\n",
    "        # cut grid and domain data to the given layer\n",
    "    \n",
    "    def analyse_data():\n",
    "        # method for getting mean, std, etc. of the given dataset\n",
    "        \n",
    "    def precompute_distances()\n",
    "        # method to precompute distances from each grid point to each other grid point\n",
    "        # depending wether euclidian or non-euclidian distance is checked\n",
    "        return dist_matrix\n",
    "    \n",
    "    def get_distance_matrices(dist_matrix, target_point, n):\n",
    "        \"\"\"\n",
    "        Method to get closest points out of distance matrix calculated beforehand.\n",
    "        Args:\n",
    "            dist_matrix (numpy.ndarray): matrix of distances between existing property data points and target point\n",
    "            n(int): number of closest points that should be used for Kriging\n",
    "            target_point(int): index of target point, within given extracted matrix\n",
    "        Returns\n",
    "            dist_close_all_to_all (numpy.ndarray)(n,n): distance matrix each to each of n closest data points\n",
    "            dist_close_target_to_all (numpy.ndarray)(n,): distance matrix of target to n closest data points\n",
    "        \"\"\"\n",
    "        # check for n closest points in matrix (minimum distance values) and sort the resulting index array\n",
    "        ind = np.argpartition(dist_matrix[target_point], n+1)[:n+1]\n",
    "        sort_ind = np.sort(ind)\n",
    "\n",
    "        # extract distances from target point (row of target index)\n",
    "        dist_close_target_to_all = dist_matrix[target_point][sort_ind]\n",
    "\n",
    "        # find new index of target point (and save it for second part) and delete value to get correct distance matrix\n",
    "        aux = np.where(dist_close_target_to_all == 0)[0][0]\n",
    "        dist_close_target_to_all = dist_close_target_to_all[dist_close_target_to_all != 0] \n",
    "\n",
    "        # extract distance each to each for those closest points, delete target point index row and column\n",
    "        dist_close_all_to_all = dist_matrix[np.ix_(sort_ind,sort_ind)]\n",
    "        dist_close_all_to_all = np.delete(dist_close_all_to_all, aux, axis=0)\n",
    "        dist_close_all_to_all = np.delete(dist_close_all_to_all, aux, axis=1)\n",
    "\n",
    "        return dist_close_target_to_all, dist_close_all_to_all\n",
    "    \n",
    "    def simple_kriging():\n",
    "        # def simple_kriging(point, mean, data, std):\n",
    "    \n",
    "        # be aware thats already only the closest points from pandas dataframe\n",
    "        data_m = data.as_matrix(('X','Y','Z'))\n",
    "        data_v = data['Property'].values\n",
    "        \n",
    "        # this has to be checked if I use both distance algortihms\n",
    "        data_d = data['dist'].values # take dist from closest points selection\n",
    "     \n",
    "        # empty matrix building\n",
    "        shape = len(data_m) \n",
    "        C = np.zeros((shape, shape))\n",
    "        c = np.zeros((shape))\n",
    "        w = np.zeros((shape))\n",
    "    \n",
    "        # Faster matrix building approach, no loops\n",
    "        dist = spatial.distance.cdist(data_m, data_m) #distance between all sampled points\n",
    "        C[:shape, :shape] = gaussian_cov_model(dist)\n",
    "        c[:shape] = gaussian_cov_model(data_d)\n",
    "    \n",
    "        # nugget effect, I have to do this properly! (How?)\n",
    "        np.fill_diagonal(C, 10)\n",
    "        \n",
    "        # solve for weights\n",
    "        w = np.linalg.solve(C,c)\n",
    "    \n",
    "        # SGS version - taking result from normal distribution with kriging mean an standard deviation\n",
    "        result = np.random.normal(mean + np.sum(w * (data_v-mean)), scale = 0) #scale=np.sqrt(variance-np.sum(w*c)))\n",
    "        # if I use other scale it gets wild\n",
    "    \n",
    "        # direct version, calculating result from weights. Need to be normed to one\n",
    "        # result = mean + np.sum(w * (data_v-mean))\n",
    "    \n",
    "        return result\n",
    "    \n",
    "    def ordinary_kriging():\n",
    "        #def ordinary_kriging(point, data):\n",
    "    \n",
    "        # be aware thats already only the closest points from pandas dataframe\n",
    "        data_m = data.as_matrix(('X','Y','Z'))\n",
    "        data_v = data['Property'].values\n",
    "        \n",
    "        # this has to be checked if I use both distance algortihms\n",
    "        data_d = data['dist'].values #take dist from closest points selection\n",
    "    \n",
    "        # empty matrix building\n",
    "        shape = len(data_m)\n",
    "        C = np.zeros((shape+1, shape+1))\n",
    "        c = np.zeros((shape+1))\n",
    "        w = np.zeros((shape+1))\n",
    "    \n",
    "        # Faster matrix building approach, no loops\n",
    "        dist = spatial.distance.cdist(data_m, data_m) #distance between all sampled points\n",
    "        C[:shape, :shape] = gaussian_variogram_model(dist)\n",
    "        c[:shape] = gaussian_variogram_model(data_d)\n",
    "    \n",
    "        # matrix setup - compare pykrige, special for OK\n",
    "        np.fill_diagonal(C, 0)\n",
    "        C[shape, :] = 1.0\n",
    "        C[:, shape] = 1.0\n",
    "        C[shape, shape] = 0.0  \n",
    "        c[shape] = 1.0\n",
    "\n",
    "        # Solve Kriging equations\n",
    "        w = np.linalg.solve(C,c)\n",
    "    \n",
    "        # SGS version - not correct yet, need to get mean and std\n",
    "        result = np.random.normal(np.sum(w[:shape] * data_v), scale=np.sqrt(w[shape]-gaussian_variogram_model(0)+np.sum(w[:shape]*c[:shape])))\n",
    "    \n",
    "        # direct version, calculating result from weights.\n",
    "        # result = np.sum(w[:shape] * data_v)\n",
    "    \n",
    "        return result\n",
    "    \n",
    "    def universal_kriging():\n",
    "        #def ordinary_kriging(point, data):\n",
    "    \n",
    "        # be aware thats already only the closest points from pandas dataframe\n",
    "        data_m = data.as_matrix(('X','Y','Z'))\n",
    "        data_v = data['Property'].values\n",
    "        \n",
    "        # this has to be checked if I use both distance algortihms\n",
    "        data_d = data['dist'].values #take dist from closest points selection\n",
    "    \n",
    "        # empty matrix building\n",
    "        shape = len(data_m)\n",
    "        C = np.zeros((shape+1, shape+1))\n",
    "        c = np.zeros((shape+1))\n",
    "        w = np.zeros((shape+1))\n",
    "    \n",
    "        # Faster matrix building approach, no loops\n",
    "        dist = spatial.distance.cdist(data_m, data_m) #distance between all sampled points\n",
    "        C[:shape, :shape] = gaussian_variogram_model(dist)\n",
    "        c[:shape] = gaussian_variogram_model(data_d)\n",
    "    \n",
    "        # matrix setup - compare pykrige\n",
    "        np.fill_diagonal(C, 0)\n",
    "        C[shape, :] = 1.0\n",
    "        C[:, shape] = 1.0\n",
    "        C[shape, shape] = 0.0  \n",
    "        c[shape] = 1.0\n",
    "    \n",
    "        # additional matrices for universal kriging, containing Coordinates and zeros\n",
    "        aux1 = np.vstack((data_m, np.zeros((1, 3))))\n",
    "        aux2 = np.hstack((np.transpose(data_m), np.zeros((3,4))))\n",
    "    \n",
    "        # adding auxiliary matrices to the kriging matrices\n",
    "        C = np.hstack((C, aux1))\n",
    "        C = np.vstack((C, aux2))\n",
    "        c = np.hstack((c, point))\n",
    "\n",
    "        # Solve Kriging equations\n",
    "        w = np.linalg.solve(C,c)\n",
    "    \n",
    "        # SGS version - in UK case the scale (standard deviation) is not yet implemented/correct\n",
    "        #result = np.random.normal(np.sum(w[:shape] * data_v), scale=np.sqrt(w[shape]-gaussian_variogram_model(0)+np.sum(w[:shape]*c[:shape])))\n",
    "    \n",
    "        # direct version, calculating result from weights.\n",
    "        result = np.sum(w[:shape] * data_v)\n",
    "    \n",
    "        return result\n",
    "        \n",
    "    def sgs():\n",
    "    # def perform_sgs(property_data, sgs_grid):\n",
    "    \"\"\"\n",
    "    Method to perform the SGS run, creating a new dataframe with the resulting grid, \n",
    "    containing the interpolated data fro the CoKriging\n",
    "    Args:\n",
    "        property_data (pandas.datframe): frame containing property data with corresponding X,Y,Z coordinates\n",
    "        sgs_grid (pandas.dataframe): frame containing grid, meaning all X,Y,Z coordinates in domain \n",
    "    Returns:\n",
    "        Result: Dataframe containg all interpolated values with corresponding coordinates       \n",
    "    \"\"\"\n",
    "    results = pd.DataFrame(columns=property_data.columns)\n",
    "    df_prop_calc = property_data.copy() #copy dataframe for appending results for SGS\n",
    "    df_sgs_grid_calc = sgs_grid.copy() #copy of grid frame to delete data\n",
    "    \n",
    "    # array with property indices and properties (n,2)\n",
    "    \n",
    "    sgs_check = np.arange(0,number_of_grid_points)\n",
    "    \n",
    "    for i in range(0, len(sgs_grid)):\n",
    "        \n",
    "        # choose random point from df_sgs_grid_calc\n",
    "        rand_pos = np.random.randint(0,len(df_sgs_grid_calc))\n",
    "        random_coord = df_sgs_grid_calc.iloc[rand_pos].as_matrix(('X','Y','Z'))\n",
    "        \n",
    "        rand_coord_aux = np.array([random_coord])\n",
    "        \n",
    "        # delete point from the df sgs_grid_calc\n",
    "        # maybe faster way without deleting, an array with only the indices and delete from that \n",
    "        df_sgs_grid_calc = df_sgs_grid_calc.drop([rand_pos])\n",
    "        df_sgs_grid_calc = df_sgs_grid_calc.reset_index() # reset indicies\n",
    "        del df_sgs_grid_calc['index'] #reset indices\n",
    "        \n",
    "        # only select n closest points for Cokriging,best by selection to make it work with miguels code\n",
    "        df_prop_calc_close = select_closest_points(rand_coord_aux, df_prop_calc)\n",
    "        \n",
    "        # perform the Kriging interpolation on this point\n",
    "        kriging_result = ordinary_kriging(target_point) \n",
    "        \n",
    "        # set coordinates in result array\n",
    "        new_interpolated_point = ([random_coord[0], random_coord[1],random_coord[2]])\n",
    "        \n",
    "        # add property interpolation to results array, depends a little bit on form of Kriging results\n",
    "        new_interpolated_point.append(kriging_results)\n",
    "                            \n",
    "        # append result to df_prop_calc to use for further SGS\n",
    "        df_prop_calc.loc[len(df_prop_calc)]=new_interpolated_point\n",
    "        \n",
    "        # append results to final results dataframe that will be returned\n",
    "        results.loc[len(results)]=new_interpolated_point\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
